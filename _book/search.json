[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "金融科技概论讲义（机器学习部分）",
    "section": "",
    "text": "欢迎学习金融科技导论！",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>金融科技导论</span>"
    ]
  },
  {
    "objectID": "index.html#课程简介",
    "href": "index.html#课程简介",
    "title": "金融科技概论讲义（机器学习部分）",
    "section": "0.1 课程简介",
    "text": "0.1 课程简介\n本课程专为零编程基础的本科二年级学生设计，采用渐进式实践优先的教学模式。通过后7周的学习，你将掌握：\n\n编程技能：Python 基础语法和数据处理\n机器学习理论：从线性回归到神经网络\n金融应用：实际案例和项目实践\n数据思维：理解数据驱动的决策过程\n\n课程具体安排与考核要求",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>金融科技导论</span>"
    ]
  },
  {
    "objectID": "index.html#学习目标",
    "href": "index.html#学习目标",
    "title": "金融科技概论讲义（机器学习部分）",
    "section": "0.2 学习目标",
    "text": "0.2 学习目标\n完成本课程后，你将能够：\n\n独立编程：使用 Python 进行数据分析和机器学习\n模型构建：从数据预处理到模型评估的完整流程\n问题解决：将机器学习应用于金融场景\n项目开发：完成端到端的机器学习项目",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>金融科技导论</span>"
    ]
  },
  {
    "objectID": "index.html#课程结构",
    "href": "index.html#课程结构",
    "title": "金融科技概论讲义（机器学习部分）",
    "section": "0.3 课程结构",
    "text": "0.3 课程结构\n本书按时间顺序组织，共分为6个主要章节：\n\n第10周：Python基础与机器学习入门\n第11周：数据处理与线性回归实践\n第12周：线性回归的正则化\n第13周：分类问题、决策树与评估指标\n第14周：集成学习 - 随机森林与 GBDT\n第15周：神经网络基础\n\n所有上机课jupyter notebook请通过百度网盘获取（链接: https://pan.baidu.com/s/1DlM2Mt7gS_Jn2C5V4JfBZA?pwd=dhc6 提取码: dhc6）",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>金融科技导论</span>"
    ]
  },
  {
    "objectID": "index.html#项目列表与要求",
    "href": "index.html#项目列表与要求",
    "title": "金融科技概论讲义（机器学习部分）",
    "section": "0.4 项目列表与要求",
    "text": "0.4 项目列表与要求\n\n项目列表与难度\n每个项目具体要求：\n\nCalifornia House Prices\nUCI Credit Card Default\nLendingClub Default Risk\nHome Credit Default Risk\nIEEE-CIS Fraud Detection\nG-Research Crypto Forecasting\n\n项目数据与模板请通过百度网盘获取（链接: https://pan.baidu.com/s/1DlM2Mt7gS_Jn2C5V4JfBZA?pwd=dhc6 提取码: dhc6）",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>金融科技导论</span>"
    ]
  },
  {
    "objectID": "index.html#技术栈",
    "href": "index.html#技术栈",
    "title": "金融科技概论讲义（机器学习部分）",
    "section": "0.5 技术栈",
    "text": "0.5 技术栈\n\n编程语言：Python 3.10+\n核心库：pandas, numpy, scikit-learn, matplotlib, seaborn\n深度学习：TensorFlow/Keras\n开发环境：VS Code + Jupyter Notebook\n版本控制：Git + GitHub",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>金融科技导论</span>"
    ]
  },
  {
    "objectID": "index.html#学习建议",
    "href": "index.html#学习建议",
    "title": "金融科技概论讲义（机器学习部分）",
    "section": "0.6 学习建议",
    "text": "0.6 学习建议\n\n理论实践结合：每章理论后都有对应的上机练习\n项目驱动学习：通过实际项目巩固知识\n逐步深入：从简单概念开始，逐渐过渡到复杂算法\n多练多想：编程是实践技能，需要大量练习",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>金融科技导论</span>"
    ]
  },
  {
    "objectID": "index.html#联系方式",
    "href": "index.html#联系方式",
    "title": "金融科技概论讲义（机器学习部分）",
    "section": "0.7 联系方式",
    "text": "0.7 联系方式\n\n课程群：随时线上问答\nOffice Hour：周二、周三上午（需预约）\n邮箱：xqwang@suibe.edu.cn\n\n\n\n记住：机器学习不是魔法，而是从数据中学习规律的工具。理解原理比记住公式更重要！\n\n祝学习愉快！🚀",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>金融科技导论</span>"
    ]
  },
  {
    "objectID": "w0_syllabus.html",
    "href": "w0_syllabus.html",
    "title": "2  课程安排与考核要求",
    "section": "",
    "text": "2.1 课程基本信息",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>课程安排与考核要求</span>"
    ]
  },
  {
    "objectID": "w0_syllabus.html#课程基本信息",
    "href": "w0_syllabus.html#课程基本信息",
    "title": "2  课程安排与考核要求",
    "section": "",
    "text": "课程性质：本科二年级课程，面向零编程基础学生\n教学模式：渐进式实践优先，理论+上机结合\n总课时：7 周 × 2 学时/周 = 14 学时（每周约 40 分钟理论 + 40 分钟上机）\n教学目标：掌握机器学习基本概念、Python编程、数据分析技能",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>课程安排与考核要求</span>"
    ]
  },
  {
    "objectID": "w0_syllabus.html#教学周次安排",
    "href": "w0_syllabus.html#教学周次安排",
    "title": "2  课程安排与考核要求",
    "section": "2.2 教学周次安排",
    "text": "2.2 教学周次安排\n\n2.2.1 W1｜Python 基础 + 回归问题入门\n理论部分\n\n机器学习是什么：预测问题、监督学习流程概览\n回归问题：线性回归直觉（拟合一条线）\n训练集/测试集、过拟合/欠拟合概念\n\n上机部分\n\n安装 Python 3.10 + VS Code + Jupyter Notebook\nPython 速成：变量、列表、函数调用\n运行第一个机器学习程序（线性回归）\n\n\n\n2.2.2 W2｜数据处理与线性回归实践\n理论部分\n\n数据预处理：缺失值、异常值、归一化\n回归模型评估指标：MAE、RMSE\n数据可视化的重要性\n\n上机部分\n\npandas 读数据探索、可视化\n线性回归模型训练与评估\n残差分析\n\n\n\n2.2.3 W3｜线性回归的正则化：Ridge, Lasso 与 Elastic Net\n理论部分\n\n过拟合与欠拟合回顾：训练集 vs 测试集表现\n正则化线性回归：Ridge（L2）、Lasso（L1）、Elastic Net\n正则化参数 α 的选择：交叉验证概念\n\n上机部分\n\n用 sklearn 实现 Ridge/Lasso/Elastic Net\n调参实验：不同 α 值观察系数变化\n正则化路径图、残差图可视化\n特征重要性分析（Lasso 稀疏性）\n\nW3 项目立项验收（第四讲前提交）\n\n\n2.2.4 W4｜分类问题、决策树与评估指标\n理论部分\n\n分类 vs. 回归：预测类别而非数值\n决策树原理（用流程图展示，不讲数学）\n评估指标体系：混淆矩阵、准确率/召回率/精确率/F1、ROC/AUC\n类别不平衡问题\n\n上机部分\n\nTitanic 数据集：加载、探索、处理类别变量\n决策树分类器训练（sklearn 模板）\n评估可视化：混淆矩阵、ROC 曲线、AUC 计算\n分类阈值调整观察精确率/召回率变化\n\n\n\n2.2.5 W5｜集成学习：随机森林与 GBDT\n理论部分\n\n决策树局限：过拟合问题\n集成学习思想：Bagging（随机森林）vs Boosting（GBDT）\n关键超参数：树深度、树数量、学习率、特征采样\n\n上机部分\n\n随机森林：训练对比决策树 + 特征重要性可视化\nGBDT：LightGBM 实现 + 超参数调整\n三模型对比：AUC、训练时间\n\n\n\n2.2.6 W6｜神经网络基础\n理论部分\n\n神经网络是什么：神经元模型、多层感知机（MLP）\n激活函数：ReLU、Sigmoid、Tanh\n前向传播与反向传播概念\n优化器：SGD、Adam\n何时用树模型 vs MLP\n\n上机部分\n\nKeras 快速入门：Sequential 模型搭建\n第一个 MLP（Titanic）：数据预处理（归一化、one-hot）\n训练可视化：loss/accuracy 曲线 + 测试集 AUC\n\n\n\n2.2.7 W7｜项目答辩\n答辩形式\n\n每组 8 分钟展示 + 4 分钟提问\n提交：6–8 页报告 + 答辩 PDF + 项目仓库（详见教学资源）\n\n验收标准\n\n能用简单脚本完整跑通实验\n有清晰的结果展示：至少 2 种模型对比、评估指标表格、2-3 张关键图\nREADME 包含：问题描述、数据说明、复现步骤、结果总结",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>课程安排与考核要求</span>"
    ]
  },
  {
    "objectID": "w0_syllabus.html#考核要求",
    "href": "w0_syllabus.html#考核要求",
    "title": "2  课程安排与考核要求",
    "section": "2.3 考核要求",
    "text": "2.3 考核要求\n\n2.3.1 必修课总分构成（50 分制）\n\n\n\n\n\n\n\n\n项目\n权重\n说明\n\n\n\n\n机器学习项目\n20分\nW3立项+ W7 项目答辩\n\n\n期末考试\n25分\n选择 + 判断 + 论述 + 案例分析（涵盖 W1-W6 理论知识）\n\n\n课堂参与\n5分\n出勤（随机点名）\n\n\n合计\n50分\n\n\n\n\n\n\n2.3.2 选修课总分构成（50 分制）\n\n\n\n项目\n权重\n说明\n\n\n\n\n机器学习项目\n30分\nW3立项 + W7 项目答辩\n\n\n课堂Quiz\n15分\n三次课堂小测（在W3、W5与W7上课时进行）\n\n\n课堂参与\n5分\n出勤（随机点名）\n\n\n合计\n50分",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>课程安排与考核要求</span>"
    ]
  },
  {
    "objectID": "w0_syllabus.html#机器学习项目池",
    "href": "w0_syllabus.html#机器学习项目池",
    "title": "2  课程安排与考核要求",
    "section": "2.4 机器学习项目池",
    "text": "2.4 机器学习项目池\n难度系数决定最终评分加成\n\n2.4.1 入门级（难度系数 0.9）\n\n房价预测（California House Prices）：回归问题，特征较少，提供数据清洗模板\n信用卡违约预测（UCI Credit Card Default）：分类问题，数据集小，特征清晰\n\n\n\n2.4.2 进阶级（难度系数 1.0）\n\nLendingClub Default Risk：评估 AUC、剔除泄露字段\nHome Credit Default Risk：评估 AUC，可合并外部表\n\n\n\n2.4.3 挑战级（难度系数 1.1，需要一定编程基础）\n\nIEEE-CIS Fraud Detection：极不平衡、严格时序、多表合并\nG-Research Crypto Forecasting：回归/排序、多币种、时间序列",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>课程安排与考核要求</span>"
    ]
  },
  {
    "objectID": "w0_syllabus.html#项目最低交付标准",
    "href": "w0_syllabus.html#项目最低交付标准",
    "title": "2  课程安排与考核要求",
    "section": "2.5 项目最低交付标准",
    "text": "2.5 项目最低交付标准\n\n2.5.1 W3 验收（第四周上课前提交到学习通/GitHub）\n\n项目仓库建立（包含相关文件夹）\nREADME 包含题目、数据来源、成员分工\n能在 Python程序脚本/Jupyter Notebook 中加载数据并展示基本统计信息\n至少一张数据可视化图\n\n\n\n2.5.2 W7 验收（答辩时）\n\n代码能运行：按照 README 步骤能复现结果\n结果齐全：\n\n至少对比 2 种模型\n评估指标表格（分类：准确率/召回率/AUC；回归：RMSE/MAE）\n2-3 张关键图（混淆矩阵/ROC 曲线/特征重要性/残差图）\n\n文档完整：\n\nREADME 有复现步骤\n报告有问题描述、方法、结果、分析\n\n\n\n\n2.5.3 项目评分\n\n基础分（60 分）：代码能跑 + 有结果 + 文档齐全\n质量分（30 分）：模型对比合理 + 分析有深度 + 可视化清晰\n难度加成（10 分）：原始分 × 难度系数（0.9-1.1）\n\n\n\n2.5.4 扣分项\n\n代码无法运行：无法手动运行Python程序脚本/Notebook，或运行结果与 README 不符\n数据泄露（未做训练/测试切分，或使用未来信息）\n结果造假：结果与 README 不符，或结果无法复现\n大段抄袭：代码/报告抄袭他人，或与他人代码/报告雷同\n\n\n\n2.5.5 不强制要求（鼓励加分）\n\n多做几种模型对比（如三个及以上模型）\n在代码中展示调参过程（如网格搜索等）\n模块化代码结构",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>课程安排与考核要求</span>"
    ]
  },
  {
    "objectID": "w0_syllabus.html#教学资源",
    "href": "w0_syllabus.html#教学资源",
    "title": "2  课程安排与考核要求",
    "section": "2.6 教学资源",
    "text": "2.6 教学资源\n\n教学资料：\n\n课程讲义（https://fintech-ml.netlify.app/）\n网上教材（https://ai-first-ml.netlify.app/）\n\nproject_list/：项目说明\nproject_root/：演示项目根目录\n\n项目仓库结构\nproject_root/\n  README.md                # 项目背景、分工、数据来源与口径摘要、运行命令\n  main.py                  # 单文件分工脚本\n  requirements.txt         # 依赖（pandas/numpy/scikit-learn 等）\n  data/\n    sample.csv             # 样本（数据不上传）\n    README.md              # 数据文件夹结构\n  outputs/\n    predictions.csv        # 模型输出样例（运行脚本可覆盖生成）\n  report.pdf  (或 .md)     # 6–8 页项目报告（请在结题时添加）\n  slides.pdf               # 6–8 页答辩幻灯（请在结题时添加）\n  ai_usage_log.md          # AI 使用记录（日期/工具/用途/采纳与否）\n  .gitignore               # 忽略大文件（保留示例数据与示例输出）",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>课程安排与考核要求</span>"
    ]
  },
  {
    "objectID": "w1_python_ml_intro.html",
    "href": "w1_python_ml_intro.html",
    "title": "3  开场：我们为什么要学机器学习？",
    "section": "",
    "text": "3.0.1 思考：这些场景有什么共同点？\ntitle: 第一讲：Python基础与机器学习入门",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>根据操作系统设置不同的字体</span>"
    ]
  },
  {
    "objectID": "w1_python_ml_intro.html#第一部分什么是机器学习",
    "href": "w1_python_ml_intro.html#第一部分什么是机器学习",
    "title": "3  开场：我们为什么要学机器学习？",
    "section": "3.1 第一部分：什么是机器学习？",
    "text": "3.1 第一部分：什么是机器学习？\n\n3.1.1 定义：机器学习的本质\n\n\n机器学习（Machine Learning）：\n让计算机通过数据和经验自动改进性能的技术\n举例：学习认猫（传统编程 vs 机器学习）\n核心要素：\n\n数据（猫的照片）\n算法（学习方法）\n模型（学到的规律）\n\n\n\n\n\n\n\nflowchart TB\n    A[输入规则：有四条腿、有胡须、会喵喵叫] --&gt; B[程序判断新图片]\n    B --&gt; C{符合这些特征吗？}\n    C --&gt;|是| D[判断为猫]\n    C --&gt;|否| E[不是猫]\n\n\n\n\n\n\n\n\n\n\n\n\nflowchart TB\n    A[看到很多猫的照片] --&gt; B[总结特征]\n    B --&gt; C[记住猫的样子]\n    C --&gt; D[看到新图片]\n    D --&gt; E{是猫吗?}\n\n\n\n\n\n\n\n\n\n\n3.1.2 为什么需要机器学习？维度诅咒\n\n3.1.2.1 维度诅咒（Curse of Dimensionality）\n问题： 随着特征维度增加，数据变得异常稀疏\n直观理解：\n\n想象一个边长为1米的正方形：撒200粒米，基本覆盖整个区域\n想象一个边长为1米的正方体：撒200粒米，只覆盖很小的角落\n现实中的机器学习：特征往往有10个、100个甚至1000个以上\n\n维度诅咒的后果：\n\n数据点之间距离变得很大\n传统的人工规则难以覆盖所有情况\n需要机器学习从数据中自动学习模式\n\n\n\n3.1.2.2 传统编程的困境\n在高维特征空间中，人工编写规则变得不可能\n金融场景例子：\n\n贷款审批：收入、信用分、负债率、年龄、工作年限、地区、婚姻状况、教育水平…（10+个特征）\n传统规则：IF 收入&gt;5000 AND 信用分&gt;700 AND 年龄&gt;25 AND 工作年限&gt;2 AND ...\n问题：特征之间的复杂交互关系，人工根本无法穷举！\n\n机器学习的优势：\n\n自动学习：从数据中自动发现特征间的复杂关系\n非线性模式：能处理特征间的非线性交互\n可扩展性：特征维度增加时，算法仍然有效\n\n\n\n\n3.1.3 机器学习 vs 传统编程\n\n\n\n\n\n\n\n\n维度\n传统编程\n机器学习\n\n\n\n\n输入\n规则 + 数据\n数据 + 答案\n\n\n输出\n答案\n规则（模型）\n\n\n适用场景\n规则明确（如计算器）\n规则复杂/未知（如人脸识别）\n\n\n优点\n逻辑清晰、可解释\n能处理复杂模式\n\n\n缺点\n难以处理复杂问题\n需要大量数据\n\n\n\n\n\n3.1.4 机器学习的分类\n\n\n\n\n\nflowchart TB\n    A[机器学习] --&gt; B[监督学习&lt;br/&gt;有标签]\n    A --&gt; C[无监督学习&lt;br/&gt;无标签]\n    A --&gt; D[强化学习&lt;br/&gt;奖励反馈]\n    \n    B --&gt; B1[分类&lt;br/&gt;预测类别]\n    B --&gt; B2[回归&lt;br/&gt;预测数值]\n    \n    C --&gt; C1[聚类&lt;br/&gt;分组]\n    C --&gt; C2[降维&lt;br/&gt;压缩]\n    \n    style B fill:#e1f5e1\n    style B1 fill:#fff4e1\n    style B2 fill:#fff4e1\n\n\n\n\n\n\n本课程重点：监督学习（因为金融领域90%的问题都是监督学习）\n\n\n3.1.5 大语言模型（LLM）与机器学习分类\n\n3.1.5.1 什么是大语言模型？\n大语言模型（Large Language Models）：如 GPT、Claude、DeepSeek 等\n核心特点：\n\n参数规模巨大：数十亿到数万亿参数\n预训练 + 微调：两阶段训练策略\n生成式AI：不仅能分类，还能生成文本\n\n\n\n3.1.5.2 LLM 在机器学习分类中的位置\n\n\n\n\n\nflowchart TB\n    A[机器学习] --&gt; B[监督学习&lt;br/&gt;有标签]\n    A --&gt; C[无监督学习&lt;br/&gt;无标签]\n    A --&gt; D[强化学习&lt;br/&gt;奖励反馈]\n\n    B --&gt; B1[传统任务]\n    B --&gt; B2[大语言模型&lt;br/&gt;LLM]\n\n    B1 --&gt; B11[分类&lt;br/&gt;房价预测]\n    B1 --&gt; B12[回归&lt;br/&gt;信用评分]\n\n    B2 --&gt; B21[文本生成]\n    B2 --&gt; B22[对话系统]\n    B2 --&gt; B23[代码编写]\n    B2 --&gt; B24[金融分析]\n\n    style B2 fill:#4caf50,color:#fff\n    style B21 fill:#81c784\n    style B22 fill:#81c784\n    style B23 fill:#81c784\n    style B24 fill:#81c784\n\n\n\n\n\n\nLLM 仍然属于监督学习！\n\n\n3.1.5.3 为什么 LLM 这么火？\n\n数据规模的突破\n\n传统机器学习：\n\n数据集：几千到几万个样本\n特征：几到几百个\n\n大语言模型：\n\n数据集：万亿级别的文本数据\n特征：数万亿个参数自动学习\n\n\n通用能力\n\n传统模型： 一个模型解决一个任务 - 房价预测模型 → 只能预测房价 - 垃圾邮件分类 → 只能分类邮件\nLLM： 一个模型解决多种任务 - 文本生成、翻译、编程、分析、创作…\n\n涌现能力（Emergent Abilities）\n\n小模型：能做简单任务 大模型：突然获得复杂能力（如数学推理、代码编写）\n\n\n3.1.5.4 LLM 与传统机器学习的区别\n\n\n\n\n\n\n\n\n\n传统机器学习\n大语言模型\n\n\n\n\n数据类型\n结构化数据（表格、数值）\n非结构化数据（文本、语言）\n\n\n特征工程\n人工设计特征\n自动学习特征\n\n\n模型复杂度\n相对简单\n极其复杂\n\n\n训练成本\n几小时到几天\n几周到几个月\n\n\n应用场景\n预测、分类\n生成、理解、对话\n\n\n可解释性\n较高\n较低\n\n\n\n\n\n3.1.5.5 LLM 在金融领域的应用\n\n智能客服与对话\n\n\n自动回答客户问题\n处理投诉和咨询\n24小时在线服务\n\n\n金融文本分析\n\n\n自动阅读研报、新闻\n生成投资摘要\n情感分析（市场情绪）\n\n\n风险评估\n\n\n分析企业财报文本\n理解合同条款\n识别潜在风险\n\n\n量化投资\n\n\n生成交易策略代码\n分析市场趋势\n自动化报告生成\n\n未来展望： LLM 将成为金融从业者的”智能助手”\n\n\n\n3.1.6 机器学习的技术演进\n\n\n\n\n\ntimeline\n    1950s : 人工智能诞生\n    1980s : 神经网络复兴\n    1990s : 支持向量机流行\n    2000s : 随机森林、梯度提升\n    2010s : 深度学习突破\n    2020s : 大语言模型时代\n    未来 : 多模态AI、通用人工智能\n\n\n\n\n\n\n我们正处于 AI 发展的激动人心的时刻！",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>根据操作系统设置不同的字体</span>"
    ]
  },
  {
    "objectID": "w1_python_ml_intro.html#第二部分监督学习详解",
    "href": "w1_python_ml_intro.html#第二部分监督学习详解",
    "title": "3  开场：我们为什么要学机器学习？",
    "section": "3.2 第二部分：监督学习详解",
    "text": "3.2 第二部分：监督学习详解\n\n3.2.1 什么是监督学习？\n定义： 从带标签的数据中学习，预测新数据的标签\n类比：有答案的练习题\n\n老师给你100道数学题和答案\n你通过练习学会解题方法\n考试时遇到新题，能用学到的方法求解\n\n\n\n3.2.2 监督学习的完整流程\n\n\n\n\n\nflowchart LR\n    A[收集历史数据] --&gt; B[数据预处理&lt;br/&gt;清洗/转换]\n    B --&gt; C[特征工程&lt;br/&gt;选择有用信息]\n    C --&gt; D[切分数据&lt;br/&gt;训练集+测试集]\n    D --&gt; E[选择算法&lt;br/&gt;如线性回归]\n    E --&gt; F[训练模型&lt;br/&gt;学习规律]\n    F --&gt; G[评估模型&lt;br/&gt;测试集上验证]\n    G --&gt; H{效果好?}\n    H --&gt;|否| E\n    H --&gt;|是| I[部署应用&lt;br/&gt;预测新数据]\n    \n    style D fill:#ffe1e1\n    style F fill:#e1f5e1\n    style G fill:#e1e5ff\n\n\n\n\n\n\n\n\n3.2.3 核心概念1：特征（Features）\n特征 = 用来预测的信息 = 输入变量 = X\n房价预测例子：\n\n\n\n\n\n\n\n\n\n特征1面积(m²)\n特征2房龄(年)\n特征3地铁距离(km)\n标签价格(万元)\n\n\n\n\n50\n5\n0.5\n200\n\n\n80\n10\n2.0\n250\n\n\n120\n2\n0.3\n500\n\n\n\n特征选择的重要性：\n\n好特征：与目标强相关（如面积与房价）\n差特征：无关信息（如房主姓氏）\n特征工程：创造新特征（如 面积/房间数 = 人均面积）\n\n\n\n3.2.4 核心概念2：标签（Label）\n标签 = 我们要预测的目标 = 输出变量 = y\n两种类型：\n\n\n连续数值（回归问题）\n\n房价：150万、200万、350万…\n温度：25.3°C、18.7°C…\n股票价格：105.3元、98.6元…\n特点： 可以取任意值\n\n\n离散类别（分类问题）\n\n是否违约：是/否\n垃圾邮件：是/否\n疾病类型：感冒/肺炎/健康\n特点： 有限的几个类别\n\n\n\n本周重点：回归问题（预测数值）\n\n\n3.2.5 核心概念3：模型（Model）\n模型 = 学到的规律 = 从X到y的映射函数\n数学表达：\n\\[\ny = f(X)\n\\]\n具体例子（线性模型）：\n\\[\n\\text{房价} = 3 \\times \\text{面积} + (-2) \\times \\text{房龄} + 50\n\\]\n\n系数3：面积每增加1m²，房价增加3万\n系数-2：房龄每增加1年，房价减少2万\n常数50：基础价格50万\n\n\n\n3.2.6 训练（Training）= 让模型学习\n目标： 找到最好的参数（系数），使得预测尽可能准确\n\n\n\n\n\n训练过程：不断调整参数，减小误差",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>根据操作系统设置不同的字体</span>"
    ]
  },
  {
    "objectID": "w1_python_ml_intro.html#第三部分分类-vs-回归",
    "href": "w1_python_ml_intro.html#第三部分分类-vs-回归",
    "title": "3  开场：我们为什么要学机器学习？",
    "section": "3.3 第三部分：分类 vs 回归",
    "text": "3.3 第三部分：分类 vs 回归\n\n3.3.1 回归问题：预测连续数值\n定义： 输出是一个数字，可以取任意值\n金融场景例子：\n\n预测房价 → 230.5万元\n预测股票收盘价 → 105.23元\n预测客户未来一年消费金额 → 18,350元\n预测贷款违约损失金额 → 35,000元\n\n特点：\n\n输出是连续的\n关心预测值与真实值的距离\n评估指标：MAE、RMSE（下周详讲）\n\n\n\n3.3.2 分类问题：预测离散类别\n定义： 输出是一个类别标签\n金融场景例子：\n\n\n二分类（2个类别）\n\n客户是否会违约？→ 是/否\n这笔交易是否欺诈？→ 是/否\n客户是否会流失？→ 是/否\n股票明天涨还是跌？→ 涨/跌\n\n\n多分类（&gt;2个类别）\n\n信用评级 → A/B/C/D\n行业分类 → 金融/科技/制造/…\n风险等级 → 高/中/低\n客户细分 → 年轻白领/中年家庭/…\n\n\n\n特点：\n\n输出是离散的\n关心是否分对了类\n评估指标：准确率、AUC（第三周详讲）\n\n\n\n3.3.3 快速判断：分类还是回归？\n看输出类型！\n\n\n\n问题\n输出\n类型\n原因\n\n\n\n\n预测明天气温\n25.3°C\n回归\n连续数值\n\n\n判断肿瘤良恶性\n良性/恶性\n分类\n2个类别\n\n\n预测客户消费金额\n1,250元\n回归\n连续数值\n\n\n手写数字识别\n0,1,2…9\n分类\n10个类别\n\n\n预测股票明天收盘价\n106.8元\n回归\n连续数值\n\n\n推荐系统（买/不买）\n买/不买\n分类\n2个类别",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>根据操作系统设置不同的字体</span>"
    ]
  },
  {
    "objectID": "w1_python_ml_intro.html#第四部分线性回归入门",
    "href": "w1_python_ml_intro.html#第四部分线性回归入门",
    "title": "3  开场：我们为什么要学机器学习？",
    "section": "3.4 第四部分：线性回归入门",
    "text": "3.4 第四部分：线性回归入门\n\n3.4.1 最简单的例子：一维线性回归\n问题： 已知房屋面积，预测房价\n数学模型：\n\\[\ny = w \\times x + b\n\\]\n\n\\(x\\)：面积（输入）\n\\(y\\)：房价（输出）\n\\(w\\)：斜率（每平米的价格）\n\\(b\\)：截距（基础价格）\n\n几何意义： 在二维平面上画一条直线\n\n\n3.4.2 可视化理解线性回归\n\n\n\n\n\n线性回归：找到最合适的一条直线\n\n\n\n\n学到的参数：斜率 w = 2.70，截距 b = 88.91\n解释：面积每增加1m²，房价增加2.70万元\n\n\n\n\n3.4.3 训练目标：最小化误差\n误差 = 真实值 - 预测值\n\n\n\n面积\n真实房价\n预测房价\n误差\n\n\n\n\n50\n200\n205\n-5\n\n\n80\n290\n285\n+5\n\n\n100\n350\n353\n-3\n\n\n\n目标函数（损失函数）：\n\\[\n\\text{Loss} = \\frac{1}{n}\\sum_{i=1}^n (\\text{真实值}_i - \\text{预测值}_i)^2\n\\]\n算法会自动找到使Loss最小的w和b\n\n\n3.4.4 多维线性回归\n现实中通常有多个特征：\n\\[\n\\text{房价} = w_1 \\times \\text{面积} + w_2 \\times \\text{房龄} + w_3 \\times \\text{地铁距离} + b\n\\]\n例子：\n\\[\n\\text{房价} = 3 \\times 100 + (-2) \\times 5 + (-10) \\times 0.5 + 50 = 335 \\text{万元}\n\\]\n\n100m²，贡献 +300万\n5年房龄，贡献 -10万\n距地铁0.5km，贡献 -5万\n基础价格 +50万\n总计：335万",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>根据操作系统设置不同的字体</span>"
    ]
  },
  {
    "objectID": "w1_python_ml_intro.html#第五部分训练集与测试集",
    "href": "w1_python_ml_intro.html#第五部分训练集与测试集",
    "title": "3  开场：我们为什么要学机器学习？",
    "section": "3.5 第五部分：训练集与测试集",
    "text": "3.5 第五部分：训练集与测试集\n\n3.5.1 为什么要切分数据？\n问题场景：\n你用100道题训练了一个模型，在这100道题上准确率100%。\n能说明什么？\n\n❌ 不能说明模型很好\n✅ 只能说明模型”记住”了这100道题\n\n真正的考验： 遇到新题目能不能做对？\n\n\n3.5.2 类比：练习题 vs 考试题\n\n\n训练集（练习题）\n\n有答案的历史数据\n用来学习规律\n允许反复看、反复练\n目标： 学到通用规律\n\n\n测试集（考试题）\n\n模型从未见过的数据\n用来评估真实性能\n只能用一次\n目标： 检验泛化能力\n\n\n\n核心原则： 训练集和测试集必须严格分开，测试集不能参与任何训练过程\n\n\n3.5.3 数据切分流程\n\n\n\n\n\nflowchart TB\n    A[全部数据 1000条] --&gt; B{随机切分}\n    B --&gt;|80%| C[训练集&lt;br/&gt;800条]\n    B --&gt;|20%| D[测试集&lt;br/&gt;200条]\n    C --&gt; E[训练模型&lt;br/&gt;学习规律]\n    E --&gt; F[得到模型]\n    D --&gt; G[评估模型&lt;br/&gt;计算准确率]\n    F --&gt; G\n    G --&gt; H[测试集准确率&lt;br/&gt;= 真实性能]\n    \n    style C fill:#e1f5e1\n    style D fill:#ffe1e1\n    style H fill:#e1e5ff\n\n\n\n\n\n\n常见比例：\n\n数据多（&gt;10万）：90% 训练 + 10% 测试\n数据中（1万-10万）：80% 训练 + 20% 测试\n数据少（&lt;1万）：70% 训练 + 30% 测试，或使用交叉验证\n\n\n\n3.5.4 代码演示：数据切分\n\n\n代码\nfrom sklearn.model_selection import train_test_split\nimport numpy as np\n\n# 假设有100个样本\nX = np.arange(100).reshape(-1, 1)  # 特征\ny = np.arange(100)  # 标签\n\n# 切分：80%训练，20%测试\nX_train, X_test, y_train, y_test = train_test_split(\n    X, y, test_size=0.2, random_state=42)\n\nprint(f\"训练集大小：{len(X_train)} 个样本\")\nprint(f\"测试集大小：{len(X_test)} 个样本\")\nprint(f\"\\n训练集的前5个样本索引：{y_train[:5]}\")\nprint(f\"测试集的前5个样本索引：{y_test[:5]}\")\n\n\n训练集大小：80 个样本\n测试集大小：20 个样本\n\n训练集的前5个样本索引：[55 88 26 42 69]\n测试集的前5个样本索引：[83 53 70 45 44]\n\n\n注意： random_state=42 保证每次切分结果相同（可复现）",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>根据操作系统设置不同的字体</span>"
    ]
  },
  {
    "objectID": "w1_python_ml_intro.html#第六部分过拟合与欠拟合",
    "href": "w1_python_ml_intro.html#第六部分过拟合与欠拟合",
    "title": "3  开场：我们为什么要学机器学习？",
    "section": "3.6 第六部分：过拟合与欠拟合",
    "text": "3.6 第六部分：过拟合与欠拟合\n\n3.6.1 核心问题：模型的复杂度\n太简单 → 欠拟合（Underfitting）\n太复杂 → 过拟合（Overfitting）\n刚刚好 → 泛化能力强\n\n\n3.6.2 欠拟合：模型太简单\n现象： 训练集和测试集表现都差\n原因： 模型能力不足，无法捕捉数据规律\n\n\n\n\n\n欠拟合例子：强行用直线拟合曲线数据\n\n\n\n\n训练集误差：大\n测试集误差：大\n结论：模型能力不足\n\n\n\n\n3.6.3 过拟合：模型太复杂\n现象： 训练集表现很好，测试集表现很差\n原因： 模型把噪声当成规律，失去泛化能力\n\n\n\n\n\n过拟合例子：用高阶多项式拟合带噪声的数据\n\n\n\n\n训练集误差：非常小（几乎为0）\n测试集误差：非常大（曲线在训练点之外剧烈波动）\n结论：模型记住了噪声，不能泛化\n\n\n\n\n3.6.4 恰到好处：良好的泛化能力\n\n\n\n\n\n对比三种情况\n\n\n\n\n\n\n3.6.5 如何判断过拟合？\n关键指标：训练集误差 vs 测试集误差\n\n\n\n情况\n训练集误差\n测试集误差\n诊断\n解决方法\n\n\n\n\n欠拟合\n大\n大\n模型太简单\n增加特征使用更复杂模型\n\n\n正常\n中\n中\n刚刚好\n保持\n\n\n过拟合\n小\n大\n模型太复杂\n正则化减少特征增加数据\n\n\n\n经验法则： 测试集误差比训练集误差大一点是正常的，但不应该大很多\n\n\n3.6.6 类比：背题 vs 理解原理\n\n\n欠拟合\n\n完全没学\n练习题不会\n考试题也不会\n问题： 学习不够\n\n\n刚刚好\n\n理解了原理\n练习题大部分会\n考试题也大部分会\n目标状态\n\n\n过拟合\n\n死记硬背答案\n练习题100%正确\n考试题换个数字就不会\n问题： 没有泛化",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>根据操作系统设置不同的字体</span>"
    ]
  },
  {
    "objectID": "w1_python_ml_intro.html#第七部分完整的机器学习流程",
    "href": "w1_python_ml_intro.html#第七部分完整的机器学习流程",
    "title": "3  开场：我们为什么要学机器学习？",
    "section": "3.7 第七部分：完整的机器学习流程",
    "text": "3.7 第七部分：完整的机器学习流程\n\n3.7.1 端到端的完整流程\n\n\n\n\n\nflowchart TD\n    A[\"明确问题&lt;br&gt;预测房价/分类客户/...\"] --&gt; B[\"收集数据&lt;br&gt;历史交易/用户行为/...\"]\n    B --&gt; C[\"数据探索&lt;br&gt;可视化/统计分析\"]\n    C --&gt; D[\"数据清洗&lt;br&gt;处理缺失值/异常值\"]\n    D --&gt; E[\"特征工程&lt;br&gt;选择/创造有用特征\"]\n    E --&gt; F[\"切分数据&lt;br&gt;训练集/测试集\"]\n    F --&gt; G[\"选择模型&lt;br&gt;线性回归/决策树/...\"]\n    G --&gt; H[\"训练模型&lt;br&gt;学习参数\"]\n    H --&gt; I[\"评估模型&lt;br&gt;计算误差\"]\n    I --&gt; J{效果满意?}\n    J --&gt;|否| K[\"调整模型/特征/参数\"]\n    K --&gt; G\n    J --&gt;|是| L[\"部署上线&lt;br&gt;实际应用\"]\n\n    style F fill:#ffe1e1\n    style H fill:#e1f5e1\n    style I fill:#e1e5ff\n    style L fill:#fff9e1\n\n\n\n\n\n\n\n\n3.7.2 第一个完整例子：房价预测\n\n\n代码\n# 1. 导入库\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.model_selection import train_test_split\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n# 2. 准备数据（实际中从CSV读取）\nareas = np.array([50, 60, 70, 80, 90, 100, 110, 120, 130, 140])\nprices = 3*areas + 50 + np.random.randn(10)*10\n\n# 3. 切分数据\nX_train, X_test, y_train, y_test = train_test_split(\n    areas.reshape(-1,1), prices, test_size=0.3, random_state=42)\n\n# 4. 创建并训练模型\nmodel = LinearRegression()\nmodel.fit(X_train, y_train)\n\n# 5. 预测和评估\ny_pred = model.predict(X_test)\nfrom sklearn.metrics import mean_absolute_error\nmae = mean_absolute_error(y_test, y_pred)\n\nprint(f\"学到的参数：w={model.coef_[0]:.2f}, b={model.intercept_:.2f}\")\nprint(f\"测试集平均误差：{mae:.2f}万元\")\n\n\n学到的参数：w=3.15, b=31.83\n测试集平均误差：8.16万元\n\n\n\n\n3.7.3 可视化预测结果",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>根据操作系统设置不同的字体</span>"
    ]
  },
  {
    "objectID": "w1_python_ml_intro.html#总结",
    "href": "w1_python_ml_intro.html#总结",
    "title": "3  开场：我们为什么要学机器学习？",
    "section": "3.8 总结",
    "text": "3.8 总结\n\n3.8.1 本讲核心知识点\n\n\n概念理解\n\n机器学习 = 从数据中学习规律\n监督学习 = 从带标签数据学习\n特征(X) + 标签(y) + 模型(f)\n分类（类别） vs 回归（数值）\n线性回归：y = wx + b\n\n\n实践技能\n\n切分训练集/测试集\n训练线性回归模型\n理解过拟合/欠拟合\n评估模型性能\nPython基础操作\n\n\n\n关键原则：\n\n训练集与测试集严格分离\n关注模型的泛化能力，不只看训练集\n模型复杂度要适中，避免过拟合",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>根据操作系统设置不同的字体</span>"
    ]
  },
  {
    "objectID": "w1_python_ml_intro.html#qa",
    "href": "w1_python_ml_intro.html#qa",
    "title": "3  开场：我们为什么要学机器学习？",
    "section": "3.9 Q&A",
    "text": "3.9 Q&A\nQ1：什么是机器学习？它和传统编程在输入和输出上有何根本区别？\nA： 机器学习是让计算机通过数据和经验自动改进性能的技术。\n它们根本的区别在于逻辑的来源：\n\n传统编程：输入是 规则 + 数据 \\(\\rightarrow\\) 输出是 答案。程序员需要手动定义所有规则。\n机器学习：输入是 数据 + 答案（标签） \\(\\rightarrow\\) 输出是 规则（模型）。机器自动从数据中学习规律。\n\nQ2：什么是监督学习？请举一个金融领域的例子，并说明它的“特征”和“标签”分别是什么。\nA： 监督学习是一种机器学习方法，机器通过学习带有“标签”（即正确答案）的数据集来建立模型。\n\n金融例子：银行的信用卡违约预测。\n特征 (X)：用来预测的信息，例如客户的年龄、收入、历史信用分、负债率等。\n标签 (y)：我们要预测的目标，例如该客户“是否会违约”（是/否）。\n\nQ3：如何快速区分“分类”问题和“回归”问题？请判断以下两个任务分别属于哪一类：\n\n预测某只股票明天是“涨”还是“跌”。\n预测某只股票明天的“收盘价”（例如105.3元）。\n\nA：\n区分的关键在于看预测的输出（标签）是离散类别还是连续数值。\n\n预测“涨”还是“跌”：输出是两个固定的类别，属于分类问题。\n预测“收盘价”：输出是一个具体的、连续的数字（可以是105.3, 105.4等任意值），属于回归问题。\n\nQ4：为什么我们需要将数据分为训练集和测试集？\nA：\n因为我们真正关心的是模型在“从未见过的新数据”上的表现，这被称为模型的泛化能力。\n\n训练集（练习题）用于训练模型学习规律。\n测试集（考试题）用于评估模型的泛化能力。 如果只看模型在训练集上的表现，可能会高估模型的性能，因为模型可能只是“死记硬背”了训练数据（即过拟合），而不是真正学会了规律。\n\nQ5：假设你训练了一个模型，发现“训练集误差”很高，“测试集误差”也很高，且两者接近。这最可能是什么问题？你应该采取什么措施？\nA： 这最可能是欠拟合（Underfitting）。\n\n诊断：“训练集误差”很高，说明模型过于简单，连训练数据本身的规律都没有学到。\n措施：应该增加模型的复杂度。例如：\n\n使用更复杂的模型（例如，如果用直线拟合曲线数据，就属于欠拟合）。\n增加更多有用的特征（即特征工程）。\n\n\nQ6：假设你训练了另一个模型，发现“训练集误差”极低，但“测试集误差”却非常高。这最可能是什么问题？这揭示了模型在“泛化能力”上的什么缺陷？\nA： 这最可能是过拟合（Overfitting）。\n\n缺陷： 这说明模型“泛化能力”很差。模型过于复杂，以至于它不仅仅学习了数据中的普遍规律，还把训练集中的噪声和偶然特征当作了真实规律去“死记硬背”。\n表现： 因此，它在熟悉的“练习题”（训练集）上表现完美（误差极低），但在遇到“考试题”（测试集）时，由于新数据的规律或噪声分布不同，模型学到的错误规律就会导致预测表现非常差（误差非常高）。\n\nQ7：在多元线性回归模型 \\(\\text{房价} = w_1 \\times \\text{面积} + w_2 \\times \\text{房龄} + b\\) 中，我们训练得到的系数 \\(w_2 = -5\\)。请问这个 \\(w_2 = -5\\) 的具体业务含义是什么？\nA：\n\\(w_2 = -5\\) 的具体含义是：在保持其他所有特征（例如“面积”）不变的情况下，“房龄”（\\(x_2\\)）每增加1个单位（例如1年），“房价”（\\(y\\)）平均减少 5 个单位（例如5万元）。\nQ8：在完整的机器学习流程中，为什么“数据切分”这一步，必须在“数据预处理”（例如下周要学的“归一化”）之前进行？如果顺序反了（即先对所有数据做归一化，再切分），会导致什么严重后果？\nA：\n这是为了防止“数据泄露”（Data Leakage）。\n\n后果：假设“归一化”操作是减去均值。如果先对1000条数据求均值，然后再切分为800条训练集和200条测试集。这意味着，训练集在训练时，已经“偷看”到了测试集的均值信息。\n影响：这违反了“测试集必须是模型从未见过的数据”这一核心原则。这会导致模型在测试集上的评估结果过于乐观（分数虚高），而无法代表模型在未来真实新数据上的表现。\n正确做法：1. 先切分。 2. 只在训练集上计算均值。 3. 用这个均值去归一化训练集，并用同一个（来自训练集的）均值去归一化测试集。",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>根据操作系统设置不同的字体</span>"
    ]
  },
  {
    "objectID": "w2_data_processing.html",
    "href": "w2_data_processing.html",
    "title": "4  第二讲：数据处理与线性回归实践",
    "section": "",
    "text": "4.1 开场：为什么数据预处理如此重要？",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>第二讲：数据处理与线性回归实践</span>"
    ]
  },
  {
    "objectID": "w2_data_processing.html#开场为什么数据预处理如此重要",
    "href": "w2_data_processing.html#开场为什么数据预处理如此重要",
    "title": "4  第二讲：数据处理与线性回归实践",
    "section": "",
    "text": "4.1.1 一个真实的场景\n假设你收到这样一份数据…\n\n\n\n面积\n卧室数\n房龄\n价格\n\n\n\n\n100\n2\n5\n200\n\n\n120\n?\n8\n250\n\n\n-50\n3\n10\n150\n\n\n110\n2\n999\n280\n\n\n\n问题：\n\n第 2 行：卧室数缺失\n第 3 行：面积为负数（不合理）\n第 4 行：房龄 999 年（明显异常）\n\n能直接训练模型吗？\n\n❌ 不能！ 模型会学到错误的规律，或者直接报错。\n\n\n\n4.1.2 本周学习目标\n\n4.1.2.1 知识目标\n\n理解数据预处理的重要性（缺失值、异常值、归一化）\n掌握回归模型的评估指标（MAE、RMSE、R²）\n理解残差的概念及其诊断作用\n掌握数据可视化的基本原则\n\n\n\n4.1.2.2 技能目标\n\n使用 pandas 探索和清洗数据\n使用 matplotlib/seaborn 绘制多种图表\n训练完整的线性回归模型并评估\n进行残差分析\n\n\n\n4.1.2.3 核心理念\n“垃圾进，垃圾出”（Garbage In, Garbage Out）\n数据质量决定模型质量！",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>第二讲：数据处理与线性回归实践</span>"
    ]
  },
  {
    "objectID": "w2_data_processing.html#第一部分数据预处理",
    "href": "w2_data_processing.html#第一部分数据预处理",
    "title": "4  第二讲：数据处理与线性回归实践",
    "section": "4.2 第一部分：数据预处理",
    "text": "4.2 第一部分：数据预处理\n\n4.2.1 缺失值处理\n\n4.2.1.1 什么是缺失值？\n\n数据收集过程中未记录的值\n在 pandas 中显示为 NaN（Not a Number）\n例子：客户忘记填年龄、传感器故障\n\n\n\n4.2.1.2 🔍 缺失值处理的首要原则：理解业务逻辑\n业务理解优先于技术方法\n\n为什么缺失？ 分析缺失的根本原因\n隐形缺失：有些缺失并非数据错误，而是业务逻辑的一部分\n填补策略：优先基于业务逻辑，然后考虑统计方法\n\n\n\n4.2.1.3 📊 隐形缺失的经典案例\nR&D支出示例：\n公司R&D支出数据示例：\n\n\n\n公司名称\nR&D支出\n\n\n\n\n科技公司A\n1000\n\n\n传统公司B\nNaN\n\n\n创业公司C\n500\n\n\n\n\n业务逻辑分析：\n\n传统公司B没有R&D部门，所以R&D支出应为0，不是缺失值。\n错误填补： 如果用均值 (750) 填补，会高估传统公司实际水平。\n正确做法： 根据业务逻辑填补为0，更准确地反映现实业务情况。\n\n\n其他隐形缺失案例：\n\n学生成绩单中”实习经历”为空 → 可能从未实习，应填”无”\n电商数据中”退货原因”为空 → 可能未退货，应填”无退货”\n医疗数据中”家族遗传病史”为空 → 需要区分”未询问”vs”无家族史”\n\n\n\n4.2.1.4 缺失值处理决策流程\n\n\n\n\n\ngraph TD\n    A[发现缺失值] --&gt; B[理解业务逻辑&lt;br/&gt;为何缺失？]\n    B --&gt; C{是否为&lt;br/&gt;隐形缺失？}\n\n    C --&gt;|是| D[根据业务规则填补&lt;br/&gt;如R&D=0, 退货原因=无]\n    C --&gt;|否| E[检查缺失比例]\n\n    E --&gt;|很小 &lt;5%| F[删除法]\n    E --&gt;|中等 5-20%| G[统计填充法]\n    E --&gt;|较大 &gt;20%| H[高级方法或&lt;br/&gt;放弃特征]\n\n    D --&gt; I[验证业务合理性]\n    F --&gt; I\n    G --&gt; I\n    H --&gt; I\n\n    style D fill:#4caf50,color:#fff\n    style I fill:#2196f3,color:#fff\n\n\n\n\n\n\n\n\n4.2.1.5 删除法\n原始数据：[100, NaN, 120, 110, NaN]\n删除后：[100, 120, 110]\n优点： - 简单直接 - 不引入偏差\n缺点： - 丢失信息 - 样本量减少\n适用场景：缺失比例很小（&lt;5%）\n\n\n4.2.1.6 填充法\n常用填充值：\n\n\n\n特征类型\n推荐填充值\n原因\n\n\n\n\n连续型（如年龄）\n中位数\n不受极端值影响\n\n\n计数型（如卧室数）\n众数\n符合实际分布\n\n\n二元型（如性别）\n众数\n最常见类别\n\n\n\n示例：\n原始: [10, 20, NaN, 30, 100]\n均值填充: [10, 20, 32, 30, 100]  ← 受极端值影响\n中位数填充: [10, 20, 25, 30, 100]  ← 更稳健 ✓\n\n\n4.2.1.7 高级方法（简介）\n模型预测填充： - 用其他特征预测缺失值 - 例子：根据房屋面积、位置预测缺失的房龄 - 后续课程会学习\n多重插补： - 生成多个填充版本 - 综合结果 - 统计学高级方法\n\n\n\n4.2.2 异常值检测与处理\n\n4.2.2.1 什么是异常值？\n定义：明显偏离正常范围的数据点\n例子：\n\n房价数据中出现 1 元/平米（可能是录入错误）\n年龄数据中出现 999 岁（占位符未替换）\n收入数据中出现负值（除非是亏损）\n\n关键问题：异常值 ≠ 错误值\n\n亿万富翁买豪宅（真实但极端） → 保留\n录入错误（如 1 元/平米） → 删除/修正\n\n\n\n4.2.2.2 异常值识别：箱线图\n\n\n代码\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\n\nnp.random.seed(42)\n# 正常数据 + 几个异常值\nnormal_data = np.random.normal(100, 15, 100)\noutliers = np.array([50, 55, 180, 190])\nprice_data = np.concatenate([normal_data, outliers])\n\nplt.figure(figsize=(10, 6))\nplt.subplot(1, 2, 1)\nplt.boxplot(price_data, vert=True)\nplt.ylabel('房价 (万元)')\nplt.title('箱线图：异常值检测')\nplt.grid(True, alpha=0.3)\n\n# 标注关键位置\nQ1 = np.percentile(price_data, 25)\nQ3 = np.percentile(price_data, 75)\nIQR = Q3 - Q1\nlower_bound = Q1 - 1.5 * IQR\nupper_bound = Q3 + 1.5 * IQR\n\nplt.axhline(y=Q1, color='green', linestyle='--', alpha=0.5, label=f'Q1={Q1:.1f}')\nplt.axhline(y=Q3, color='blue', linestyle='--', alpha=0.5, label=f'Q3={Q3:.1f}')\nplt.axhline(y=lower_bound, color='red', linestyle='--', alpha=0.5, label=f'下界={lower_bound:.1f}')\nplt.axhline(y=upper_bound, color='red', linestyle='--', alpha=0.5, label=f'上界={upper_bound:.1f}')\nplt.legend(fontsize=8)\n\nplt.subplot(1, 2, 2)\nplt.hist(price_data, bins=20, edgecolor='black', alpha=0.7)\nplt.xlabel('房价 (万元)')\nplt.ylabel('频数')\nplt.title('直方图：数据分布')\nplt.axvline(x=lower_bound, color='red', linestyle='--', label='异常值边界')\nplt.axvline(x=upper_bound, color='red', linestyle='--')\nplt.legend()\nplt.grid(True, alpha=0.3)\n\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\n\n箱线图组成：\n\n箱体：Q1 到 Q3（中间 50% 数据）\n中线：中位数\n须：正常数据范围\n点：异常值\n\n\n\n4.2.2.3 异常值识别：统计方法\n1. IQR 方法（四分位距）\nQ1 = 25% 分位数\nQ3 = 75% 分位数\nIQR = Q3 - Q1\n下界 = Q1 - 1.5 × IQR\n上界 = Q3 + 1.5 × IQR\n\n异常值 = 低于下界 或 高于上界\n2. 3σ 原则\n异常值 = 超出 [均值 - 3×标准差, 均值 + 3×标准差]\n\n\n4.2.2.4 异常值处理决策\n\n\n\n\n\ngraph TD\n    A[发现异常值] --&gt; B{分析原因}\n    B --&gt; C{是否错误?}\n    C --&gt;|明确错误&lt;br/&gt;如负数面积| D[删除]\n    C --&gt;|不确定| E{业务判断}\n    C --&gt;|真实极端值&lt;br/&gt;如豪宅| F[保留]\n    \n    E --&gt;|影响大| D\n    E --&gt;|影响小| G[替换为边界值&lt;br/&gt;Winsorization]\n    E --&gt;|需要建模| F\n    \n    style D fill:#f44336,color:#fff\n    style F fill:#4caf50,color:#fff\n    style G fill:#ff9800,color:#fff\n\n\n\n\n\n\n关键原则：先分析，再处理！不要盲目删除！\n\n\n\n4.2.3 归一化（Normalization）\n\n4.2.3.1 为什么需要归一化？\n问题场景：\n\n\n\n特征\n范围\n单位\n\n\n\n\n面积\n50-200\n平米\n\n\n房龄\n0-50\n年\n\n\n票价\n10-5000\n元\n\n\n\n影响：\n\n某些模型（如神经网络、SVM）对特征尺度敏感\n大数值特征会主导梯度下降\n导致收敛慢或不收敛\n\n线性回归影响较小，但归一化仍有益\n\n\n4.2.3.2 两种常用归一化方法\n1. Min-Max 归一化（缩放到 [0, 1]）\n\\[\nx' = \\frac{x - \\min(x)}{\\max(x) - \\min(x)}\n\\]\n示例：[10, 20, 30] → [0, 0.5, 1]\n优点： - 保留原始分布形状 - 结果有界\n缺点： - 对异常值敏感\n2. Z-score 标准化（均值 0，标准差 1）\n\\[\nx' = \\frac{x - \\mu}{\\sigma}\n\\]\n示例：[10, 20, 30] → [-1, 0, 1]\n优点： - 不受异常值影响（相对） - 适合正态分布数据\n缺点： - 结果无界\n\n\n4.2.3.3 归一化前后对比\n\n\n代码\nfrom sklearn.preprocessing import MinMaxScaler, StandardScaler\n\n# 模拟三个特征\nnp.random.seed(42)\narea = np.random.uniform(50, 200, 100)    # 面积 50-200\nage = np.random.uniform(0, 50, 100)       # 房龄 0-50\nprice = np.random.uniform(100, 500, 100)  # 价格 100-500\n\n# 创建 DataFrame\ndata_orig = pd.DataFrame({\n    '面积': area,\n    '房龄': age,\n    '价格': price\n})\n\n# Min-Max 归一化\nscaler_minmax = MinMaxScaler()\ndata_minmax = pd.DataFrame(\n    scaler_minmax.fit_transform(data_orig),\n    columns=data_orig.columns\n)\n\n# Z-score 标准化\nscaler_std = StandardScaler()\ndata_std = pd.DataFrame(\n    scaler_std.fit_transform(data_orig),\n    columns=data_orig.columns\n)\n\n# 可视化\nfig, axes = plt.subplots(1, 3, figsize=(15, 5))\n\n# 原始数据\ndata_orig.boxplot(ax=axes[0])\naxes[0].set_title('原始数据')\naxes[0].set_ylabel('数值')\naxes[0].grid(True, alpha=0.3)\n\n# Min-Max\ndata_minmax.boxplot(ax=axes[1])\naxes[1].set_title('Min-Max 归一化 [0,1]')\naxes[1].set_ylabel('归一化值')\naxes[1].grid(True, alpha=0.3)\n\n# Z-score\ndata_std.boxplot(ax=axes[2])\naxes[2].set_title('Z-score 标准化 (μ=0, σ=1)')\naxes[2].set_ylabel('标准化值')\naxes[2].grid(True, alpha=0.3)\n\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\n4.2.3.4 何时使用哪种归一化？\n\n\n\n\n\n\n\n\n方法\n适用场景\n例子\n\n\n\n\nMin-Max\n数据分布均匀需要固定范围图像数据（0-255 → 0-1）\n神经网络输入层\n\n\nZ-score\n数据有异常值正态分布需要保留分布形状\n逻辑回归SVM\n\n\n不归一化\n树模型（决策树、随机森林、GBDT）\n线性回归影响小但建议归一化",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>第二讲：数据处理与线性回归实践</span>"
    ]
  },
  {
    "objectID": "w2_data_processing.html#第二部分回归模型评估",
    "href": "w2_data_processing.html#第二部分回归模型评估",
    "title": "4  第二讲：数据处理与线性回归实践",
    "section": "4.3 第二部分：回归模型评估",
    "text": "4.3 第二部分：回归模型评估\n\n4.3.1 残差（Residual）\n\n4.3.1.1 核心概念\n定义： \\[\n\\text{残差} = \\text{真实值} - \\text{预测值} = y - \\hat{y}\n\\]\n例子：\n\n\n\n样本\n真实价格\n预测价格\n残差\n\n\n\n\n1\n250\n240\n+10\n\n\n2\n200\n210\n-10\n\n\n3\n300\n295\n+5\n\n\n\n\n\n4.3.1.2 理想的残差\n\n\n代码\n# 模拟好的模型和差的模型\nnp.random.seed(42)\nX = np.linspace(0, 10, 100)\ny_true = 2*X + 3 + np.random.randn(100)*0.5\n\n# 好的模型\ny_pred_good = 2*X + 3\nresiduals_good = y_true - y_pred_good\n\n# 差的模型（欠拟合）\ny_pred_bad = 1.5*X + 2\nresiduals_bad = y_true - y_pred_bad\n\nfig, axes = plt.subplots(2, 2, figsize=(14, 10))\n\n# 好的模型：拟合图\naxes[0, 0].scatter(X, y_true, alpha=0.5, label='真实数据')\naxes[0, 0].plot(X, y_pred_good, 'r-', linewidth=2, label='拟合线')\naxes[0, 0].set_xlabel('特征 X')\naxes[0, 0].set_ylabel('目标 y')\naxes[0, 0].set_title('好的模型：拟合图')\naxes[0, 0].legend()\naxes[0, 0].grid(True, alpha=0.3)\n\n# 好的模型：残差图\naxes[0, 1].scatter(y_pred_good, residuals_good, alpha=0.5)\naxes[0, 1].axhline(y=0, color='red', linestyle='--', linewidth=2)\naxes[0, 1].set_xlabel('预测值')\naxes[0, 1].set_ylabel('残差')\naxes[0, 1].set_title('好的模型：残差随机分布 ✓')\naxes[0, 1].grid(True, alpha=0.3)\n\n# 差的模型：拟合图\naxes[1, 0].scatter(X, y_true, alpha=0.5, label='真实数据')\naxes[1, 0].plot(X, y_pred_bad, 'r-', linewidth=2, label='拟合线（欠拟合）')\naxes[1, 0].set_xlabel('特征 X')\naxes[1, 0].set_ylabel('目标 y')\naxes[1, 0].set_title('差的模型：拟合图')\naxes[1, 0].legend()\naxes[1, 0].grid(True, alpha=0.3)\n\n# 差的模型：残差图\naxes[1, 1].scatter(y_pred_bad, residuals_bad, alpha=0.5, color='orange')\naxes[1, 1].axhline(y=0, color='red', linestyle='--', linewidth=2)\naxes[1, 1].set_xlabel('预测值')\naxes[1, 1].set_ylabel('残差')\naxes[1, 1].set_title('差的模型：残差有趋势 ✗')\naxes[1, 1].grid(True, alpha=0.3)\n\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\n\n判断标准：\n\n✓ 好的残差图：点随机分布在 y=0 附近，无明显趋势\n✗ 差的残差图：有漏斗形、U 形、趋势线等规律\n\n\n\n\n4.3.2 MAE（平均绝对误差）\n\n4.3.2.1 定义\n\\[\n\\text{MAE} = \\frac{1}{n}\\sum_{i=1}^{n}|y_i - \\hat{y}_i|\n\\]\n直观理解：所有预测误差的绝对值的平均\n\n\n4.3.2.2 MAE 的优缺点\n优点：\n\n🎯 直观：单位与原数据相同\n🛡️ 稳健：对异常值不敏感\n📊 易解释：适合向业务人员汇报\n\n缺点：\n\n😐 不区分大小误差：误差 10 和误差 100 被同等对待\n\n适用场景：\n\n关注平均误差水平\n对所有误差一视同仁\n例子：房价预测、销量预测\n\n\n\n\n4.3.3 RMSE（均方根误差）\n\n4.3.3.1 定义\n\\[\n\\text{RMSE} = \\sqrt{\\frac{1}{n}\\sum_{i=1}^{n}(y_i - \\hat{y}_i)^2}\n\\]\n步骤：\n\n计算残差的平方\n求平均\n开根号\n\n\n\n4.3.3.2 MAE vs RMSE 对比\n\n\n代码\n# 对比两个场景\n# 场景1：误差均匀分布\nerrors_uniform = np.array([5, 5, 5, 5, 5])\n\n# 场景2：存在一个大误差\nerrors_outlier = np.array([1, 1, 1, 1, 21])\n\nmae_uniform = np.mean(np.abs(errors_uniform))\nrmse_uniform = np.sqrt(np.mean(errors_uniform**2))\n\nmae_outlier = np.mean(np.abs(errors_outlier))\nrmse_outlier = np.sqrt(np.mean(errors_outlier**2))\n\ncomparison_data = pd.DataFrame({\n    '场景': ['均匀误差', '存在大误差'],\n    '误差分布': ['[5,5,5,5,5]', '[1,1,1,1,21]'],\n    'MAE': [mae_uniform, mae_outlier],\n    'RMSE': [rmse_uniform, rmse_outlier],\n    'RMSE/MAE': [rmse_uniform/mae_uniform, rmse_outlier/mae_outlier]\n})\n\nprint(comparison_data.to_string(index=False))\n\n\n   场景         误差分布  MAE     RMSE  RMSE/MAE\n 均匀误差  [5,5,5,5,5]  5.0 5.000000  1.000000\n存在大误差 [1,1,1,1,21]  5.0 9.433981  1.886796\n\n\n观察：\n\n场景 1（均匀误差）：RMSE ≈ MAE\n场景 2（有大误差）：RMSE &gt;&gt; MAE（RMSE 对大误差更敏感）\n\n\n\n4.3.3.3 MAE vs RMSE 总结\n\n\n\n\n\n\n\n\n\n\n指标\n计算\n优点\n缺点\n何时使用\n\n\n\n\nMAE\n绝对值平均\n直观稳健\n不区分大小误差\n关注平均误差垃圾邮件分类\n\n\nRMSE\n平方平均开根\n惩罚大误差常用\n对异常值敏感\n大误差代价高医疗诊断金融风控\n\n\n\n选择建议：\n\n不确定 → 两个都算\n业务对大误差敏感 → RMSE\n只关心平均水平 → MAE\n\n\n\n\n4.3.4 R² 决定系数\n\n4.3.4.1 定义\n\\[\nR^2 = 1 - \\frac{SS_{res}}{SS_{tot}} = 1 - \\frac{\\sum(y_i - \\hat{y}_i)^2}{\\sum(y_i - \\bar{y})^2}\n\\]\n直观理解：模型解释了多少变异\n\n\\(SS_{res}\\)：残差平方和（模型的误差）\n\\(SS_{tot}\\)：总平方和（数据的总变异）\n\n\n\n4.3.4.2 R² 的含义\n取值范围：\n\nR² = 1：完美预测\nR² = 0.8：模型解释了 80% 的变异\nR² = 0：模型等同于预测平均值\nR² &lt; 0：模型比预测平均值还差（很糟糕）\n\n\n\n代码\n# 可视化 R² 的含义\nnp.random.seed(42)\nX_demo = np.linspace(0, 10, 50).reshape(-1, 1)\ny_demo = 2*X_demo.flatten() + 3 + np.random.randn(50)*2\n\nfrom sklearn.linear_model import LinearRegression\n\nmodel_demo = LinearRegression()\nmodel_demo.fit(X_demo, y_demo)\ny_pred_demo = model_demo.predict(X_demo)\ny_mean = np.mean(y_demo)\n\n# 计算 R²\nr2 = model_demo.score(X_demo, y_demo)\n\nplt.figure(figsize=(12, 5))\n\nplt.subplot(1, 2, 1)\nplt.scatter(X_demo, y_demo, alpha=0.6, label='真实数据')\nplt.plot(X_demo, y_pred_demo, 'r-', linewidth=2, label='模型预测')\nplt.axhline(y=y_mean, color='green', linestyle='--', linewidth=2, label=f'平均值 = {y_mean:.1f}')\nplt.xlabel('X')\nplt.ylabel('y')\nplt.title(f'模型拟合 (R² = {r2:.3f})')\nplt.legend()\nplt.grid(True, alpha=0.3)\n\n# 残差对比\nplt.subplot(1, 2, 2)\nresiduals_model = y_demo - y_pred_demo\nresiduals_mean = y_demo - y_mean\n\nx_pos = np.arange(len(residuals_model))\nwidth = 0.35\nplt.bar(x_pos - width/2, np.abs(residuals_mean), width, label='预测平均值的误差', alpha=0.6)\nplt.bar(x_pos + width/2, np.abs(residuals_model), width, label='模型的误差', alpha=0.6)\nplt.xlabel('样本序号')\nplt.ylabel('|残差|')\nplt.title('模型 vs 基线（预测平均值）')\nplt.legend()\nplt.grid(True, alpha=0.3)\n\nplt.tight_layout()\nplt.show()",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>第二讲：数据处理与线性回归实践</span>"
    ]
  },
  {
    "objectID": "w2_data_processing.html#第三部分数据可视化",
    "href": "w2_data_processing.html#第三部分数据可视化",
    "title": "4  第二讲：数据处理与线性回归实践",
    "section": "4.4 第三部分：数据可视化",
    "text": "4.4 第三部分：数据可视化\n\n4.4.1 为什么需要可视化？\n\n4.4.1.1 Anscombe’s Quartet（安斯库姆四重奏）\n四组数据，统计量完全相同：\n\n均值、方差、相关系数、回归线都一样\n但数据分布完全不同！\n\n\n\n代码\n# Anscombe's Quartet\ndatasets = {\n    'I': {'x': [10, 8, 13, 9, 11, 14, 6, 4, 12, 7, 5],\n          'y': [8.04, 6.95, 7.58, 8.81, 8.33, 9.96, 7.24, 4.26, 10.84, 4.82, 5.68]},\n    'II': {'x': [10, 8, 13, 9, 11, 14, 6, 4, 12, 7, 5],\n           'y': [9.14, 8.14, 8.74, 8.77, 9.26, 8.10, 6.13, 3.10, 9.13, 7.26, 4.74]},\n    'III': {'x': [10, 8, 13, 9, 11, 14, 6, 4, 12, 7, 5],\n            'y': [7.46, 6.77, 12.74, 7.11, 7.81, 8.84, 6.08, 5.39, 8.15, 6.42, 5.73]},\n    'IV': {'x': [8, 8, 8, 8, 8, 8, 8, 19, 8, 8, 8],\n           'y': [6.58, 5.76, 7.71, 8.84, 8.47, 7.04, 5.25, 12.50, 5.56, 7.91, 6.89]}\n}\n\nfig, axes = plt.subplots(2, 2, figsize=(12, 10))\naxes = axes.flatten()\n\nfor idx, (name, data) in enumerate(datasets.items()):\n    x = np.array(data['x'])\n    y = np.array(data['y'])\n    \n    # 回归线\n    from scipy import stats\n    slope, intercept, r_value, p_value, std_err = stats.linregress(x, y)\n    line = slope * x + intercept\n    \n    axes[idx].scatter(x, y, s=100, alpha=0.6)\n    axes[idx].plot(x, line, 'r-', linewidth=2)\n    axes[idx].set_xlabel('X')\n    axes[idx].set_ylabel('Y')\n    axes[idx].set_title(f'数据集 {name}\\n均值X={np.mean(x):.1f}, 均值Y={np.mean(y):.2f}, r={r_value:.3f}')\n    axes[idx].grid(True, alpha=0.3)\n    axes[idx].set_xlim(0, 20)\n    axes[idx].set_ylim(2, 14)\n\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\n\n教训：永远要可视化数据！数字不会说谎，但会隐藏真相。\n\n\n\n4.4.2 常用图表类型\n\n4.4.2.1 散点图（Scatter Plot）\n用途：观察两个变量的关系\n\n\n代码\n# 生成示例数据\nnp.random.seed(42)\narea_demo = np.random.uniform(50, 200, 100)\nprice_demo = 2*area_demo + np.random.randn(100)*30 + 50\n\nplt.figure(figsize=(10, 6))\nplt.scatter(area_demo, price_demo, alpha=0.6, s=50)\nplt.xlabel('面积 (平米)', fontsize=12)\nplt.ylabel('价格 (万元)', fontsize=12)\nplt.title('散点图示例：房屋面积 vs 价格', fontsize=14)\nplt.grid(True, alpha=0.3)\n\n# 添加趋势线\nz = np.polyfit(area_demo, price_demo, 1)\np = np.poly1d(z)\nplt.plot(area_demo, p(area_demo), \"r--\", linewidth=2, alpha=0.8, label=f'趋势线: y={z[0]:.2f}x+{z[1]:.2f}')\nplt.legend()\nplt.show()\n\n\n\n\n\n\n\n\n\n能看出什么：\n\n正相关/负相关/无关系\n线性/非线性\n离群点\n\n\n\n4.4.2.2 直方图（Histogram）\n用途：观察单个变量的分布\n\n\n代码\nfig, axes = plt.subplots(1, 3, figsize=(15, 5))\n\n# 正态分布\ndata_normal = np.random.normal(100, 15, 1000)\naxes[0].hist(data_normal, bins=30, edgecolor='black', alpha=0.7)\naxes[0].set_xlabel('数值')\naxes[0].set_ylabel('频数')\naxes[0].set_title('正态分布（对称）')\naxes[0].grid(True, alpha=0.3)\n\n# 右偏分布\ndata_skewed = np.random.exponential(50, 1000)\naxes[1].hist(data_skewed, bins=30, edgecolor='black', alpha=0.7, color='orange')\naxes[1].set_xlabel('数值')\naxes[1].set_ylabel('频数')\naxes[1].set_title('右偏分布（收入、房价常见）')\naxes[1].grid(True, alpha=0.3)\n\n# 双峰分布\ndata_bimodal = np.concatenate([np.random.normal(50, 10, 500), np.random.normal(100, 10, 500)])\naxes[2].hist(data_bimodal, bins=30, edgecolor='black', alpha=0.7, color='green')\naxes[2].set_xlabel('数值')\naxes[2].set_ylabel('频数')\naxes[2].set_title('双峰分布（可能有两个群体）')\naxes[2].grid(True, alpha=0.3)\n\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\n4.4.2.3 相关系数热力图（Heatmap）\n用途：一次性看所有特征之间的相关性\n\n\n代码\n# 生成相关数据\nnp.random.seed(42)\nn = 100\ndata_corr = pd.DataFrame({\n    '面积': np.random.uniform(50, 200, n),\n})\ndata_corr['卧室数'] = 0.7 * data_corr['面积'] / 30 + np.random.randn(n) * 0.5\ndata_corr['房龄'] = np.random.uniform(0, 50, n)\ndata_corr['价格'] = 2 * data_corr['面积'] + 20 * data_corr['卧室数'] - 1 * data_corr['房龄'] + np.random.randn(n) * 20\n\n# 计算相关系数矩阵\ncorr_matrix = data_corr.corr()\n\nplt.figure(figsize=(8, 6))\nsns.heatmap(corr_matrix, annot=True, cmap='coolwarm', center=0, \n            square=True, linewidths=1, cbar_kws={\"shrink\": 0.8},\n            vmin=-1, vmax=1)\nplt.title('特征相关系数热力图', fontsize=14)\nplt.show()\n\n\n\n\n\n\n\n\n\n解读：\n\n红色（接近 +1）：强正相关（面积↑价格↑）\n蓝色（接近 -1）：强负相关（房龄↑价格↓）\n白色（接近 0）：无线性关系\n\n\n\n\n4.4.3 可视化陷阱\n\n4.4.3.1 陷阱 1：截断 Y 轴\n\n\n代码\n# 示例：夸大差异\ncategories = ['产品A', '产品B']\nvalues = [100, 102]\n\nfig, axes = plt.subplots(1, 2, figsize=(12, 5))\n\n# 诚实的图\naxes[0].bar(categories, values, color=['blue', 'orange'])\naxes[0].set_ylabel('销量')\naxes[0].set_title('诚实的图：差异很小')\naxes[0].set_ylim(0, 120)\naxes[0].grid(True, alpha=0.3, axis='y')\n\n# 误导的图（截断Y轴）\naxes[1].bar(categories, values, color=['blue', 'orange'])\naxes[1].set_ylabel('销量')\naxes[1].set_title('误导的图：看起来差距巨大！')\naxes[1].set_ylim(99, 103)  # 截断 Y 轴\naxes[1].grid(True, alpha=0.3, axis='y')\n\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\n\n教训：始终检查 Y 轴起点是否为 0\n\n\n4.4.3.2 陷阱 2：忽略样本量\n\n\n代码\n# 示例：样本量差异\ndata_large = np.random.normal(100, 15, 1000)\ndata_small = np.random.normal(105, 15, 10)\n\nfig, axes = plt.subplots(1, 2, figsize=(12, 5))\n\naxes[0].hist(data_large, bins=30, alpha=0.7, label=f'样本量=1000\\n均值={np.mean(data_large):.1f}')\naxes[0].set_xlabel('数值')\naxes[0].set_ylabel('频数')\naxes[0].set_title('大样本：分布稳定')\naxes[0].legend()\naxes[0].grid(True, alpha=0.3)\n\naxes[1].hist(data_small, bins=10, alpha=0.7, color='orange', label=f'样本量=10\\n均值={np.mean(data_small):.1f}')\naxes[1].set_xlabel('数值')\naxes[1].set_ylabel('频数')\naxes[1].set_title('小样本：分布不稳定')\naxes[1].legend()\naxes[1].grid(True, alpha=0.3)\n\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\n\n教训：报告统计量时，务必说明样本量",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>第二讲：数据处理与线性回归实践</span>"
    ]
  },
  {
    "objectID": "w2_data_processing.html#第四部分完整实战流程",
    "href": "w2_data_processing.html#第四部分完整实战流程",
    "title": "4  第二讲：数据处理与线性回归实践",
    "section": "4.5 第四部分：完整实战流程",
    "text": "4.5 第四部分：完整实战流程\n\n4.5.1 完整流程概览\n\n\n\n\n\ngraph TD\n    A[读取数据] --&gt; B[探索性数据分析&lt;br&gt;EDA]\n    B --&gt; C[数据清洗]\n    C --&gt; D[特征工程&lt;br&gt;可选]\n    D --&gt; E[数据切分]\n    E --&gt; F[训练模型]\n    F --&gt; G[模型评估]\n    G --&gt; H[残差分析]\n    H --&gt; I{满意?}\n    I --&gt;|否| J[调整模型/特征]\n    J --&gt; F\n    I --&gt;|是| K[完成]\n    \n    style A fill:#e3f2fd\n    style C fill:#fff9c4\n    style F fill:#c8e6c9\n    style G fill:#ffccbc\n    style K fill:#4caf50,color:#fff",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>第二讲：数据处理与线性回归实践</span>"
    ]
  },
  {
    "objectID": "w2_data_processing.html#总结",
    "href": "w2_data_processing.html#总结",
    "title": "4  第二讲：数据处理与线性回归实践",
    "section": "4.6 总结",
    "text": "4.6 总结\n\n4.6.1 本讲知识回顾\n\n4.6.1.1 数据预处理\n\n缺失值：删除 vs 填充\n异常值：IQR 方法、3σ 原则、业务判断\n归一化：Min-Max vs Z-score\n\n\n\n4.6.1.2 模型评估\n\n残差：模型诊断的核心\nMAE：平均绝对误差，直观稳健\nRMSE：均方根误差，惩罚大误差\nR²：解释变异的比例\n\n\n\n4.6.1.3 数据可视化\n\n散点图、直方图、箱线图、热力图\n永远先可视化，再建模！\n\n\n\n\n4.6.2 核心要点\n\n数据质量决定模型质量\n“Garbage In, Garbage Out” → 数据清洗是基础\n评估指标要多角度\n不要只看一个指标，MAE + RMSE + R² + 残差图\n可视化是必须的\nAnscombe’s Quartet 的教训\n模型诊断很重要\n残差图能发现很多问题",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>第二讲：数据处理与线性回归实践</span>"
    ]
  },
  {
    "objectID": "w2_data_processing.html#qa",
    "href": "w2_data_processing.html#qa",
    "title": "4  第二讲：数据处理与线性回归实践",
    "section": "4.7 Q&A",
    "text": "4.7 Q&A\nQ1：请简述 Min-Max 归一化和 Z-score 标准化各自的计算目标（或特点）。根据讲义，为什么树模型（如决策树、随机森林）通常不需要进行归一化处理？\nA：\n\nMin-Max 归一化：其目标是将数据线性缩放到一个固定的区间，通常是 [0, 1]。\nZ-score 标准化：其目标是将数据转换为均值为 0、标准差为 1 的分布。\n树模型不需要的原因：树模型是基于“分裂点”来做决策的（例如“面积 &gt; 80平米”），它关心的是特征的顺序和阈值，而不关心特征的绝对尺度。归一化不会改变特征值的相对顺序，因此对树模型的决策几乎没有影响。\n\nQ2：在处理缺失值时，为什么讲义强调第一步是“理解业务逻辑”？请结合课程中“R&D支出”的例子说明。\nA： 因为某些缺失值（NaN）可能并非真正的“数据丢失”，而是具有特定业务含义的“隐形缺失”。\n\n例子：在“R&D支出”的例子中，一家“传统公司”的R&D支出显示为 NaN。\n错误处理：如果盲目用均值或中位数填充，会错误地高估这家公司的研发投入。\n正确处理：通过业务逻辑理解，这家公司很可能没有R&D部门，因此 NaN 的真实含义是 0。此时应将其填充为 0 才能准确反映业务现实。\n\nQ3：MAE (平均绝对误差) 和 RMSE (均方根误差) 都是评估回归模型的指标。请问 RMSE 的计算方式（平方-求均-开方）有何特点，这导致它对哪种类型的误差（大误差还是小误差）更敏感？\nA： * 特点：RMSE 的计算涉及“平方”步骤（ \\((y_i - \\hat{y}_i)^2\\) ）。 * 敏感性：这个“平方”操作会显著放大那些数值较大的误差。 * 结论：因此，RMSE 相比 MAE 对“大误差”（即预测错得离谱的异常点）更为敏感。如果业务上无法容忍大的预测失误（例如金融风控），RMSE 是一个很重要的参考指标。\nQ4：课程中的“安斯库姆四重奏”(Anscombe’s Quartet) 案例告诉了我们一个关于数据分析的什么重要教训？\nA： 它告诉我们的教训是：“永远要可视化你的数据！”\n这四组数据的均值、方差、相关系数、甚至回归线都完全相同，但它们的数据分布形态却截然不同。如果只看统计数字，我们会误以为它们是一样的数据；只有通过可视化（如散点图），才能发现真相和数据中隐藏的模式。\nQ5：某回归模型的 R² (决定系数) 值为 0.8 [cite: 83]。这句话的直观解释是什么？R² 是否有可能为负数？\nA：\n\n解释：R² = 0.8 意味着，这个模型解释了数据中 80% 的变异性（或方差）。换句话说，相比于“盲猜”所有样本的平均值，这个模型能将预测的误差（用平方和衡量）减少 80%。\n是否为负：有可能。R² 为负数意味着模型的预测表现比“直接预测平均值”这个最简单的基线还要差。这通常说明模型非常糟糕，或者数据完全不适合该模型。\n\n**Q6：你在使用箱线图（Boxplot）进行异常值检测时，发现了一个明显偏离上界（Q3 + 1.5*IQR）的“异常值”。你的下一步处理流程是什么？**\nA：\n\n不应该立即删除。发现异常值只是第一步，关键是分析其产生的原因：\n\n\n分析原因：这个异常值是录入错误、测量错误，还是一个真实但极端的数据点？\n业务判断：\n\n如果是明确的错误：例如“面积-50”或“房龄999年”，这种数据应予以删除或修正（如果可能）。\n如果是真实极端值：例如“亿万富翁买豪宅”导致的极高房价，这个数据是真实有效的，应该保留。盲目删除会扭曲数据分布，使模型失去对高端市场的预测能力。\n如果不确定：可以尝试替换（例如用边界值替换），或者分别训练“包含”和“不包含”该异常值的模型，对比其对模型稳定性和评估指标的影响，再做决策。\n\n\nQ7：在对线性回归模型进行“残差分析”时，如果你发现残差图（横轴为预测值，纵轴为残差）中的点呈现出明显的“喇叭口”形状（即预测值越大，残差的波动范围越大），这揭示了模型可能存在什么问题？\nA： 这揭示了模型可能存在“异方差性”（Heteroscedasticity）。\n\n含义：“异方差性”意味着模型的误差（残差）不是恒定的，而是随着预测值的变化而变化。\n具体表现：在“喇叭口”形态中，当预测值（例如房价）较低时，模型预测得较准（误差小）；但当预测值较高时，模型的预测误差变得非常不稳定（时而偏高，时而偏低，波动范围大）。\n影响：这违反了线性回归的基本假设之一（误差方差恒定），可能导致模型的参数估计和置信区间不准确。\n\nQ8：假设你在构建两个金融模型： 1. 模型A：预测银行网点的平均每日取款量，用于常规运营规划。 2. 模型B：预测高频交易中的极端风险敞口，用于触发熔断机制。\n在评估时，模型A 和 模型B 应该分别更侧重 MAE 还是 RMSE？为什么？\nA：\n\n模型A (平均取款量)：应该更侧重 MAE (平均绝对误差)。\n\n原因：运营规划关心的是“平均”误差水平。MAE 能够直观地反映模型平均预测偏差了多少金额，且它对少数几天的极端值（例如节假日）不那么敏感（即更稳健），适合评估模型的整体稳健性。\n\n模型B (极端风险)：应该更侧重 RMSE (均方根误差)。\n\n原因：风险控制和熔断机制的核心就是识别和惩罚“大误差”。RMSE 因为计算时有平方项，会极大地惩罚那些预测偏差大的点，侧重 RMSE 能确保模型在“错得最离谱”的极端情况下表现得更好，这对于风控至关重要。\n\n\nQ9：在第一讲我们学到要先切分训练集/测试集。在第二讲我们学习了归一化。为什么“归一化”这个操作（例如 Z-score）必须在“切分数据”之后进行？如果顺序反了，会导致什么严重后果？\nA： 这是为了防止“数据泄露”（Data Leakage）。\n\n后果：Z-score 归一化需要计算数据的均值(\\(\\mu\\))和标准差(\\(\\sigma\\))。如果先对所有数据（1000条）进行归一化，再切分为训练集（800条）和测试集（200条），那么在计算均值和标准差时，测试集的 200 条数据信息已经被用到了。\n影响：这导致模型在训练阶段就已经“偷看”到了测试集的分布信息。这违反了“测试集必须是模型在训练过程中从未见过的数据”这一核心原则。这会导致模型在测试集上的评估结果过于乐观（分数虚高），而无法代表模型在未来真实新数据上的泛化能力。\n正确做法：1. 先切分。 2. 只在训练集上计算 \\(\\mu\\) 和 \\(\\sigma\\)。 3. 用这个（来自训练集的）\\(\\mu\\) 和 \\(\\sigma\\) 去归一化训练集，并用同一个 \\(\\mu\\) 和 \\(\\sigma\\) 去归一化测试集。",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>第二讲：数据处理与线性回归实践</span>"
    ]
  },
  {
    "objectID": "w3_lm_regularization.html",
    "href": "w3_lm_regularization.html",
    "title": "5  第三讲：线性回归的正则化",
    "section": "",
    "text": "5.1 开场：一个问题",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>第三讲：线性回归的正则化</span>"
    ]
  },
  {
    "objectID": "w3_lm_regularization.html#开场一个问题",
    "href": "w3_lm_regularization.html#开场一个问题",
    "title": "5  第三讲：线性回归的正则化",
    "section": "",
    "text": "5.1.1 当模型”太聪明”时…\n场景：你训练了一个房价预测模型\n\n\n\n数据集\nRMSE\n表现\n\n\n\n\n训练集\n5万\n✓ 很好\n\n\n测试集\n50万\n✗ 糟糕\n\n\n\n问题出在哪里？\n\n🚨 过拟合（Overfitting）：模型记住了训练数据的细节（包括噪声），但不能泛化到新数据！\n\n\n\n5.1.2 本周学习目标\n\n5.1.2.1 知识目标\n\n理解过拟合与欠拟合的概念\n理解正则化的基本思想（限制模型复杂度）\n掌握 Ridge、Lasso、Elastic Net 的区别和应用场景\n了解交叉验证的作用\n\n\n\n5.1.2.2 技能目标\n\n使用 sklearn 训练正则化回归模型\n使用交叉验证选择最优正则化参数\n绘制正则化路径图\n解释 Lasso 的特征选择结果\n\n\n\n5.1.2.3 核心理念\n“简单的模型往往更好”（Occam’s Razor）\n复杂度与泛化能力的权衡是机器学习的核心！",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>第三讲：线性回归的正则化</span>"
    ]
  },
  {
    "objectID": "w3_lm_regularization.html#第一部分过拟合与欠拟合",
    "href": "w3_lm_regularization.html#第一部分过拟合与欠拟合",
    "title": "5  第三讲：线性回归的正则化",
    "section": "5.2 第一部分：过拟合与欠拟合",
    "text": "5.2 第一部分：过拟合与欠拟合\n\n5.2.1 用多项式回归理解过拟合\n\n5.2.1.1 真实场景模拟\n假设真实关系是： \\(y = 2x + 1 + \\epsilon\\)，其中 \\(\\epsilon\\) 是噪声。\n我们用不同次数的多项式拟合：\n\n\n\n\n\n\n\n\n\n\n\n\n5.2.2 欠拟合 vs 过拟合 vs 刚刚好\n\n\n\n\n\n\n\n\n\n\n\n模型状态\n模型复杂度\n训练集误差\n测试集误差\n问题\n表现\n\n\n\n\n欠拟合\n太简单\n大\n大\n无法学到规律\n🙁 差\n\n\n刚刚好\n适中\n小\n小\n-\n😊 好\n\n\n过拟合\n太复杂\n非常小\n大\n记住了噪声\n😱 看起来好但实际差\n\n\n\n关键观察：\n\n欠拟合：训练和测试都差\n过拟合：训练很好，测试很差（差距大是关键信号）\n刚刚好：训练和测试都还不错，且差距小\n\n\n\n5.2.3 Bias-Variance Tradeoff（偏差-方差权衡）\n\n\n\n\n\n\n\n\n\n直观理解：\n\n偏差（Bias）：模型的”先天不足”，太简单无法拟合真实关系\n方差（Variance）：模型对训练数据的”过度敏感”，训练数据稍有变化预测就变很多\n目标：找到偏差和方差都较低的平衡点",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>第三讲：线性回归的正则化</span>"
    ]
  },
  {
    "objectID": "w3_lm_regularization.html#第二部分正则化的直觉",
    "href": "w3_lm_regularization.html#第二部分正则化的直觉",
    "title": "5  第三讲：线性回归的正则化",
    "section": "5.3 第二部分：正则化的直觉",
    "text": "5.3 第二部分：正则化的直觉\n\n5.3.1 什么是正则化？\n\n5.3.1.1 问题\n普通线性回归的目标： \\[\n\\min \\sum_{i=1}^{n}(y_i - \\hat{y}_i)^2 = \\min \\text{MSE}\n\\]\n只关心拟合训练数据，不管模型复杂度！\n\n\n5.3.1.2 正则化的想法\n在损失函数中加入惩罚项： \\[\n\\min \\underbrace{\\sum_{i=1}^{n}(y_i - \\hat{y}_i)^2}_{\\text{拟合误差}} + \\underbrace{\\alpha \\times \\text{惩罚项}}_{\\text{复杂度惩罚}}\n\\]\n\n拟合误差：让模型拟合数据\n复杂度惩罚：防止模型过于复杂\nα（alpha）：权衡两者的超参数\n\n\n\n\n5.3.2 正则化的类比\n类比 1：给模型”戴镣铐”\n\n不正则化 = 模型完全自由，可能”乱跑”（过拟合）\n正则化 = 给模型加限制，让它”老实点”\n\n类比 2：奥卡姆剃刀（Occam’s Razor）\n\n“如无必要，勿增实体”\n\n\n在同等拟合效果下，选择更简单的模型\n简单模型 = 系数小、特征少\n\n\n\n5.3.3 正则化的几何直觉\n\n\n\n\n\n\n\n\n\n关键区别：\n\nL2（圆形）：约束边界是平滑的，最优解很少正好在坐标轴上 → 系数小但不为0\nL1（菱形）：约束边界有”尖角”在坐标轴上，最优解容易碰到尖角 → 某些系数直接为0",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>第三讲：线性回归的正则化</span>"
    ]
  },
  {
    "objectID": "w3_lm_regularization.html#第三部分三种正则化方法",
    "href": "w3_lm_regularization.html#第三部分三种正则化方法",
    "title": "5  第三讲：线性回归的正则化",
    "section": "5.4 第三部分：三种正则化方法",
    "text": "5.4 第三部分：三种正则化方法\n\n5.4.1 Ridge 回归（L2 正则化）\n\n5.4.1.1 损失函数\n\\[\n\\min \\sum_{i=1}^{n}(y_i - \\hat{y}_i)^2 + \\alpha \\sum_{j=1}^{p}w_j^2\n\\]\n惩罚项：$ _{j=1}{p}w_j2 $ = 权重的平方和\n\n\n5.4.1.2 特点\n✅ 让所有权重变小\n✅ 不会让权重变成 0\n✅ 适合所有特征都重要的情况\n✅ 对多重共线性有帮助\n\n\n\n5.4.2 Lasso 回归（L1 正则化）\n\n5.4.2.1 损失函数\n\\[\n\\min \\sum_{i=1}^{n}(y_i - \\hat{y}_i)^2 + \\alpha \\sum_{j=1}^{p}|w_j|\n\\]\n惩罚项： $ _{j=1}^{p}|w_j| $ = 权重的绝对值和\n\n\n5.4.2.2 特点\n✅ 让某些权重直接变为 0（自动特征选择）\n✅ 产生稀疏模型（只保留重要特征）\n✅ 适合认为只有少数特征重要的情况\n✅ 结果易解释（特征少）\n\n\n\n5.4.3 Elastic Net（L1 + L2）\n\n5.4.3.1 损失函数\n\\[\n\\min \\sum_{i=1}^{n}(y_i - \\hat{y}_i)^2 + \\alpha \\left( \\rho \\sum_{j=1}^{p}|w_j| + \\frac{1-\\rho}{2} \\sum_{j=1}^{p}w_j^2 \\right)\n\\]\n两个超参数：\n\nα：正则化强度\nρ（l1_ratio）：L1 和 L2 的混合比例（0 = 纯 L2，1 = 纯 L1）\n\n\n\n5.4.3.2 特点\n✅ 结合 Ridge 和 Lasso 的优点\n✅ 在相关特征较多时表现更好\n✅ 不确定用哪个时的折中选择\n\n\n\n5.4.4 三种方法对比总结\n\n\n\n\n\n\n\n\n\n\n\n方法\n正则化项\n权重特点\n特征选择\n适用场景\nsklearn类\n\n\n\n\n普通线性回归\n无\n可能很大\n否\n特征少、数据多\nLinearRegression\n\n\nRidge (L2)\n∑w²\n变小但不为0\n否\n特征都重要\nRidge\n\n\nLasso (L1)\n∑|w|\n部分变为0\n是\n特征稀疏\nLasso\n\n\nElastic Net\nρ∑|w| + (1-ρ)∑w²\n折中\n是\n不确定时\nElasticNet",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>第三讲：线性回归的正则化</span>"
    ]
  },
  {
    "objectID": "w3_lm_regularization.html#第四部分正则化参数-α-的选择",
    "href": "w3_lm_regularization.html#第四部分正则化参数-α-的选择",
    "title": "5  第三讲：线性回归的正则化",
    "section": "5.5 第四部分：正则化参数 α 的选择",
    "text": "5.5 第四部分：正则化参数 α 的选择\n\n5.5.1 α 的作用\n\n\n\n\n\n\n\n\n\n关键点：\n\nα = 0：无正则化（普通线性回归）\nα 很小：弱正则化，接近普通回归\nα 适中：平衡拟合与复杂度 ✓\nα 很大：强正则化，可能欠拟合\n\n\n\n5.5.2 交叉验证（Cross-Validation）\n\n5.5.2.1 为什么需要交叉验证？\n错误做法 ❌：在测试集上尝试不同的 α，选最好的\n\n这样会”泄露”测试集信息\n导致对模型效果的过于乐观估计\n\n正确做法 ✓：用交叉验证在训练集上选 α\n\n\n5.5.2.2 K-Fold 交叉验证\n\n\n\n\n\n\n\n\n\n流程：\n\n将训练集分成 K 份（例如 K=5）\n每次用其中 1 份作验证，其余 K-1 份训练\n重复 K 次，得到 K 个评分\n取平均作为该 α 的评估分数\n选择评分最好的 α",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>第三讲：线性回归的正则化</span>"
    ]
  },
  {
    "objectID": "w3_lm_regularization.html#第五部分正则化路径与可视化",
    "href": "w3_lm_regularization.html#第五部分正则化路径与可视化",
    "title": "5  第三讲：线性回归的正则化",
    "section": "5.6 第五部分：正则化路径与可视化",
    "text": "5.6 第五部分：正则化路径与可视化\n\n5.6.1 正则化路径图（Regularization Path）\n问题：随着 α 增大，各特征的系数如何变化？\n\n\n\n\n\n\n\n\n\n观察：\n\nα 很小时：所有特征都保留\nα 逐渐增大：不重要的特征系数先变为 0\nα 很大时：几乎所有特征都被剔除",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>第三讲：线性回归的正则化</span>"
    ]
  },
  {
    "objectID": "w3_lm_regularization.html#第六部分实践建议",
    "href": "w3_lm_regularization.html#第六部分实践建议",
    "title": "5  第三讲：线性回归的正则化",
    "section": "5.7 第六部分：实践建议",
    "text": "5.7 第六部分：实践建议\n\n5.7.1 正则化回归完整流程\n\n\n\n\n\ngraph TD\n    A[加载数据] --&gt; B[数据标准化&lt;br&gt;StandardScaler]\n    B --&gt; C[训练/测试切分]\n    C --&gt; D[选择正则化方法]\n    D --&gt; E1[Ridge: 特征都重要]\n    D --&gt; E2[Lasso: 需要特征选择]\n    D --&gt; E3[Elastic Net: 不确定]\n    \n    E1 --&gt; F1[RidgeCV 自动选α]\n    E2 --&gt; F2[LassoCV 自动选α]\n    E3 --&gt; F3[ElasticNetCV 自动选α]\n    \n    F1 --&gt; G[训练最终模型]\n    F2 --&gt; G\n    F3 --&gt; G\n    \n    G --&gt; H[测试集评估]\n    H --&gt; I[可视化分析&lt;br&gt;系数/路径/残差]\n    \n    style B fill:#fff9c4\n    style F1 fill:#c8e6c9\n    style F2 fill:#c8e6c9\n    style F3 fill:#c8e6c9\n    style I fill:#ffccbc\n\n\n\n\n\n\n\n\n5.7.2 常见错误与注意事项\n\n5.7.2.1 ❌ 错误 1：忘记标准化\n错误做法：直接在原始数据上训练正则化模型\n\n特征尺度差异很大时，正则化会不公平地惩罚大尺度特征\n例如：面积特征（0-200）和卧室数特征（1-10），面积特征的权重会被过度惩罚\n\n正确做法：\n\n先用 StandardScaler 在训练集上 fit（计算均值和标准差）\n用训练集的参数 transform 训练集和测试集\n确保所有特征都在同一尺度（均值0，标准差1）\n\n为什么重要：正则化惩罚权重的大小，如果特征尺度不同，会导致不公平的惩罚。\n\n\n5.7.2.2 ❌ 错误 2：在测试集上选 α\n错误做法：尝试不同的 α 值，在测试集上选择表现最好的\n\n这会”泄露”测试集信息，导致对模型效果的过于乐观估计\n相当于用测试数据训练模型，违背了机器学习的基本原则\n\n正确做法：\n\n用交叉验证在训练集上选择最优 α\n训练最终模型后，再在测试集上评估\n确保测试集只用于最终评估\n\n为什么重要：避免数据泄露，得到真实的模型评估结果。\n\n\n5.7.2.3 ❌ 错误 3：选择不合适的正则化方法\n\n\n\n场景\n推荐方法\n原因\n\n\n\n\n100个特征，认为都重要\nRidge\nRidge保留所有特征\n\n\n100个特征，只有10个重要\nLasso\nLasso自动特征选择\n\n\n特征间高度相关\nElastic Net\nElastic Net处理共线性更好\n\n\n不确定哪些特征重要\nElastic Net\nElastic Net是折中方案\n\n\n需要可解释性（特征少）\nLasso\nLasso产生稀疏模型\n\n\n\n\n\n\n5.7.3 实用技巧\n\n5.7.3.1 技巧 1：先尝试 Lasso\n为什么：Lasso 可以自动做特征选择，告诉你哪些特征真正重要\n\n如果 Lasso 把很多特征剔除了，说明数据有稀疏性\n可以根据 Lasso 的结果决定是否需要特征工程\n帮助理解数据的特征重要性分布\n\n\n\n5.7.3.2 技巧 2：绘制验证曲线\n目的：观察 α 参数如何影响模型性能\n\nX轴：α 值（对数刻度，从 0.001 到 1000）\nY轴：模型评分（R² 或其他指标）\n两条线：训练集和验证集的性能\n\n如何解读：\n\nα 太小：训练和验证都表现良好（可能过拟合）\nα 适中：验证集表现最好 ✓\nα 太大：训练和验证都表现差（欠拟合）\n\n\n\n5.7.3.3 技巧 3：对比多种方法\n推荐做法：\n\n同时训练 Ridge、Lasso 和 Elastic Net（都用 CV 自动选参）\n比较它们的测试集性能\n选择最适合业务场景的方法\n记录不同方法的优缺点，便于后续解释\n\n为什么重要：不同正则化方法适合不同场景，盲目选择可能错过最佳方案。",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>第三讲：线性回归的正则化</span>"
    ]
  },
  {
    "objectID": "w3_lm_regularization.html#总结",
    "href": "w3_lm_regularization.html#总结",
    "title": "5  第三讲：线性回归的正则化",
    "section": "5.8 总结",
    "text": "5.8 总结\n\n5.8.1 本讲核心概念\n\n5.8.1.1 过拟合与正则化\n\n过拟合：模型太复杂，记住了训练数据的噪声\n正则化：在损失函数中加入复杂度惩罚，限制模型复杂度\nBias-Variance Tradeoff：找到偏差和方差的平衡点\n\n\n\n5.8.1.2 三种正则化方法\n\nRidge (L2)：让系数变小但不为 0，适合所有特征都重要\nLasso (L1)：让某些系数变为 0，自动特征选择\nElastic Net：结合 Ridge 和 Lasso，折中方案\n\n\n\n5.8.1.3 参数选择\n\n交叉验证：避免在测试集上调参\nRidgeCV/LassoCV：自动选择最优 α\n正则化路径：观察 α 变化时系数的变化\n\n\n\n\n5.8.2 重要提醒\n\n正则化前必须标准化特征 ⚠️\n否则正则化会不公平地惩罚某些特征\n不要在测试集上选参数 ⚠️\n用交叉验证在训练集上选\n多试几种方法 ⚠️\nRidge、Lasso、Elastic Net 都试试，对比效果\n可视化很重要 ⚠️\n正则化路径图、系数图、残差图",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>第三讲：线性回归的正则化</span>"
    ]
  },
  {
    "objectID": "w3_lm_regularization.html#qa",
    "href": "w3_lm_regularization.html#qa",
    "title": "5  第三讲：线性回归的正则化",
    "section": "5.9 Q&A",
    "text": "5.9 Q&A\nQ1：什么是“过拟合” (Overfitting)？根据讲义的开场案例，它的关键信号是什么？\nA：\n\n定义：过拟合是指模型过度学习了训练数据中的细节和噪声，导致它无法很好地泛化到未见过的新数据上。\n关键信号：模型在训练集上表现很好（例如RMSE 5万），但在测试集上表现很差（例如RMSE 50万）。训练集表现和测试集表现之间存在巨大差距是过拟合的关键信号。\n\nQ2：什么是“正则化”？它如何修改普通线性回归的损失函数？\nA：\n\n定义：正则化是一种用来防止过拟合、控制模型复杂度的技术。\n修改方式：它在普通线性回归的损失函数（拟合误差，如MSE）基础上，额外加入一个“复杂度惩罚项”。\n新目标：\\(\\min(\\text{拟合误差} + \\alpha \\times \\text{复杂度惩罚})\\)。这迫使模型在“拟合数据”和“保持简单”之间找到一个平衡。\n\nQ3：Ridge 回归和 Lasso 回归各自使用的是哪种正则化惩罚项（L1 还是 L2）？它们的惩罚项在数学上有什么不同？\nA：\n\nRidge (L2)：使用 L2 正则化。惩罚项是所有特征系数（权重）的平方和 (\\(\\sum w_j^2\\))。\nLasso (L1)：使用 L1 正则化。惩罚项是所有特征系数（权重）的绝对值和 (\\(\\sum |w_j|\\))。\n\nQ4：Lasso (L1) 正则化最独特的特点是什么？这使它在实践中有什么重要应用？\nA：\n\n最独特的特点：Lasso 最独特的特点是它能将某些不重要特征的系数（权重）直接压缩到 0。\n重要应用：这使 Lasso 具有自动特征选择的功能。它可以帮助我们从大量特征中筛选出真正重要的特征，从而得到一个更简单（稀疏）、可解释性更强的模型。\n\nQ5：为什么我们必须使用“交叉验证” (Cross-Validation) 来选择正则化参数 \\(\\alpha\\)，而不是直接在测试集上选择？\nA：\n\n因为测试集的核心原则是“只在最后使用一次”，它用来评估最终模型的泛化能力。\n如果在测试集上反复尝试不同的 \\(\\alpha\\) 值来“调参”，就相当于让模型在训练过程中“偷看”到了测试集的信息，这称为“数据泄露”。这会导致我们对模型性能的评估过于乐观，得到的不是模型真实的泛化能力。交叉验证允许我们在训练集内部安全地模拟这一评估过程，以找到最优的 \\(\\alpha\\)。\n\nQ6：正则化是如何体现在“偏差-方差权衡” (Bias-Variance Tradeoff) 上的？增加正则化强度（即增大 \\(\\alpha\\)）时，偏差和方差分别会如何变化？\nA：\n\n关系：正则化是管理偏差-方差权衡的关键工具。一个过拟合的模型（\\(\\alpha=0\\)）通常具有低偏差（能完美拟合训练数据）和高方差（对训练数据中的噪声高度敏感）。\n增大 \\(\\alpha\\) 的影响：\n\n增加偏差：当我们增大 \\(\\alpha\\)（加强惩罚），我们是在强迫模型变得更简单。这种限制会使模型增加偏差（Bias），因为它可能无法再完美捕捉训练数据中的所有复杂规律。\n降低方差：作为交换，一个更简单的模型对训练数据中特定噪声的敏感度显著降低了，即降低了方差（Variance）。\n\n目标：正则化的目标是找到一个最优的 \\(\\alpha\\)，在“欠拟合”（偏差高）和“过拟合”（方差高）之间找到一个平衡点，使得总误差（偏差 + 方差）最小。\n\nQ7：为什么讲义中反复强调“在应用正则化之前必须标准化特征”？如果忘记标准化（例如，一个特征“面积”范围 50-200，另一个“卧室数”范围 1-5），会导致什么严重后果？\nA：\n\n核心原因：正则化（L1 和 L2）是通过惩罚系数（权重 \\(w\\)）的大小来限制模型复杂度的。\n严重后果：\n\n尺度影响系数：如果特征尺度不同，“面积”（50-200）的系数 \\(w_1\\) 自然会很小（例如 0.01），而“卧室数”（1-5）的系数 \\(w_2\\) 会相对很大（例如 10）。\n不公平的惩罚：在计算惩罚项时（例如 L2：\\(\\alpha (w_1^2 + w_2^2)\\)），模型会极大地惩罚那个尺度小、系数大的特征（\\(w_2=10\\)），而几乎忽略那个尺度大、系数小的特征（\\(w_1=0.01\\)）。\n结论：忘记标准化会导致正则化的惩罚变得不公平且毫无意义。它会错误地惩罚那些仅仅因为单位尺度小而系数大的特征，而不是真正“不重要”的特征。标准化（如 Z-score）使所有特征处于同一尺度（例如均值0，标准差1），惩罚才会公平有效。\n\n\nQ8：在以下三种场景中，你应优先选择哪种正则化方法（Ridge, Lasso, Elastic Net），并说明理由？\n\n你有 500 个特征，但你怀疑其中只有约 20 个真正有用。\n你有 50 个特征，它们都与目标相关，但彼此之间（例如“收入”和“房产价值”）高度相关。\n你有 50 个特征，你认为它们都对预测有贡献，没有哪个是完全无用的。\n\nA：\n\n优先 Lasso：这是一个典型的“稀疏”场景。Lasso 的自动特征选择功能非常适合从大量特征中筛选出少数有用的特征，同时将其他无用特征的系数变为 0，得到一个简洁、可解释性强的模型。\n优先 Elastic Net：Lasso 在处理高度相关的特征时表现不稳定（它可能会随机选择一个，而把其他相关的特征系数压到0）。Elastic Net 结合了 L2（Ridge）的特性，在处理相关特征时更稳健，倾向于将它们“成组”地保留或剔除。\n优先 Ridge：因为我们认为所有特征都重要，我们不希望 Lasso 把任何一个特征的系数变为 0。Ridge (L2) 会保留所有特征，同时通过“缩小”所有系数来防止模型过拟合，这非常适合“所有特征都有用”的场景。",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>第三讲：线性回归的正则化</span>"
    ]
  },
  {
    "objectID": "w4_classification_decision_tree.html",
    "href": "w4_classification_decision_tree.html",
    "title": "6  第四讲：分类问题、决策树与评估指标",
    "section": "",
    "text": "6.1 开场：从预测数值到预测类别",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>第四讲：分类问题、决策树与评估指标</span>"
    ]
  },
  {
    "objectID": "w4_classification_decision_tree.html#开场从预测数值到预测类别",
    "href": "w4_classification_decision_tree.html#开场从预测数值到预测类别",
    "title": "6  第四讲：分类问题、决策树与评估指标",
    "section": "",
    "text": "6.1.1 上周回顾\n上两周学了什么？\n\n数据预处理（缺失值、异常值、归一化）\n回归模型的评估指标（MAE、RMSE、R²）\n线性回归模型\n线性回归模型的正则化（Ridge、Lasso、Elastic Net）\n\n核心任务：回归（预测连续数值）\n例子：预测房价 250 万元\n\n\n6.1.2 本周的新挑战\n新任务：分类（预测离散类别）\n例子：\n\n这笔贷款会违约吗？（是/否）\n这封邮件是垃圾邮件吗？（是/否）\n这个肿瘤是良性还是恶性？（良性/恶性）\n泰坦尼克号上的乘客会存活吗？（存活/死亡）\n\n关键区别：输出不再是数字，而是类别标签\n\n\n6.1.3 本周学习目标\n\n6.1.3.1 知识目标\n\n理解分类与回归的本质区别\n掌握决策树的基本原理\n理解混淆矩阵（TP、FP、TN、FN）\n掌握分类模型评估指标（准确率、精确率、召回率、F1、AUC）\n理解 ROC 曲线的含义\n\n\n\n6.1.3.2 技能目标\n\n使用 sklearn 训练决策树分类器\n计算并可视化混淆矩阵\n绘制 ROC 曲线并计算 AUC\n处理类别型特征（编码）",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>第四讲：分类问题、决策树与评估指标</span>"
    ]
  },
  {
    "objectID": "w4_classification_decision_tree.html#第一部分分类-vs-回归",
    "href": "w4_classification_decision_tree.html#第一部分分类-vs-回归",
    "title": "6  第四讲：分类问题、决策树与评估指标",
    "section": "6.2 第一部分：分类 vs 回归",
    "text": "6.2 第一部分：分类 vs 回归\n\n6.2.1 核心区别\n\n\n\n\n\ngraph LR\n    A[机器学习任务] --&gt; B[监督学习]\n    B --&gt; C[回归&lt;br/&gt;Regression]\n    B --&gt; D[分类&lt;br/&gt;Classification]\n    \n    C --&gt; C1[预测连续值]\n    C1 --&gt; C2[例: 250.5万]\n    \n    D --&gt; D1[预测离散类别]\n    D1 --&gt; D2[例: 存活/死亡]\n    \n    style C fill:#c8e6c9\n    style D fill:#bbdefb\n\n\n\n\n\n\n\n\n6.2.2 对比表格\n\n\n\n\n\n\n\n\n维度\n回归 (Regression)\n分类 (Classification)\n\n\n\n\n输出类型\n连续数值\n离散类别\n\n\n输出例子\n250.5 万、3.14、-5.2\n是/否、猫/狗/鸟\n\n\n典型应用\n房价预测、温度预测、销量预测\n垃圾邮件识别、疾病诊断、图像识别\n\n\n评估指标\nMAE、RMSE、R²\n准确率、精确率、召回率、AUC\n\n\n可视化\n拟合曲线、残差图\n混淆矩阵、ROC 曲线\n\n\n常用模型\n线性回归、回归树\n逻辑回归、决策树、SVM\n\n\n\n\n\n6.2.3 快速判断练习\n判断以下问题是分类还是回归？\n\n预测明天的最高气温 → 回归（连续值：25.5°C）\n判断肿瘤是良性还是恶性 → 分类（两个类别）\n预测用户会花多少钱 → 回归（连续值：$123.45）\n识别手写数字 0-9 → 分类（10 个类别）\n预测股票明天的收盘价 → 回归（连续值）\n预测客户是否会流失 → 分类（是/否）\n\n\n\n6.2.4 金融场景中的分类问题\n\n6.2.4.1 信用风险评估\n\n问题：这个贷款申请人会违约吗？\n类别：违约 / 不违约\n特征：收入、信用评分、负债率、工作年限\n\n\n\n6.2.4.2 欺诈检测\n\n问题：这笔交易是否欺诈？\n类别：欺诈 / 正常\n特征：交易金额、时间、地点、历史行为\n\n\n\n6.2.4.3 客户流失预测\n\n问题：客户下个月是否会流失？\n类别：流失 / 留存\n特征：使用频率、投诉次数、余额、会员等级",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>第四讲：分类问题、决策树与评估指标</span>"
    ]
  },
  {
    "objectID": "w4_classification_decision_tree.html#第二部分决策树decision-tree",
    "href": "w4_classification_decision_tree.html#第二部分决策树decision-tree",
    "title": "6  第四讲：分类问题、决策树与评估指标",
    "section": "6.3 第二部分：决策树（Decision Tree）",
    "text": "6.3 第二部分：决策树（Decision Tree）\n\n6.3.1 引入：人类如何做决策？\n场景：银行如何决定是否发放贷款？\n传统规则（专家经验）：\nIF 收入 &gt; 5000 AND 信用评分 &gt; 700 THEN\n    批准贷款\nELSE IF 收入 &gt; 8000 THEN\n    批准贷款\nELSE\n    拒绝贷款\n问题：规则由人工制定，可能不准确\n决策树：让机器从数据中自动学习这些规则！\n\n\n6.3.2 决策树的结构\n\n\n\n\n\ngraph TD\n    A[收入 &gt; 5000?] --&gt;|是| B[信用评分 &gt; 700?]\n    A --&gt;|否| C[拒绝贷款]\n    B --&gt;|是| D[批准贷款]\n    B --&gt;|否| E[拒绝贷款]\n    \n    style A fill:#fff9c4\n    style B fill:#fff9c4\n    style D fill:#c8e6c9,color:#000\n    style C fill:#ffccbc,color:#000\n    style E fill:#ffccbc,color:#000\n\n\n\n\n\n\n关键概念：\n\n根节点：第一个判断条件（收入 &gt; 5000?）\n内部节点：中间的判断条件（信用评分 &gt; 700?）\n叶节点：最终决策（批准/拒绝）\n分裂：根据某个特征的某个值进行分组\n\n\n\n6.3.3 决策树如何学习？\n\n6.3.3.1 核心思想\n每次选择”最能区分两类”的特征进行分裂\n类比：20 个问题猜动物游戏\n\n好问题：“是哺乳动物吗？” → 能区分很多动物\n差问题：“是蓝色的吗？” → 区分能力有限\n\n\n\n6.3.3.2 示例数据\n\n\n\n收入\n信用分\n是否违约\n\n\n\n\n3000\n650\n是\n\n\n6000\n750\n否\n\n\n4000\n700\n是\n\n\n7000\n800\n否\n\n\n5000\n600\n是\n\n\n8000\n750\n否\n\n\n\n目标：找到最好的分裂点\n\n\n6.3.3.3 尝试分裂 1：收入 &gt; 5000\n\n\n\n\n\ngraph TD\n    A[收入 &gt; 5000?] --&gt;|是&lt;br/&gt;3个样本| B[全部不违约 ✓&lt;br/&gt;纯净]\n    A --&gt;|否&lt;br/&gt;3个样本| C[全部违约 ✓&lt;br/&gt;纯净]\n    \n    style B fill:#c8e6c9\n    style C fill:#ffccbc\n\n\n\n\n\n\n结果：完美分类！ 纯度 100%\n\n\n6.3.3.4 尝试分裂 2：信用分 &gt; 700\n\n\n\n\n\ngraph TD\n    A[信用分 &gt; 700?] --&gt;|是&lt;br/&gt;3个样本| B[2个不违约&lt;br/&gt;1个违约&lt;br/&gt;纯度67%]\n    A --&gt;|否&lt;br/&gt;3个样本| C[2个违约&lt;br/&gt;1个不违约&lt;br/&gt;纯度67%]\n    \n    style B fill:#fff9c4\n    style C fill:#fff9c4\n\n\n\n\n\n\n结果：分类不纯净，纯度 67%\n选择：收入 &gt; 5000（纯度更高）\n\n\n\n6.3.4 决策树的优缺点\n\n6.3.4.1 优点 ✓\n\n易于理解：可视化，符合人类思维\n可解释性强：能清楚看到决策路径\n不需要归一化：对特征尺度不敏感\n能处理非线性：不像线性回归只能拟合直线\n自动特征选择：重要特征会靠近根节点\n\n\n\n6.3.4.2 缺点 ✗\n\n容易过拟合：树太深会记住训练数据\n不稳定：数据稍微变化，树结构可能完全不同\n单棵树精度有限：后续会学集成方法改进\n\n\n\n\n6.3.5 控制过拟合：关键参数\n\n\n\n参数\n含义\n效果\n建议值\n\n\n\n\nmax_depth\n树的最大深度\n越大越复杂\n3-10\n\n\nmin_samples_split\n分裂所需最小样本数\n越大越保守\n2-20\n\n\nmin_samples_leaf\n叶节点最小样本数\n越大越保守\n1-10\n\n\nmax_leaf_nodes\n最大叶节点数\n限制树大小\n10-100\n\n\n\n核心原则：限制树的复杂度，防止过拟合",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>第四讲：分类问题、决策树与评估指标</span>"
    ]
  },
  {
    "objectID": "w4_classification_decision_tree.html#第三部分混淆矩阵",
    "href": "w4_classification_decision_tree.html#第三部分混淆矩阵",
    "title": "6  第四讲：分类问题、决策树与评估指标",
    "section": "6.4 第三部分：混淆矩阵",
    "text": "6.4 第三部分：混淆矩阵\n\n6.4.1 为什么需要混淆矩阵？\n场景：违约预测\n\n模型 A：所有人都预测为”不违约” → 准确率 99%（因为 99% 人真的不违约）\n问题：完全没有检测出违约！\n\n教训：准确率不够！需要更细致的评估\n混淆矩阵：把所有预测结果分成 4 类\n\n\n6.4.2 混淆矩阵的定义\nTitanic 例子：预测乘客是否存活\n\n\n\n\n预测：存活\n预测：死亡\n\n\n\n\n真实：存活\nTP = 50  ✓ 预测对了\nFN = 10  ✗ 漏报\n\n\n真实：死亡\nFP = 5  ✗ 误报\nTN = 35  ✓ 预测对了\n\n\n\n\n\n6.4.3 四个概念详解\n\n6.4.3.1 TP（True Positive，真阳性）\n\n含义：真实是正类，预测也是正类 ✓\n例子：真的存活，预测存活（50 人）\n理解：预测对了，皆大欢喜\n\n\n\n6.4.3.2 FN（False Negative，假阴性）\n\n含义：真实是正类，预测是负类 ✗\n例子：真的存活，预测死亡（10 人）\n理解：漏报（本该检测出来，但漏掉了）\n\n\n\n6.4.3.3 FP（False Positive，假阳性）\n\n含义：真实是负类，预测是正类 ✗\n例子：真的死亡，预测存活（5 人）\n理解：误报（本不该报警，但误报了）\n\n\n\n6.4.3.4 TN（True Negative，真阴性）\n\n含义：真实是负类，预测也是负类 ✓\n例子：真的死亡，预测死亡（35 人）\n理解：预测对了，正确排除\n\n\n\n\n6.4.4 记忆方法\n\n\n\n\n\ngraph TD\n    A[TP/FP/TN/FN] --&gt; B[第一个字母&lt;br/&gt;True/False]\n    A --&gt; C[第二个字母&lt;br/&gt;Positive/Negative]\n    \n    B --&gt; D[预测是否正确]\n    C --&gt; E[预测为哪一类]\n    \n    D --&gt; F[True = 对&lt;br/&gt;False = 错]\n    E --&gt; G[Positive = 正类&lt;br/&gt;Negative = 负类]\n    \n    style F fill:#c8e6c9\n    style G fill:#bbdefb\n\n\n\n\n\n\n口诀：\n\nTrue/False：预测对/错\nPositive/Negative：预测为正/负类\nP 在前：Predict Positive（预测为正类）\n\n\n\n6.4.5 可视化混淆矩阵\n\n\n代码\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nfrom sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n\n# 模拟预测结果\nnp.random.seed(42)\ny_true = np.array([1]*60 + [0]*40)  # 60个存活，40个死亡\ny_pred = y_true.copy()\n# 引入一些错误\ny_pred[[5, 8, 12]] = 0  # 3个FN（漏报）\ny_pred[[65, 72]] = 1    # 2个FP（误报）\n\ncm = confusion_matrix(y_true, y_pred)\n\nfig, axes = plt.subplots(1, 2, figsize=(14, 6))\n\n# 混淆矩阵（数字）\ndisp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=['死亡', '存活'])\ndisp.plot(cmap='Blues', ax=axes[0])\naxes[0].set_title('混淆矩阵', fontsize=14)\n\n# 标注含义\nTN, FP, FN, TP = cm.ravel()\naxes[1].text(0.1, 0.8, f'TP (真阳性) = {TP}\\n真实存活，预测存活 ✓', fontsize=12, \n             bbox=dict(boxstyle='round', facecolor='#c8e6c9'))\naxes[1].text(0.1, 0.6, f'FN (假阴性) = {FN}\\n真实存活，预测死亡 ✗\\n漏报', fontsize=12,\n             bbox=dict(boxstyle='round', facecolor='#ffccbc'))\naxes[1].text(0.1, 0.4, f'FP (假阳性) = {FP}\\n真实死亡，预测存活 ✗\\n误报', fontsize=12,\n             bbox=dict(boxstyle='round', facecolor='#ffccbc'))\naxes[1].text(0.1, 0.2, f'TN (真阴性) = {TN}\\n真实死亡，预测死亡 ✓', fontsize=12,\n             bbox=dict(boxstyle='round', facecolor='#c8e6c9'))\naxes[1].set_xlim(0, 1)\naxes[1].set_ylim(0, 1)\naxes[1].axis('off')\naxes[1].set_title('含义解释', fontsize=14)\n\nplt.tight_layout()\nplt.show()\n\nprint(f\"TP={TP}, FN={FN}, FP={FP}, TN={TN}\")\n\n\n/var/folders/dh/sd70vd1d0jg1tkw7h3zwjqxr0000gn/T/ipykernel_89141/493726840.py:38: UserWarning:\n\nGlyph 10003 (\\N{CHECK MARK}) missing from current font.\n\n/var/folders/dh/sd70vd1d0jg1tkw7h3zwjqxr0000gn/T/ipykernel_89141/493726840.py:38: UserWarning:\n\nGlyph 10007 (\\N{BALLOT X}) missing from current font.\n\n/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/IPython/core/pylabtools.py:170: UserWarning:\n\nGlyph 10003 (\\N{CHECK MARK}) missing from current font.\n\n/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/IPython/core/pylabtools.py:170: UserWarning:\n\nGlyph 10007 (\\N{BALLOT X}) missing from current font.\n\n\n\n\n\n\n\n\n\n\nTP=57, FN=3, FP=2, TN=38",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>第四讲：分类问题、决策树与评估指标</span>"
    ]
  },
  {
    "objectID": "w4_classification_decision_tree.html#第四部分分类评估指标",
    "href": "w4_classification_decision_tree.html#第四部分分类评估指标",
    "title": "6  第四讲：分类问题、决策树与评估指标",
    "section": "6.5 第四部分：分类评估指标",
    "text": "6.5 第四部分：分类评估指标\n\n6.5.1 准确率（Accuracy）\n\n6.5.1.1 定义\n\\[\n\\text{Accuracy} = \\frac{TP + TN}{\\text{总样本数}} = \\frac{\\text{预测正确的}}{\\text{全部}}\n\\]\n例子：\\(\\frac{57 + 38}{100} = 95\\%\\)\n\n\n6.5.1.2 准确率的问题\n场景：欺诈检测\n\n总样本：10000 笔交易\n欺诈：100 笔（1%）\n正常：9900 笔（99%）\n\n“愚蠢”模型：\n\n策略：预测所有交易都是正常的\n准确率：\\(\\frac{9900}{10000} = 99\\%\\)\n问题：完全没有抓到欺诈！\n\n结论：在类别不平衡时，准确率会误导\n\n\n\n6.5.2 精确率（Precision）\n\n6.5.2.1 定义\n\\[\n\\text{Precision} = \\frac{TP}{TP + FP} = \\frac{\\text{真正是正类}}{\\text{预测为正类}}\n\\]\n业务含义：在所有”预测为正类”的样本中，真正是正类的比例\n例子（垃圾邮件）：\n\n预测为垃圾邮件的 100 封中，真的垃圾邮件有 90 封\nPrecision = 90/100 = 90%\n\n关注点：误报代价高时\n\n垃圾邮件过滤：不能误删重要邮件\n推荐系统：不能推荐用户不喜欢的\n\n\n\n\n6.5.3 召回率（Recall / TPR）\n\n6.5.3.1 定义\n\\[\n\\text{Recall} = \\frac{TP}{TP + FN} = \\frac{\\text{找出来的正类}}{\\text{真正的正类}}\n\\]\n业务含义：在所有”真正是正类”的样本中，被正确找出的比例\n例子（疾病诊断）：\n\n真实病人 100 人，模型检测出 80 人\nRecall = 80/100 = 80%\n\n关注点：漏报代价高时\n\n疾病诊断：不能漏掉病人\n欺诈检测：不能放过欺诈\n安检：不能漏掉危险品\n\n\n\n\n6.5.4 Precision vs Recall\n\n\n代码\n# 可视化 Precision vs Recall\nfig, axes = plt.subplots(1, 2, figsize=(14, 6))\n\n# 场景1：高 Precision，低 Recall\ny_true_1 = np.array([1]*50 + [0]*50)\ny_pred_1 = np.array([1]*10 + [0]*40 + [0]*50)  # 只预测10个正类，但都对\ncm_1 = confusion_matrix(y_true_1, y_pred_1)\nTN_1, FP_1, FN_1, TP_1 = cm_1.ravel()\nprecision_1 = TP_1 / (TP_1 + FP_1) if (TP_1 + FP_1) &gt; 0 else 0\nrecall_1 = TP_1 / (TP_1 + FN_1)\n\ndisp_1 = ConfusionMatrixDisplay(confusion_matrix=cm_1, display_labels=['负', '正'])\ndisp_1.plot(cmap='Blues', ax=axes[0])\naxes[0].set_title(f'保守策略\\nPrecision={precision_1:.2f}, Recall={recall_1:.2f}\\n（宁可放过，不可错杀）', fontsize=12)\n\n# 场景2：低 Precision，高 Recall\ny_pred_2 = np.array([1]*80 + [0]*20)  # 预测80个正类，包含30个FP\ncm_2 = confusion_matrix(y_true_1, y_pred_2)\nTN_2, FP_2, FN_2, TP_2 = cm_2.ravel()\nprecision_2 = TP_2 / (TP_2 + FP_2)\nrecall_2 = TP_2 / (TP_2 + FN_2)\n\ndisp_2 = ConfusionMatrixDisplay(confusion_matrix=cm_2, display_labels=['负', '正'])\ndisp_2.plot(cmap='Oranges', ax=axes[1])\naxes[1].set_title(f'激进策略\\nPrecision={precision_2:.2f}, Recall={recall_2:.2f}\\n（宁可错杀，不可放过）', fontsize=12)\n\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\n\nPrecision-Recall 权衡：\n\n提高 Precision → 降低 Recall（更保守）\n提高 Recall → 降低 Precision（更激进）\n\n\n\n6.5.5 F1 分数\n\n6.5.5.1 定义\n\\[\nF1 = 2 \\times \\frac{\\text{Precision} \\times \\text{Recall}}{\\text{Precision} + \\text{Recall}}\n\\]\n直观理解：Precision 和 Recall 的调和平均\n为什么用调和平均？\n\n算术平均：\\((0.9 + 0.1) / 2 = 0.5\\)\n调和平均：\\(2 \\times \\frac{0.9 \\times 0.1}{0.9 + 0.1} = 0.18\\)\n\n调和平均惩罚极端值：两个指标都高，F1 才高\n\n\n6.5.5.2 F1 的应用场景\n何时使用 F1？\n\nPrecision 和 Recall 都重要\n需要一个综合指标\n例子：欺诈检测、信息检索\n\n示例计算：\n\nPrecision = 0.9, Recall = 0.8\nF1 = \\(2 \\times \\frac{0.9 \\times 0.8}{0.9 + 0.8} = 0.847\\)\n\n\n\n代码\n# F1 分数可视化\nprecisions = np.linspace(0.1, 1, 50)\nrecalls = np.linspace(0.1, 1, 50)\nP, R = np.meshgrid(precisions, recalls)\nF1 = 2 * (P * R) / (P + R)\n\nplt.figure(figsize=(10, 7))\ncontour = plt.contourf(P, R, F1, levels=20, cmap='RdYlGn')\nplt.colorbar(contour, label='F1 分数')\nplt.xlabel('Precision', fontsize=12)\nplt.ylabel('Recall', fontsize=12)\nplt.title('F1 分数热力图\\n（两个指标都高，F1 才高）', fontsize=14)\nplt.grid(True, alpha=0.3)\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\n\n6.5.6 指标总结对比\n\n\n\n指标\n公式\n关注点\n何时使用\n例子\n\n\n\n\n准确率\n(TP+TN)/总数\n整体正确率\n类别平衡\n性别识别\n\n\n精确率\nTP/(TP+FP)\n误报\n误报代价高\n垃圾邮件\n\n\n召回率\nTP/(TP+FN)\n漏报\n漏报代价高\n疾病诊断\n\n\nF1\n调和平均\n综合\n两者都重要\n欺诈检测",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>第四讲：分类问题、决策树与评估指标</span>"
    ]
  },
  {
    "objectID": "w4_classification_decision_tree.html#第五部分roc-曲线与-auc",
    "href": "w4_classification_decision_tree.html#第五部分roc-曲线与-auc",
    "title": "6  第四讲：分类问题、决策树与评估指标",
    "section": "6.6 第五部分：ROC 曲线与 AUC",
    "text": "6.6 第五部分：ROC 曲线与 AUC\n\n6.6.1 分类阈值的影响\n问题：分类器输出的是概率，如何转成类别？\n例子：\n\n\n\n样本\n预测概率\n阈值=0.5\n阈值=0.7\n阈值=0.3\n\n\n\n\nA\n0.8\n存活\n存活\n存活\n\n\nB\n0.6\n存活\n死亡\n存活\n\n\nC\n0.4\n死亡\n死亡\n存活\n\n\nD\n0.2\n死亡\n死亡\n死亡\n\n\n\n观察：阈值不同，分类结果不同\n\n\n6.6.2 阈值对指标的影响\n\n\n代码\n# 模拟阈值变化\nnp.random.seed(42)\ny_true_roc = np.array([1]*60 + [0]*40)\ny_score = np.concatenate([np.random.beta(8, 2, 60), np.random.beta(2, 5, 40)])\n\nfrom sklearn.metrics import precision_score, recall_score\n\nthresholds = [0.3, 0.5, 0.7, 0.9]\nresults = []\n\nfor thresh in thresholds:\n    y_pred_thresh = (y_score &gt;= thresh).astype(int)\n    precision = precision_score(y_true_roc, y_pred_thresh)\n    recall = recall_score(y_true_roc, y_pred_thresh)\n    pred_positive = y_pred_thresh.sum()\n    results.append({\n        '阈值': thresh,\n        '预测正类数': pred_positive,\n        'Precision': precision,\n        'Recall': recall\n    })\n\ndf_thresh = pd.DataFrame(results)\nprint(df_thresh.to_string(index=False))\n\n\n 阈值  预测正类数  Precision   Recall\n0.3     74   0.810811 1.000000\n0.5     62   0.967742 1.000000\n0.7     51   0.980392 0.833333\n0.9     10   1.000000 0.166667\n\n\n规律：\n\n阈值低 → 预测更多正类 → Recall 高，Precision 低\n阈值高 → 预测更少正类 → Precision 高,Recall 低\n\n\n\n6.6.3 ROC 曲线\n\n6.6.3.1 定义\nROC（Receiver Operating Characteristic）曲线：\n\n横轴：假正例率 FPR = FP / (FP + TN)\n纵轴：真正例率 TPR = TP / (TP + FN) = Recall\n每个点：一个阈值对应的 (FPR, TPR)\n\n\n\n6.6.3.2 ROC 曲线可视化\n\n\n代码\nfrom sklearn.metrics import roc_curve, auc\n\nfpr, tpr, thresholds_roc = roc_curve(y_true_roc, y_score)\nroc_auc = auc(fpr, tpr)\n\nplt.figure(figsize=(10, 8))\nplt.plot(fpr, tpr, color='darkorange', lw=3, label=f'ROC 曲线 (AUC = {roc_auc:.3f})')\nplt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--', label='随机猜测 (AUC = 0.5)')\n\n# 标注几个关键点\nfor i, thresh in enumerate([0.3, 0.5, 0.7]):\n    idx = np.argmin(np.abs(thresholds_roc - thresh))\n    plt.scatter(fpr[idx], tpr[idx], s=100, zorder=5)\n    plt.annotate(f'阈值={thresh:.1f}', (fpr[idx], tpr[idx]), \n                textcoords=\"offset points\", xytext=(10,5), fontsize=10)\n\nplt.xlim([0.0, 1.0])\nplt.ylim([0.0, 1.05])\nplt.xlabel('假正例率 (FPR) = FP/(FP+TN)', fontsize=12)\nplt.ylabel('真正例率 (TPR) = Recall', fontsize=12)\nplt.title('ROC 曲线', fontsize=14)\nplt.legend(loc=\"lower right\", fontsize=12)\nplt.grid(alpha=0.3)\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\n\n6.6.4 理解 ROC 曲线\n\n\n\n\n\ngraph TD\n    A[左下角 0,0] --&gt; B[随机猜测对角线]\n    B --&gt; C[左上角 0,1]\n    \n    A --&gt; D[从不预测正类&lt;br/&gt;TPR=0, FPR=0]\n    C --&gt; E[完美分类器&lt;br/&gt;TPR=1, FPR=0]\n    B --&gt; F[随机猜测&lt;br/&gt;TPR=FPR]\n    \n    style E fill:#4caf50,color:#fff\n    style D fill:#f44336,color:#fff\n    style F fill:#ff9800,color:#fff\n\n\n\n\n\n\n关键点：\n\n左上角 (0, 1)：完美分类器（TPR=1, FPR=0）\n对角线：随机猜测（瞎蒙）\n曲线越靠近左上角越好\n\n\n\n6.6.5 AUC（Area Under Curve）\n\n6.6.5.1 定义\nAUC：ROC 曲线下的面积\n取值范围：0.5 ~ 1.0\n\n\n6.6.5.2 AUC 的含义\n直观解释：\n随机选一个正样本和一个负样本，模型给正样本打分更高的概率\n判断标准：\n\n\n\nAUC 范围\n模型质量\n说明\n\n\n\n\n&lt; 0.7\n差\n接近随机猜测\n\n\n0.7 ~ 0.8\n一般\n可用但有改进空间\n\n\n0.8 ~ 0.9\n好\n较好的分类器\n\n\n0.9 ~ 1.0\n很好\n优秀（小心过拟合）\n\n\n\n\n\n6.6.5.3 为什么 AUC 重要？\n优点：\n\n不受阈值影响：综合评估所有阈值\n不受类别不平衡影响：比准确率更可靠\n评估排序能力：而非单点预测\n\n缺点：\n\n不够直观（不如准确率好理解）\n不能直接告诉你用哪个阈值\n\n推荐：\n\n类别平衡 → 准确率 + AUC\n类别不平衡 → 只看 AUC（准确率会误导）",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>第四讲：分类问题、决策树与评估指标</span>"
    ]
  },
  {
    "objectID": "w4_classification_decision_tree.html#总结",
    "href": "w4_classification_decision_tree.html#总结",
    "title": "6  第四讲：分类问题、决策树与评估指标",
    "section": "6.7 总结",
    "text": "6.7 总结\n\n6.7.1 本讲知识回顾\n\n6.7.1.1 分类 vs 回归\n\n回归：预测连续值（房价、温度）\n分类：预测离散类别（存活/死亡、是/否）\n\n\n\n6.7.1.2 决策树\n\n结构：根节点、内部节点、叶节点\n原理：选择最能区分的特征分裂\n优点：易理解、可解释\n缺点：易过拟合\n\n\n\n6.7.1.3 混淆矩阵与评估指标\n\n\n\n概念\n含义\n何时重要\n\n\n\n\nTP\n真阳性：预测对了的正类\n总是好\n\n\nFN\n假阴性：漏报\n疾病诊断\n\n\nFP\n假阳性：误报\n垃圾邮件\n\n\nTN\n真阴性：预测对了的负类\n总是好\n\n\nPrecision\n预测为正类中真正是正类的比例\n误报代价高\n\n\nRecall\n真正是正类中被找出的比例\n漏报代价高\n\n\nF1\nPrecision 和 Recall 的调和平均\n综合评估\n\n\n\n\n\n6.7.1.4 ROC 与 AUC\n\nROC 曲线：不同阈值下的 TPR vs FPR\nAUC：ROC 曲线下面积（0.5~1.0）\n优点：不受阈值和类别不平衡影响\n推荐：类别不平衡时必看 AUC\n\n\n\n\n6.7.2 核心要点\n\n选对评估指标\n类别平衡 → 准确率；类别不平衡 → AUC\n理解业务需求\n误报代价高 → Precision；漏报代价高 → Recall\n可视化很重要\n混淆矩阵 + ROC 曲线 比单看数字更直观\n决策树易过拟合\n控制 max_depth，下周学更强的模型",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>第四讲：分类问题、决策树与评估指标</span>"
    ]
  },
  {
    "objectID": "w4_classification_decision_tree.html#qa",
    "href": "w4_classification_decision_tree.html#qa",
    "title": "6  第四讲：分类问题、决策树与评估指标",
    "section": "6.8 Q&A",
    "text": "6.8 Q&A\nQ1：请用一句话概括“分类”与“回归”的本质区别，并判断“预测客户信用评级（A/B/C/D）”属于哪一类？\nA：\n\n本质区别：回归（Regression）预测的是连续数值（例如房价250.5万），而分类（Classification）预测的是离散类别（例如“存活”/“死亡”）。\n判断：“预测客户信用评级”属于分类问题，因为它是在预测有限的几个类别（A、B、C、D）。\n\nQ2：什么是混淆矩阵？请写出 TP、FP、FN、TN 的中文含义。\nA： 混淆矩阵是用来详细评估分类模型性能的工具，它将预测结果分为四种情况：\n\nTP (True Positive):真阳性（真实为正类，预测也为正类）\nFN (False Negative):假阴性（真实为正类，预测为负类，即“漏报”）\nFP (False Positive):假阳性（真实为负类，预测为正类，即“误报”）\nTN (True Negative):真阴性（真实为负类，预测也为负类）\n\nQ3：为什么“准确率” (Accuracy) 在类别不平衡（例如 99% 正常交易，1% 欺诈交易）的数据集上是一个具有误导性的指标？\nA： 因为在这种情况下，一个“愚蠢”的模型如果把所有样本都预测为占比高的那个类别（例如“正常交易”），它依然可以获得极高的准确率（例如 99%）。但这个模型是完全无用的，因为它一个欺诈样本都检测不出来。\nQ4：什么是 AUC？ROC 曲线下面积（AUC）为 0.5 意味着什么？\nA： * AUC：指的是 ROC 曲线（受试者工作特征曲线）下方的面积（Area Under Curve）。 * AUC = 0.5：这意味着模型的表现和随机猜测（瞎蒙）一样。ROC 曲线表现为一条从(0,0)到(1,1)的对角线。\nQ5：在什么业务场景下，我们应该优先关注“精确率” (Precision)？在什么场景下又该优先关注“召回率” (Recall)？请各举一例。\nA： 这取决于我们更害怕哪种错误（“误报”还是“漏报”）： 1. 优先 Precision (精确率)：当“误报” (FP) 的代价很高时。 * 例子：垃圾邮件过滤。我们更害怕把一封重要邮件（例如 offer 或账单）错判为垃圾邮件（FP），相比之下，漏掉几封垃圾邮件（FN）的代价较低。 2. 优先 Recall (召回率)：当“漏报” (FN) 的代价很高时。 * 例子：疾病诊断 或金融欺诈检测。我们更害怕把一个真正的病人漏诊为“健康”（FN），因为这可能危及生命。相比之下，把健康人误判为“疑似病人”（FP）让他再做一次检查，代价相对较低。\nQ6：如果你的决策树模型表现出明显的“过拟合”（即训练集表现很好，测试集表现很差），你应该调整讲义中提到的哪些参数来限制模型的复杂度？\nA： 为了防止过拟合，我们应该限制树的复杂度。讲义中提到了几个关键参数：\n\nmax_depth (最大深度)：减小这个值，让树变得更浅，防止它学得太细。\nmin_samples_split (分裂所需最小样本数)：增大这个值，要求一个节点必须有足够多的样本才能继续分裂。\nmin_samples_leaf (叶节点最小样本数)：增大这个值，确保每个叶节点（最终决策）都代表了足够多的样本。\n\nQ7：为什么 F1 分数要使用 Precision 和 Recall 的“调和平均数”，而不是简单的“算术平均数”（即 (P+R)/2）？\nA： 因为调和平均数会更严厉地惩罚极端情况。\n\n例子：假设 Precision = 0.9，Recall = 0.1。\n\n算术平均 = (0.9 + 0.1) / 2 = 0.5（看起来还不错）\n调和平均 (F1) = \\(2 \\times \\frac{0.9 \\times 0.1}{0.9 + 0.1} = 0.18\\)（非常低）\n\n结论：F1 分数的目标是确保 Precision 和 Recall 两者都必须比较高时，F1 分数才会高。如果其中任何一个指标很低，F1 分数都会被拉得很低，这更符合我们对一个“好模型”的综合评估要求。\n\nQ8：分类器输出的“概率阈值”（Threshold）是如何影响 Precision 和 Recall 的？如果我们把阈值从 0.5 提高到 0.8，Precision 和 Recall 会如何变化？\nA：\n\n影响：阈值决定了模型预测的“激进”程度。\n提高阈值 (0.5 \\(\\rightarrow\\) 0.8)：这意味着模型变得“保守”了，只有当它非常有把握（概率 &gt; 0.8）时，才会把样本预测为正类。\n\nPrecision (精确率) 会上升：因为被预测为“正类”的门槛高了，这些预测中“猜对”的比例（TP / (TP+FP)）会更高。\nRecall (召回率) 会下降：因为模型变得保守，它会漏掉很多“不太确定但确实是正类”的样本（FN 增加），导致“找全”的能力（TP / (TP+FN)）下降。\n\n这就是 Precision-Recall 权衡。",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>第四讲：分类问题、决策树与评估指标</span>"
    ]
  },
  {
    "objectID": "w5_ensemble_learning.html",
    "href": "w5_ensemble_learning.html",
    "title": "7  第五讲：集成学习 - 随机森林与 GBDT",
    "section": "",
    "text": "7.1 开场：单棵树的困境",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>第五讲：集成学习 - 随机森林与 GBDT</span>"
    ]
  },
  {
    "objectID": "w5_ensemble_learning.html#开场单棵树的困境",
    "href": "w5_ensemble_learning.html#开场单棵树的困境",
    "title": "7  第五讲：集成学习 - 随机森林与 GBDT",
    "section": "",
    "text": "7.1.1 上周回顾\n决策树：\n\n易于理解和可视化\n能处理非线性问题\n但有一个致命问题…\n\n\n\n7.1.2 过拟合演示\n\n\n代码\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score\n\n# 模拟数据\nnp.random.seed(42)\nX = np.random.rand(100, 2) * 10\ny = ((X[:, 0] &gt; 5) & (X[:, 1] &gt; 5)).astype(int)\n# 添加噪声\nnoise_idx = np.random.choice(100, 10, replace=False)\ny[noise_idx] = 1 - y[noise_idx]\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n\n# 训练不同深度的树\ndepths = [2, 5, 10, None]\nfig, axes = plt.subplots(1, 4, figsize=(16, 4))\n\nfor idx, depth in enumerate(depths):\n    tree = DecisionTreeClassifier(max_depth=depth, random_state=42)\n    tree.fit(X_train, y_train)\n    \n    train_acc = accuracy_score(y_train, tree.predict(X_train))\n    test_acc = accuracy_score(y_test, tree.predict(X_test))\n    \n    # 决策边界\n    xx, yy = np.meshgrid(np.linspace(0, 10, 100), np.linspace(0, 10, 100))\n    Z = tree.predict(np.c_[xx.ravel(), yy.ravel()]).reshape(xx.shape)\n    \n    axes[idx].contourf(xx, yy, Z, alpha=0.3, cmap='RdYlBu')\n    axes[idx].scatter(X_train[:, 0], X_train[:, 1], c=y_train, cmap='RdYlBu', edgecolors='k', s=50)\n    axes[idx].set_title(f'深度={depth}\\n训练={train_acc:.2f} 测试={test_acc:.2f}')\n    axes[idx].set_xlabel('特征 1')\n    axes[idx].set_ylabel('特征 2')\n\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\n\n观察：\n\n深度=2：欠拟合（训练和测试都差）\n深度=5：恰好（训练和测试接近）\n深度=10 或无限制：过拟合（训练完美，测试很差）\n\n\n\n7.1.3 本周的解决方案\n核心思想：“三个臭皮匠，顶个诸葛亮”\n不再依赖单棵树，而是：\n\n训练多棵不同的树\n让它们共同决策（投票/平均）\n减少过拟合，提高稳定性\n\n这就是 集成学习（Ensemble Learning）\n\n\n7.1.4 本周学习目标\n\n7.1.4.1 知识目标\n\n理解集成学习的核心思想\n掌握 Bagging 和 Boosting 的本质区别\n了解随机森林的工作原理\n了解 GBDT 的工作原理\n理解关键超参数的作用\n\n\n\n7.1.4.2 技能目标\n\n使用 sklearn 训练随机森林\n使用 LightGBM 训练 GBDT\n进行超参数调整\n对比多个模型性能\n绘制特征重要性图",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>第五讲：集成学习 - 随机森林与 GBDT</span>"
    ]
  },
  {
    "objectID": "w5_ensemble_learning.html#第一部分集成学习核心思想",
    "href": "w5_ensemble_learning.html#第一部分集成学习核心思想",
    "title": "7  第五讲：集成学习 - 随机森林与 GBDT",
    "section": "7.2 第一部分：集成学习核心思想",
    "text": "7.2 第一部分：集成学习核心思想\n\n7.2.1 类比：专家团队 vs 单个专家\n\n7.2.1.1 单个专家（单棵树）\n\n可能有盲点\n受个人经验限制\n容易出错\n\n\n\n7.2.1.2 专家团队（多棵树）\n\n多个视角\n互补长短\n投票决策，更可靠\n\n\n\n\n7.2.2 集成学习的数学直觉\n假设每个模型准确率 60%（略强于随机猜测 50%）\n\n1 个模型：准确率 60%\n3 个模型投票：至少 2 个正确的概率 ≈ 65%\n5 个模型投票：至少 3 个正确的概率 ≈ 68%\n更多模型：准确率持续提升\n\n前提：各模型的错误要独立（不能都在同一个地方出错）\n\n\n7.2.3 如何保证模型”不一样”？\n\n\n\n\n\ngraph TD\n    A[如何让多个模型不同?] --&gt; B[Bagging&lt;br/&gt;数据随机]\n    A --&gt; C[Boosting&lt;br/&gt;关注错误]\n    \n    B --&gt; B1[每个模型用不同的训练数据]\n    B --&gt; B2[代表: 随机森林]\n    \n    C --&gt; C1[后面的模型专注于&lt;br/&gt;前面模型的错误]\n    C --&gt; C2[代表: GBDT/XGBoost]\n    \n    style B fill:#c8e6c9\n    style C fill:#bbdefb",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>第五讲：集成学习 - 随机森林与 GBDT</span>"
    ]
  },
  {
    "objectID": "w5_ensemble_learning.html#第二部分bagging-与随机森林",
    "href": "w5_ensemble_learning.html#第二部分bagging-与随机森林",
    "title": "7  第五讲：集成学习 - 随机森林与 GBDT",
    "section": "7.3 第二部分：Bagging 与随机森林",
    "text": "7.3 第二部分：Bagging 与随机森林\n\n7.3.1 Bagging 原理\nBagging = Bootstrap Aggregating\n\n7.3.1.1 Step 1: Bootstrap（自助采样）\n问题：只有一份训练数据，如何创造多份不同的数据？\n方法：有放回地随机抽样\n\n\n代码\n# 演示 Bootstrap\nnp.random.seed(42)\noriginal_data = np.array([1, 2, 3, 4, 5, 6, 7, 8, 9, 10])\n\nfig, axes = plt.subplots(1, 4, figsize=(16, 4))\n\naxes[0].bar(range(len(original_data)), original_data, color='skyblue')\naxes[0].set_title('原始数据 (10个样本)', fontsize=12)\naxes[0].set_xlabel('索引')\naxes[0].set_ylabel('值')\n\nfor i in range(1, 4):\n    bootstrap_sample = np.random.choice(original_data, size=10, replace=True)\n    axes[i].bar(range(len(bootstrap_sample)), bootstrap_sample, alpha=0.7)\n    axes[i].set_title(f'Bootstrap 样本 {i}', fontsize=12)\n    axes[i].set_xlabel('索引')\n    axes[i].set_ylabel('值')\n    axes[i].set_ylim(0, 11)\n    \n    # 标注哪些是重复的\n    unique_count = len(np.unique(bootstrap_sample))\n    axes[i].text(0.5, 10, f'唯一值: {unique_count}/10', fontsize=10, ha='center')\n\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\n\n特点：\n\n每个 Bootstrap 样本大小与原数据相同\n某些样本会被重复选中\n约 63% 的唯一样本（其余是重复）\n\n\n\n7.3.1.2 Step 2: Aggregating（聚合）\n\n\n\n\n\ngraph TD\n    A[原始训练数据&lt;br/&gt;1000个样本] --&gt; B[Bootstrap 1]\n    A --&gt; C[Bootstrap 2]\n    A --&gt; D[Bootstrap 3]\n    A --&gt; E[...]\n    A --&gt; F[Bootstrap M]\n    \n    B --&gt; G[树1]\n    C --&gt; H[树2]\n    D --&gt; I[树3]\n    E --&gt; J[...]\n    F --&gt; K[树M]\n    \n    G --&gt; L[投票/平均]\n    H --&gt; L\n    I --&gt; L\n    J --&gt; L\n    K --&gt; L\n    \n    L --&gt; M[最终预测]\n    \n    style A fill:#fff9c4\n    style L fill:#c8e6c9\n    style M fill:#4caf50,color:#fff\n\n\n\n\n\n\n\n\n7.3.1.3 Bagging 完整流程\n\n重复 M 次：\n\n从训练集中 Bootstrap 采样\n在该样本上训练一棵树\n\n预测时：\n\n分类：M 棵树投票，多数票获胜\n回归：M 棵树预测值的平均\n\n为什么有效：\n\n每棵树看到不同的数据\n每棵树的误差方向不同\n投票后误差相互抵消\n\n\n\n\n\n7.3.2 随机森林（Random Forest）\n随机森林 = Bagging + 特征随机\n\n7.3.2.1 额外的随机性：特征随机选择\n问题：如果某个特征特别强（如 Titanic 中的性别），所有树都会优先用它分裂 → 树之间太相似\n解决：每次分裂时，只考虑 随机选择的一部分特征\n\n\n7.3.2.2 特征随机演示\n\n\n\n\n\ngraph TD\n    A[9个特征] --&gt; B[每次分裂时]\n    B --&gt; C[随机选3个特征&lt;br/&gt;√9≈3]\n    \n    C --&gt; D[树1选: 特征2, 5, 8]\n    C --&gt; E[树2选: 特征1, 3, 6]\n    C --&gt; F[树3选: 特征4, 7, 9]\n    \n    D --&gt; G[树之间更不同]\n    E --&gt; G\n    F --&gt; G\n    \n    G --&gt; H[集成效果更好]\n    \n    style C fill:#fff9c4\n    style H fill:#4caf50,color:#fff\n\n\n\n\n\n\n常用规则：\n\n分类：每次考虑 \\(\\sqrt{p}\\) 个特征（p = 总特征数）\n回归：每次考虑 \\(p/3\\) 个特征\n\n\n\n\n7.3.3 随机森林关键参数\n\n\n\n\n\n\n\n\n\n参数\n含义\n默认值\n调参建议\n\n\n\n\nn_estimators\n树的数量\n100\n越多越好（但速度慢）50-200\n\n\nmax_depth\n每棵树的最大深度\nNone\n通常 5-20防止过拟合\n\n\nmax_features\n每次分裂考虑的特征数\n√p\n可尝试 log₂(p)\n\n\nmin_samples_split\n分裂所需最小样本数\n2\n增大防止过拟合5-20\n\n\nmin_samples_leaf\n叶节点最小样本数\n1\n增大防止过拟合2-10\n\n\n\n\n\n7.3.4 随机森林 vs 单棵决策树\n\n\n\n维度\n决策树\n随机森林\n\n\n\n\n偏差\n低\n低\n\n\n方差\n高（易过拟合）\n低（稳定） ✓\n\n\n训练速度\n快\n慢（M 棵树）\n\n\n预测速度\n快\n慢（M 次预测）\n\n\n可解释性\n高\n低（黑盒）\n\n\n准确率\n中\n高 ✓\n\n\n\n核心优势：降低方差，防止过拟合",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>第五讲：集成学习 - 随机森林与 GBDT</span>"
    ]
  },
  {
    "objectID": "w5_ensemble_learning.html#第三部分boosting-与-gbdt",
    "href": "w5_ensemble_learning.html#第三部分boosting-与-gbdt",
    "title": "7  第五讲：集成学习 - 随机森林与 GBDT",
    "section": "7.4 第三部分：Boosting 与 GBDT",
    "text": "7.4 第三部分：Boosting 与 GBDT\n\n7.4.1 Boosting 核心思想\nBagging：独立专家各自诊断，最后投票\nBoosting：第一个医生诊断，第二个医生专门看第一个医生漏掉的症状\n\n7.4.1.1 Bagging vs Boosting\n\n\n\n\n\ngraph TD\n    A[Bagging] --&gt; A1[并行训练]\n    A --&gt; A2[数据: Bootstrap]\n    A --&gt; A3[目标: 降低方差]\n    A --&gt; A4[代表: 随机森林]\n    \n    B[Boosting] --&gt; B1[串行训练]\n    B --&gt; B2[数据: 加权/残差]\n    B --&gt; B3[目标: 降低偏差]\n    B --&gt; B4[代表: GBDT/XGBoost]\n    \n    style A fill:#c8e6c9\n    style B fill:#bbdefb\n\n\n\n\n\n\n\n\n7.4.1.2 Boosting 流程\n\n\n\n\n\ngraph LR\n    A[训练集] --&gt; B[树1]\n    B --&gt; C[找出错误样本]\n    C --&gt; D[树2&lt;br/&gt;专注错误]\n    D --&gt; E[再找错误]\n    E --&gt; F[树3&lt;br/&gt;继续修正]\n    F --&gt; G[...]\n    G --&gt; H[组合所有树]\n    \n    style B fill:#fff9c4\n    style D fill:#ffccbc\n    style F fill:#ffccbc\n    style H fill:#4caf50,color:#fff\n\n\n\n\n\n\n关键：后面的树专注于前面树的错误\n\n\n\n7.4.2 GBDT 原理\nGBDT = Gradient Boosting Decision Tree\n核心思想：每棵新树去拟合之前所有树的”预测误差”（残差）\n\n7.4.2.1 GBDT 示例（回归）\n数据：真实房价 [100, 150, 200]\nStep 1：初始预测 = 平均值 = 150\n真实值: [100, 150, 200]\n预测值: [150, 150, 150]\n残差:   [-50,   0,  50]\nStep 2：训练树1 拟合残差 [-50, 0, 50]\n假设树1学到：预测残差 = [-45, 0, 45]\n更新预测 = 150 + 0.1 × [-45, 0, 45] = [145.5, 150, 154.5]\n（0.1 是学习率）\nStep 3：计算新残差\n真实值: [100, 150, 200]\n预测值: [145.5, 150, 154.5]\n新残差: [-45.5,   0,  45.5]\nStep 4：训练树2 拟合新残差，继续更新…\n\n\n7.4.2.2 GBDT 可视化\n\n\n代码\n# GBDT 逐步修正示意\nnp.random.seed(42)\nX_demo = np.linspace(0, 10, 50).reshape(-1, 1)\ny_demo = 2*X_demo.flatten() + 3 + np.random.randn(50)*2\n\nfrom sklearn.ensemble import GradientBoostingRegressor\n\nfig, axes = plt.subplots(2, 2, figsize=(14, 10))\n\nstages = [1, 5, 20, 100]\nfor idx, n_estimators in enumerate(stages):\n    ax = axes[idx//2, idx%2]\n    \n    gbdt = GradientBoostingRegressor(n_estimators=n_estimators, learning_rate=0.1, \n                                      max_depth=3, random_state=42)\n    gbdt.fit(X_demo, y_demo)\n    y_pred = gbdt.predict(X_demo)\n    \n    ax.scatter(X_demo, y_demo, alpha=0.5, label='真实数据')\n    ax.plot(X_demo, y_pred, 'r-', linewidth=2, label=f'{n_estimators}棵树')\n    ax.set_xlabel('X')\n    ax.set_ylabel('y')\n    ax.set_title(f'GBDT - {n_estimators} 棵树')\n    ax.legend()\n    ax.grid(True, alpha=0.3)\n\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\n\n观察：随着树数量增加，拟合越来越精确\n\n\n\n7.4.3 GBDT 关键参数\n\n\n\n参数\n含义\n默认值\n调参建议\n\n\n\n\nn_estimators\n树的数量\n100\n100-1000配合 learning_rate\n\n\nlearning_rate\n学习率\n0.1\n0.01-0.3越小需要越多树\n\n\nmax_depth\n树的深度\n3\n3-8通常用浅树\n\n\nsubsample\n每次迭代用多少数据\n1.0\n0.8-1.0防止过拟合\n\n\n\n\n7.4.3.1 学习率的作用\n\n\n代码\n# 学习率对比\nfig, axes = plt.subplots(1, 3, figsize=(15, 5))\n\nlearning_rates = [0.01, 0.1, 0.5]\n\nfor idx, lr in enumerate(learning_rates):\n    ax = axes[idx]\n    \n    train_scores = []\n    test_scores = []\n    \n    for n in range(1, 101):\n        gbdt = GradientBoostingRegressor(n_estimators=n, learning_rate=lr, \n                                          max_depth=3, random_state=42)\n        gbdt.fit(X_demo, y_demo)\n        train_scores.append(gbdt.score(X_demo, y_demo))\n    \n    ax.plot(range(1, 101), train_scores, label=f'lr={lr}')\n    ax.set_xlabel('树的数量')\n    ax.set_ylabel('R² 分数')\n    ax.set_title(f'学习率 = {lr}')\n    ax.legend()\n    ax.grid(True, alpha=0.3)\n\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\n\n规律：\n\nlr 小（0.01）：收敛慢，需要更多树，但最终可能更好\nlr 大（0.5）：收敛快，但容易过拟合",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>第五讲：集成学习 - 随机森林与 GBDT</span>"
    ]
  },
  {
    "objectID": "w5_ensemble_learning.html#总结",
    "href": "w5_ensemble_learning.html#总结",
    "title": "7  第五讲：集成学习 - 随机森林与 GBDT",
    "section": "7.5 总结",
    "text": "7.5 总结\n\n7.5.1 本讲知识回顾\n\n7.5.1.1 集成学习\n\n核心思想：“三个臭皮匠顶个诸葛亮”\n关键：让多个模型”不一样”\n\n\n\n7.5.1.2 Bagging（随机森林）\n\n方法：Bootstrap 采样 + 特征随机\n优点：降低方差，防止过拟合\n适用：数据噪声大、需要稳定模型\n\n\n\n7.5.1.3 Boosting（GBDT）\n\n方法：串行训练，逐步修正错误\n优点：降低偏差，精度高\n适用：数据干净、追求极致精度\n\n\n\n\n7.5.2 Bagging vs Boosting 总结\n\n\n\n维度\nBagging（随机森林）\nBoosting（GBDT）\n\n\n\n\n训练方式\n并行\n串行\n\n\n数据\nBootstrap\n加权/残差\n\n\n降低\n方差（过拟合）\n偏差（欠拟合）\n\n\n速度\n可并行，较快\n串行，较慢\n\n\n鲁棒性\n对异常值鲁棒\n对异常值敏感\n\n\n调参\n较简单\n较复杂\n\n\n何时用\n数据噪声大\n数据干净、追求精度\n\n\n\n选择建议：\n\n不确定 → 都试试\n需要稳定 → 随机森林\n追求精度 → GBDT\n\n\n\n7.5.3 实战要点\n\n先用默认参数跑通\n了解基线性能\n对比多个模型\n决策树 vs 随机森林 vs GBDT\n查看特征重要性\n了解哪些特征重要\n调参时控制变量\n一次只改一个参数\n警惕过拟合\n训练集和测试集差距过大是警报",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>第五讲：集成学习 - 随机森林与 GBDT</span>"
    ]
  },
  {
    "objectID": "w5_ensemble_learning.html#qa",
    "href": "w5_ensemble_learning.html#qa",
    "title": "7  第五讲：集成学习 - 随机森林与 GBDT",
    "section": "7.6 Q&A",
    "text": "7.6 Q&A\nQ1：集成学习（Ensemble Learning）试图解决单棵决策树的什么核心问题？\nA： 核心问题是过拟合（Overfitting）。单棵决策树如果深度没有限制，很容易学到训练数据中的噪声，导致训练集表现完美，但测试集表现很差。集成学习通过组合多棵树的决策来降低这种过拟合，提高模型的稳定性和泛化能力。\nQ2：Bagging（例如随机森林）和 Boosting（例如 GBDT）在训练模型时，最核心的区别是什么？\nA： 最核心的区别在于模型的训练方式：\n\nBagging (并行)：像一个“专家团队”，每棵树（专家）独立并行地在不同的数据子集上训练，最后“投票”决定结果。\nBoosting (串行)：像一个“师徒体系”，树（学徒）是串行训练的，后一棵树的主要任务是专注于修正前一棵树犯下的错误（残差）。\n\nQ3：随机森林（Random Forest）中的“随机”体现在哪两个方面？\nA： 体现在两个方面：\n\n数据随机（Bootstrap）：每棵树的训练数据都是从原始数据集中有放回地随机抽样（Bootstrap）得到的。\n特征随机：在构建每棵树的每个分裂节点时，并不会考虑所有特征，而是随机选择一部分特征（例如 \\(\\sqrt{p}\\) 个）作为候选，再从中选择最好的分裂点。\n\nQ4：GBDT (梯度提升决策树) 的核心思想是什么？（即，后一棵树是如何“修正”前一棵树的？）\nA： GBDT 的核心思想是拟合残差（Residuals）。\n\n模型从一个初始预测（例如平均值）开始。\n第一棵树训练的目标是拟合真实值与初始预测之间的误差（残差）。\n第二棵树训练的目标是拟合真实值与“初始预测+第一棵树预测”之间的新残差。\n以此类推，每棵新树都在逐步修正前面所有树累积下来的预测误差。\n\nQ5：Bagging（随机森林）和 Boosting（GBDT）分别主要致力于降低哪种误差（偏差 vs 方差）？\nA：\n\nBagging (随机森林) 主要通过平均/投票来抵消噪声，降低方差（Variance），解决的是过拟合问题。\nBoosting (GBDT) 主要通过不断修正错误来提高模型精度，降低偏差（Bias），解决的是欠拟合问题。\n\nQ6：为什么随机森林在“数据随机”之外，还需要引入“特征随机”？\nA： 这是为了“去相关性”，保证树的多样性。\n\n问题：假设数据中有一个特征（例如“性别”）特别重要，如果 Bagging 时每棵树都能看到所有特征，那么几乎每棵树都会在根节点附近使用这个强特征进行分裂。\n后果：这会导致所有树的结构都非常相似，它们会犯同样的错误。\n解决：“特征随机”强迫一些树在分裂时“看不到”那个强特征，必须寻找其他次优特征来分裂。这使得每棵树长得更不一样，它们之间的相关性降低，集成“投票”时的纠错能力更强，最终的集成效果更好。\n\nQ7：在 GBDT 中，learning_rate（学习率）和 n_estimators（树的数量）之间是什么关系？我们为什么通常倾向于使用“较小”的学习率？\nA：\n\n关系：它们是权衡（Trade-off）关系。learning_rate 控制了每棵树修正错误的“步长”。\n\n高 learning_rate (如 0.5)：收敛快，但可能“冲过头”导致过拟合，需要的 n_estimators 较少。\n低 learning_rate (如 0.01)：收敛慢，模型拟合更精细，需要更多的 n_estimators (树) 才能达到同样的拟合程度，但通常泛化能力更强。\n\n为何用较小的 LR：我们倾向于用“较小”的学习率（如 0.01-0.1）配合“较多”的树（n_estimators），这被称为“Shrinkage”。这使得模型在修正错误的道路上“小步慢走”，防止在训练过程中过早地过拟合，从而找到一个更稳健、泛化能力更强的最终模型。\n\nQ8：为什么 Boosting (GBDT) 对异常值（Outliers）比 Bagging (随机森林) 更敏感？\nA： * Boosting (GBDT)：因为 GBDT 的核心机制是串行地关注错误（残差）。异常值（Outlier）通常会产生巨大的残差。在后续的迭代中，GBDT 会越来越“专注”地试图去拟合这个由异常值导致的巨大残差，这会扭曲整个模型，导致模型为了迁就一个异常点而牺牲了整体的泛化能力。 * Bagging (随机森林)：随机森林是并行地，且最后通过投票或平均来聚合结果。异常值可能只会影响到少数（包含该异常值的 Bootstrap 样本）树的决策，但在最终的“民主投票”中，这些少数树的错误决策很容易被其他大量正确的树“淹没”或“平均掉”，因此模型整体表现更稳健（鲁棒）。\nQ9：在 GBDT 和随机森林中，我们通常对单棵树的 max_depth（最大深度）有截然不同的设置（一个深一个浅）。请问哪个模型通常使用“浅树”，哪个使用“深树”，为什么？\nA：\n\nGBDT (Boosting)：通常使用“浅树”（例如 max_depth = 3 到 8）。\n\n原因：GBDT 的强大之处在于“集成”而非“单树”。它依靠大量简单的（高偏差、低方差）浅树串行叠加，逐步降低整体模型的偏差。如果单棵树太深（低偏差、高方差），模型会过快地过拟合，失去 Boosting 的优势。\n\n随机森林 (Bagging)：通常使用“深树”（例如 max_depth = None 或 10-20），让树充分生长。\n\n原因：随机森林的目标是降低方差。它希望每棵树都是一个“低偏差、高方差”的“聪明但偏科”的专家。通过让每棵树充分生长（深树）来保证“低偏差”（拟合能力强）。然后通过 Bagging 和特征随机来保证树之间的差异性，最后通过“投票”来消除“高方差”，实现整体的低方差。",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>第五讲：集成学习 - 随机森林与 GBDT</span>"
    ]
  },
  {
    "objectID": "w6_neural_networks.html",
    "href": "w6_neural_networks.html",
    "title": "8  第六讲：神经网络基础",
    "section": "",
    "text": "8.1 开场：深度学习的神秘面纱",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>第六讲：神经网络基础</span>"
    ]
  },
  {
    "objectID": "w6_neural_networks.html#开场深度学习的神秘面纱",
    "href": "w6_neural_networks.html#开场深度学习的神秘面纱",
    "title": "8  第六讲：神经网络基础",
    "section": "",
    "text": "8.1.1 深度学习无处不在\n你每天都在使用深度学习：\n\n📱 手机人脸解锁\n🗣️ 语音助手（Siri、小爱）\n📷 拍照美颜\n🚗 自动驾驶\n💬 ChatGPT\n\n问题：这些”黑科技”的底层原理是什么？\n答案：神经网络\n\n\n8.1.2 本周目标：揭开神秘面纱\n\n8.1.2.1 知识目标\n\n理解神经元的基本概念\n理解多层感知机（MLP）的网络结构\n了解常见激活函数（ReLU、Sigmoid、Tanh）\n理解前向传播和反向传播的直觉\n知道何时用树模型 vs 神经网络\n\n\n\n8.1.2.2 技能目标\n\n使用 Keras 搭建简单的 MLP\n训练 MLP 并可视化学习曲线\n在测试集上评估 MLP 的 AUC\n调整网络结构（层数、神经元数量）\n\n\n\n8.1.2.3 核心理念\n深度学习不神秘\n\n它是基于简单数学运算的累积\n关键是”学习”：通过数据自动调整参数\n不要被复杂的公式吓倒，先建立直觉！",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>第六讲：神经网络基础</span>"
    ]
  },
  {
    "objectID": "w6_neural_networks.html#第一部分从生物到人工",
    "href": "w6_neural_networks.html#第一部分从生物到人工",
    "title": "8  第六讲：神经网络基础",
    "section": "8.2 第一部分：从生物到人工",
    "text": "8.2 第一部分：从生物到人工\n\n8.2.1 1.1 生物神经元\n\n8.2.1.1 人脑的神经网络\n\n人脑约有 860 亿个神经元\n每个神经元连接 数千到上万个其他神经元\n通过电信号传递信息\n学习 = 调整神经元之间的连接强度\n\n\n\n8.2.1.2 生物神经元的结构\n\n\n\n\n\ngraph LR\n    A[树突&lt;br/&gt;Dendrites&lt;br/&gt;接收信号] --&gt; B[细胞体&lt;br/&gt;Soma&lt;br/&gt;整合处理]\n    B --&gt; C[轴突&lt;br/&gt;Axon&lt;br/&gt;输出信号]\n    C --&gt; D[突触&lt;br/&gt;Synapse&lt;br/&gt;连接下一个神经元]\n    \n    style A fill:#fff9c4\n    style B fill:#c8e6c9\n    style C fill:#bbdefb\n    style D fill:#ffccbc\n\n\n\n\n\n\n关键过程：\n\n树突接收多个输入信号\n细胞体对信号进行加权求和\n如果总和超过阈值，神经元”发火”（激活）\n通过轴突传递信号给下一个神经元\n\n\n\n\n8.2.2 1.2 人工神经元\n\n8.2.2.1 数学模型\n简化的神经元模型（1943年，McCulloch & Pitts）：\n\\[\ny = f\\left(\\sum_{i=1}^{n} w_i x_i + b\\right)\n\\]\n组成部分：\n\n\\(x_i\\)：输入信号（特征）\n\\(w_i\\)：权重（连接强度）\n\\(b\\)：偏置（阈值）\n\\(f\\)：激活函数（决定是否”发火”）\n\\(y\\)：输出\n\n\n\n8.2.2.2 可视化人工神经元\n\n\n\n\n\ngraph LR\n    X1[x₁] --&gt;|w₁| S((Σ))\n    X2[x₂] --&gt;|w₂| S\n    X3[x₃] --&gt;|w₃| S\n    B[+b] --&gt; S\n    S --&gt; F[激活函数&lt;br/&gt;f]\n    F --&gt; Y[y]\n    \n    style S fill:#fff9c4\n    style F fill:#c8e6c9\n    style Y fill:#4caf50,color:#fff\n\n\n\n\n\n\n步骤 1：加权求和\n\\[\nz = w_1 x_1 + w_2 x_2 + w_3 x_3 + b\n\\]\n步骤 2：激活\n\\[\ny = f(z)\n\\]\n\n\n8.2.2.3 具体例子：Titanic 生存预测\n特征：\n\n\\(x_1\\) = 性别（1=男，0=女）\n\\(x_2\\) = 年龄\n\\(x_3\\) = 票价\n\n假设权重：\n\n\\(w_1 = -2\\)（性别越男越不利）\n\\(w_2 = -0.01\\)（年龄越大越不利）\n\\(w_3 = 0.001\\)（票价越高越有利）\n\\(b = 1\\)（基础偏置）\n\n计算过程：\n男性乘客：x₁=1, x₂=25, x₃=50\nz = (-2)×1 + (-0.01)×25 + 0.001×50 + 1\n  = -2 - 0.25 + 0.05 + 1\n  = -1.2\n\n经过 Sigmoid 激活：\ny = 1/(1+e^1.2) ≈ 0.23\n\n解释：存活概率 23%（较低）\n权重的含义：\n\n\\(w_1 = -2\\)：性别对生存影响最大\n负权重表示负相关\n权重的绝对值表示重要性",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>第六讲：神经网络基础</span>"
    ]
  },
  {
    "objectID": "w6_neural_networks.html#第二部分激活函数",
    "href": "w6_neural_networks.html#第二部分激活函数",
    "title": "8  第六讲：神经网络基础",
    "section": "8.3 第二部分：激活函数",
    "text": "8.3 第二部分：激活函数\n\n8.3.1 为什么需要激活函数？\n没有激活函数的问题：\n\\[\n\\begin{align}\n\\text{层1: } &h_1 = W_1 x + b_1 \\\\\n\\text{层2: } &h_2 = W_2 h_1 + b_2 = W_2(W_1 x + b_1) + b_2 \\\\\n&= (W_2 W_1) x + (W_2 b_1 + b_2) \\\\\n&= W' x + b' \\quad \\text{（仍然是线性）}\n\\end{align}\n\\]\n结论：多层线性叠加 = 单层线性\n激活函数的作用：引入非线性，让网络能学习复杂模式\n\n\n8.3.2 常见激活函数\n\\[\n\\sigma(z) = \\frac{1}{1 + e^{-z}}\n\\]\n\n\n代码\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\nz = np.linspace(-6, 6, 100)\n\nsigmoid = 1 / (1 + np.exp(-z))\nrelu = np.maximum(0, z)\ntanh = np.tanh(z)\n\nfig, axes = plt.subplots(1, 3, figsize=(15, 5))\n\n# Sigmoid\naxes[0].plot(z, sigmoid, linewidth=3, color='#2196f3')\naxes[0].axhline(y=0, color='k', linestyle='--', alpha=0.3)\naxes[0].axhline(y=1, color='k', linestyle='--', alpha=0.3)\naxes[0].axvline(x=0, color='k', linestyle='--', alpha=0.3)\naxes[0].set_xlabel('z', fontsize=12)\naxes[0].set_ylabel('σ(z)', fontsize=12)\naxes[0].set_title('Sigmoid', fontsize=14)\naxes[0].grid(True, alpha=0.3)\naxes[0].set_ylim(-0.1, 1.1)\naxes[0].text(3, 0.5, '输出: (0, 1)', fontsize=11, bbox=dict(boxstyle='round', facecolor='wheat'))\n\n# ReLU\naxes[1].plot(z, relu, linewidth=3, color='#4caf50')\naxes[1].axhline(y=0, color='k', linestyle='--', alpha=0.3)\naxes[1].axvline(x=0, color='k', linestyle='--', alpha=0.3)\naxes[1].set_xlabel('z', fontsize=12)\naxes[1].set_ylabel('ReLU(z)', fontsize=12)\naxes[1].set_title('ReLU', fontsize=14)\naxes[1].grid(True, alpha=0.3)\naxes[1].text(3, 3, '输出: [0, ∞)', fontsize=11, bbox=dict(boxstyle='round', facecolor='wheat'))\n\n# Tanh\naxes[2].plot(z, tanh, linewidth=3, color='#ff9800')\naxes[2].axhline(y=0, color='k', linestyle='--', alpha=0.3)\naxes[2].axhline(y=1, color='k', linestyle='--', alpha=0.3)\naxes[2].axhline(y=-1, color='k', linestyle='--', alpha=0.3)\naxes[2].axvline(x=0, color='k', linestyle='--', alpha=0.3)\naxes[2].set_xlabel('z', fontsize=12)\naxes[2].set_ylabel('tanh(z)', fontsize=12)\naxes[2].set_title('Tanh', fontsize=14)\naxes[2].grid(True, alpha=0.3)\naxes[2].set_ylim(-1.1, 1.1)\naxes[2].text(3, 0, '输出: (-1, 1)', fontsize=11, bbox=dict(boxstyle='round', facecolor='wheat'))\n\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\n\n\n8.3.2.1 Sigmoid 详解\n公式：\n\\[\n\\sigma(z) = \\frac{1}{1 + e^{-z}}\n\\]\n特点：\n\n输出范围：(0, 1)\nS 形曲线，平滑\n可解释为概率\n\n优点：\n\n输出有界，稳定\n适合二分类输出层\n\n缺点：\n\n梯度消失：当 \\(|z|\\) 很大时，梯度接近 0\n计算成本高（指数运算）\n\n使用场景：\n\n✓ 二分类问题的输出层\n✗ 隐藏层（已被 ReLU 取代）\n\n\n\n8.3.2.2 ReLU 详解\n公式：\n\\[\n\\text{ReLU}(z) = \\max(0, z) = \\begin{cases}\nz & \\text{if } z &gt; 0 \\\\\n0 & \\text{if } z \\leq 0\n\\end{cases}\n\\]\n优点：\n\n⚡ 计算超快（只是比较和选择）\n🎯 缓解梯度消失（\\(z&gt;0\\) 时梯度恒为 1）\n🧠 生物学合理性（神经元要么激活要么不激活）\n📊 稀疏激活（约 50% 神经元输出 0）\n\n缺点：\n\n💀 “神经元死亡”：某些神经元可能永远输出 0\n\n使用场景：\n\n✓ 隐藏层首选\n✓ 绝大多数深度学习任务\n\n\n\n8.3.2.3 Tanh 详解\n公式：\n\\[\n\\tanh(z) = \\frac{e^z - e^{-z}}{e^z + e^{-z}}\n\\]\n特点：\n\n输出范围：(-1, 1)\n零中心（Sigmoid 不是）\n比 Sigmoid 更陡\n\n优点：\n\n零中心 → 收敛更快\n输出范围对称\n\n缺点：\n\n仍有梯度消失问题\n计算成本高\n\n使用场景：\n\n循环神经网络（RNN）\n需要零中心输出的场景\n\n\n\n8.3.2.4 激活函数对比表\n\n\n\n\n\n\n\n\n\n\n激活函数\n范围\n优点\n缺点\n主要用途\n\n\n\n\nSigmoid\n(0, 1)\n概率解释平滑\n梯度消失计算慢\n二分类输出层\n\n\nReLU\n[0, ∞)\n快速缓解梯度消失\n神经元死亡\n隐藏层首选\n\n\nTanh\n(-1, 1)\n零中心对称\n梯度消失计算慢\nRNN\n\n\n\n经验法则：\n\n隐藏层：优先选 ReLU\n输出层：\n\n二分类 → Sigmoid\n多分类 → Softmax（后续会学）\n回归 → 不用激活（线性输出）",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>第六讲：神经网络基础</span>"
    ]
  },
  {
    "objectID": "w6_neural_networks.html#第三部分多层感知机mlp",
    "href": "w6_neural_networks.html#第三部分多层感知机mlp",
    "title": "8  第六讲：神经网络基础",
    "section": "8.4 第三部分：多层感知机（MLP）",
    "text": "8.4 第三部分：多层感知机（MLP）\n\n8.4.1 网络结构\n\n8.4.1.1 从单个神经元到神经网络\n\n\n\n\n\ngraph LR\n    subgraph 输入层\n    X1[特征1]\n    X2[特征2]\n    X3[特征3]\n    end\n    subgraph 隐藏层1\n    H11[神经元1]\n    H12[神经元2]\n    H13[神经元3]\n    H14[神经元4]\n    end\n    subgraph 隐藏层2\n    H21[神经元1]\n    H22[神经元2]\n    end\n    subgraph 输出层\n    Y[预测]\n    end\n\n    X1 --&gt; H11\n    X1 --&gt; H12\n    X1 --&gt; H13\n    X1 --&gt; H14\n    X2 --&gt; H11\n    X2 --&gt; H12\n    X2 --&gt; H13\n    X2 --&gt; H14\n    X3 --&gt; H11\n    X3 --&gt; H12\n    X3 --&gt; H13\n    X3 --&gt; H14\n\n    H11 --&gt; H21\n    H11 --&gt; H22\n    H12 --&gt; H21\n    H12 --&gt; H22\n    H13 --&gt; H21\n    H13 --&gt; H22\n    H14 --&gt; H21\n    H14 --&gt; H22\n\n    H21 --&gt; Y\n    H22 --&gt; Y\n\n    style X1 fill:#fff9c4\n    style X2 fill:#fff9c4\n    style X3 fill:#fff9c4\n    style H11 fill:#c8e6c9\n    style H12 fill:#c8e6c9\n    style H13 fill:#c8e6c9\n    style H14 fill:#c8e6c9\n    style H21 fill:#bbdefb\n    style H22 fill:#bbdefb\n    style Y fill:#4caf50,color:#fff\n    %% subgraph 背景色美化\n    style 输入层 fill:#f8f9fa,stroke:#e0e0e0\n    style 隐藏层1 fill:#f1f8e9,stroke:#aed581\n    style 隐藏层2 fill:#e3f2fd,stroke:#90caf9\n    style 输出层 fill:#fce4ec,stroke:#f06292\n\n\n\n\n\n\n\n\n8.4.1.2 符号表示\n输入层 → 隐藏层1 → 隐藏层2 → 输出层\n\n输入：3 个特征\n隐藏层1：4 个神经元（ReLU）\n隐藏层2：2 个神经元（ReLU）\n输出层：1 个神经元（Sigmoid）\n\n简写：Input(3) → [4] → [2] → Output(1)\n\n\n\n8.4.2 参数数量计算\n\n8.4.2.1 Titanic 例子\nInput(8) → Dense(64, ReLU) → Dense(32, ReLU) → Output(1, Sigmoid)\n计算：\n\n\n\n层\n参数数量\n计算\n\n\n\n\n输入 → 隐藏1\n8×64 + 64 = 576\n权重 + 偏置\n\n\n隐藏1 → 隐藏2\n64×32 + 32 = 2,080\n权重 + 偏置\n\n\n隐藏2 → 输出\n32×1 + 1 = 33\n权重 + 偏置\n\n\n总计\n2,689\n\n\n\n\n对比：\n\n决策树：只有分裂规则（少量参数）\nMLP：数千个参数需要学习\n\n\n\n\n8.4.3 为什么需要多层？\n\n8.4.3.1 单层的局限性\n单层神经网络（= 逻辑回归）：\n\n只能学习线性决策边界\n无法解决 XOR 问题\n\n\n\n代码\n# XOR 问题示例\nfig, axes = plt.subplots(1, 2, figsize=(12, 5))\n\n# XOR 数据\nX_xor = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])\ny_xor = np.array([0, 1, 1, 0])\n\n# 单层无法分类\naxes[0].scatter(X_xor[y_xor==0, 0], X_xor[y_xor==0, 1], s=200, c='red', marker='o', label='类别 0', edgecolors='k', linewidth=2)\naxes[0].scatter(X_xor[y_xor==1, 0], X_xor[y_xor==1, 1], s=200, c='blue', marker='s', label='类别 1', edgecolors='k', linewidth=2)\naxes[0].plot([0, 1], [0.5, 0.5], 'k--', linewidth=2, alpha=0.5, label='线性边界？')\naxes[0].set_xlabel('x₁', fontsize=12)\naxes[0].set_ylabel('x₂', fontsize=12)\naxes[0].set_title('XOR 问题：单层网络无法解决', fontsize=14)\naxes[0].legend(fontsize=10)\naxes[0].set_xlim(-0.2, 1.2)\naxes[0].set_ylim(-0.2, 1.2)\naxes[0].grid(True, alpha=0.3)\n\n# 多层可以分类\nfrom sklearn.neural_network import MLPClassifier\nmlp_xor = MLPClassifier(hidden_layer_sizes=(4,), activation='relu', random_state=42, max_iter=5000)\nmlp_xor.fit(X_xor, y_xor)\n\nxx, yy = np.meshgrid(np.linspace(-0.2, 1.2, 100), np.linspace(-0.2, 1.2, 100))\nZ = mlp_xor.predict(np.c_[xx.ravel(), yy.ravel()]).reshape(xx.shape)\n\naxes[1].contourf(xx, yy, Z, alpha=0.3, cmap='RdBu')\naxes[1].scatter(X_xor[y_xor==0, 0], X_xor[y_xor==0, 1], s=200, c='red', marker='o', label='类别 0', edgecolors='k', linewidth=2)\naxes[1].scatter(X_xor[y_xor==1, 0], X_xor[y_xor==1, 1], s=200, c='blue', marker='s', label='类别 1', edgecolors='k', linewidth=2)\naxes[1].set_xlabel('x₁', fontsize=12)\naxes[1].set_ylabel('x₂', fontsize=12)\naxes[1].set_title('XOR 问题：多层网络可以解决', fontsize=14)\naxes[1].legend(fontsize=10)\naxes[1].set_xlim(-0.2, 1.2)\naxes[1].set_ylim(-0.2, 1.2)\naxes[1].grid(True, alpha=0.3)\n\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\n8.4.3.2 多层的威力：层次特征学习\n\n\n\n\n\ngraph TD\n    A[图像识别例子] --&gt; B[第1层&lt;br/&gt;检测边缘]\n    B --&gt; C[第2层&lt;br/&gt;检测形状]\n    C --&gt; D[第3层&lt;br/&gt;检测物体部件]\n    D --&gt; E[第4层&lt;br/&gt;识别完整物体]\n    \n    style B fill:#fff9c4\n    style C fill:#c8e6c9\n    style D fill:#bbdefb\n    style E fill:#4caf50,color:#fff\n\n\n\n\n\n\n关键洞察：\n\n浅层：学习简单特征（边缘、纹理）\n深层：学习复杂特征（组合模式）\n这是自动特征工程！\n\n\n\n8.4.3.3 层数选择建议\n\n\n\n数据量\n推荐层数\n原因\n\n\n\n\n&lt; 1万\n1-2 层隐藏层\n数据少，深层易过拟合\n\n\n1万-10万\n2-3 层隐藏层\n中等复杂度\n\n\n&gt; 10万\n3-5 层隐藏层\n大数据支持深层网络\n\n\n&gt; 100万\n5+ 层\n需要特殊技巧（下周讲）\n\n\n\n经验法则：\n\n从简单开始（2层）\n如果欠拟合，增加层数或神经元数\n如果过拟合，减少复杂度或使用正则化（下周讲）",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>第六讲：神经网络基础</span>"
    ]
  },
  {
    "objectID": "w6_neural_networks.html#第四部分前向传播与反向传播",
    "href": "w6_neural_networks.html#第四部分前向传播与反向传播",
    "title": "8  第六讲：神经网络基础",
    "section": "8.5 第四部分：前向传播与反向传播",
    "text": "8.5 第四部分：前向传播与反向传播\n\n8.5.1 前向传播（Forward Propagation）\n\n8.5.1.1 从输入到输出的信息流\n\n\n\n\n\ngraph LR\n    A[输入&lt;br/&gt;x] --&gt; B[隐藏层1&lt;br/&gt;h₁ = ReLU W₁x+b₁]\n    B --&gt; C[隐藏层2&lt;br/&gt;h₂ = ReLU W₂h₁+b₂]\n    C --&gt; D[输出&lt;br/&gt;ŷ = σ W₃h₂+b₃]\n    \n    style A fill:#fff9c4\n    style B fill:#c8e6c9\n    style C fill:#bbdefb\n    style D fill:#4caf50,color:#fff\n\n\n\n\n\n\n逐层计算：\n\n输入：\\(x\\) = [性别, 年龄, 票价, …]\n隐藏层1：\\(h_1 = \\text{ReLU}(W_1 x + b_1)\\)\n隐藏层2：\\(h_2 = \\text{ReLU}(W_2 h_1 + b_2)\\)\n输出：\\(\\hat{y} = \\sigma(W_3 h_2 + b_3)\\)\n\n结果：\\(\\hat{y}\\) = 0.85（85% 存活概率）\n\n\n\n8.5.2 损失函数（Loss Function）\n\n8.5.2.1 衡量预测误差\n二分类：Binary Cross-Entropy\n\\[\n\\text{Loss} = -\\frac{1}{n}\\sum_{i=1}^{n}\\left[y_i \\log(\\hat{y}_i) + (1-y_i)\\log(1-\\hat{y}_i)\\right]\n\\]\n直观理解：\n\n真实是 1，预测 0.9 → Loss 小（好）\n真实是 1，预测 0.1 → Loss 大（差）\n\n类比：Loss = 考试分数与满分的差距\n\n\n8.5.2.2 损失函数可视化\n\n\n代码\n# Binary Cross-Entropy 可视化\ny_true_demo = 1  # 真实标签\ny_pred_range = np.linspace(0.01, 0.99, 100)\nloss = -np.log(y_pred_range)\n\nplt.figure(figsize=(10, 6))\nplt.plot(y_pred_range, loss, linewidth=3, color='#f44336')\nplt.xlabel('预测概率 ŷ', fontsize=12)\nplt.ylabel('Loss', fontsize=12)\nplt.title('Binary Cross-Entropy Loss\\n（真实标签 y=1 时）', fontsize=14)\nplt.grid(True, alpha=0.3)\nplt.axvline(x=1, color='green', linestyle='--', linewidth=2, label='完美预测')\nplt.axvline(x=0.5, color='orange', linestyle='--', linewidth=2, label='随机猜测')\nplt.legend(fontsize=11)\n\n# 标注\nplt.text(0.9, 0.5, 'ŷ → 1\\nLoss → 0\\n(预测对了)', fontsize=11, bbox=dict(boxstyle='round', facecolor='#c8e6c9'))\nplt.text(0.1, 4, 'ŷ → 0\\nLoss → ∞\\n(预测错了)', fontsize=11, bbox=dict(boxstyle='round', facecolor='#ffccbc'))\n\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\n\n8.5.3 反向传播（Backpropagation）\n\n8.5.3.1 核心思想（不讲数学细节）\n问题：如何调整 W 和 b 来降低 Loss？\n方法：计算 Loss 对每个参数的”贡献”（梯度）\n\n\n\n\n\ngraph RL\n    A[Loss] --&gt; B[∂Loss/∂W₃&lt;br/&gt;∂Loss/∂b₃]\n    B --&gt; C[∂Loss/∂W₂&lt;br/&gt;∂Loss/∂b₂]\n    C --&gt; D[∂Loss/∂W₁&lt;br/&gt;∂Loss/∂b₁]\n    \n    style A fill:#f44336,color:#fff\n    style B fill:#ffccbc\n    style C fill:#fff9c4\n    style D fill:#c8e6c9\n\n\n\n\n\n\n更新规则：\n\\[\nW_{\\text{new}} = W_{\\text{old}} - \\eta \\times \\frac{\\partial \\text{Loss}}{\\partial W}\n\\]\n\n\\(\\eta\\)：学习率（步长）\n\\(\\frac{\\partial \\text{Loss}}{\\partial W}\\)：梯度（方向）\n\n\n\n8.5.3.2 类比：登山下坡\n\n\n代码\n# 梯度下降可视化\nx = np.linspace(-2, 2, 100)\ny = x**2 + 1  # 简单的凸函数\n\nplt.figure(figsize=(12, 6))\nplt.plot(x, y, linewidth=3, color='#2196f3', label='Loss 曲线')\n\n# 梯度下降路径\nx_path = [1.8, 1.2, 0.7, 0.3, 0.1, 0.0]\ny_path = [xi**2 + 1 for xi in x_path]\n\nplt.plot(x_path, y_path, 'ro-', markersize=10, linewidth=2, label='梯度下降路径')\nplt.scatter([0], [1], s=300, c='green', marker='*', zorder=5, label='最优点')\n\nplt.xlabel('参数 W', fontsize=12)\nplt.ylabel('Loss', fontsize=12)\nplt.title('梯度下降：沿着坡度下山', fontsize=14)\nplt.legend(fontsize=11)\nplt.grid(True, alpha=0.3)\nplt.annotate('起点', xy=(1.8, y_path[0]), xytext=(2, 4.5), \n            arrowprops=dict(arrowstyle='-&gt;', color='red'), fontsize=11)\nplt.annotate('终点（最优）', xy=(0, 1), xytext=(0.5, 2), \n            arrowprops=dict(arrowstyle='-&gt;', color='green'), fontsize=11)\nplt.show()\n\n\n\n\n\n\n\n\n\n类比：\n\n做菜太咸（Loss 大） → 下次少放盐（调整参数）\n通过不断尝试，找到最佳配方（最优参数）\n\n\n\n\n8.5.4 优化器（Optimizer）\n\n8.5.4.1 SGD vs Adam\n\n\n\n\n\n\n\n\n\n优化器\n全称\n特点\n何时用\n\n\n\n\nSGD\nStochastic Gradient Descent\n最基础学习率固定\n简单问题理论研究\n\n\nAdam\nAdaptive Moment Estimation\n自适应学习率收敛快\n大多数情况首选\n\n\n\n建议：\n\n初学者：直接用 Adam\n效果不好再试 SGD",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>第六讲：神经网络基础</span>"
    ]
  },
  {
    "objectID": "w6_neural_networks.html#第五部分mlp-vs-树模型",
    "href": "w6_neural_networks.html#第五部分mlp-vs-树模型",
    "title": "8  第六讲：神经网络基础",
    "section": "8.6 第五部分：MLP vs 树模型",
    "text": "8.6 第五部分：MLP vs 树模型\n\n8.6.1 何时用树模型，何时用 MLP？\n\n8.6.1.1 对比表\n\n\n\n\n\n\n\n\n维度\n树模型（RF/GBDT）\nMLP\n\n\n\n\n适用数据\n表格数据（行列结构）\n图像、文本、音频（非结构化）\n\n\n特征工程\n需要人工处理（编码、缺失值）\n自动学习特征\n\n\n训练速度\n快（分钟级）\n慢（小时级）\n\n\n调参难度\n简单（3-5个参数）\n复杂（层数、神经元数、学习率…）\n\n\n可解释性\n高（特征重要性、可视化）\n低（黑盒）\n\n\n样本量要求\n小数据也可以（100+）\n需要大量数据（10000+）\n\n\n过拟合\n较容易控制\n容易过拟合\n\n\n\n\n\n8.6.1.2 金融领域实际情况\n\n\n\n场景\n数据类型\n首选模型\n原因\n\n\n\n\n贷款违约预测\n表格\nGBDT\n可解释\n\n\n欺诈检测\n表格\nGBDT/RF\n速度快\n\n\n客户流失\n表格\nGBDT\n可解释\n\n\n票据识别（OCR）\n图像\nCNN\n图像专用\n\n\n舆情分析\n文本\nBERT\n文本专用\n\n\n股票预测\n时间序列\nLSTM/Transformer\n序列专用\n\n\n\n核心结论：\n\n表格数据（90%的金融任务） → 树模型\n图像/文本/音频 → 深度学习",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>第六讲：神经网络基础</span>"
    ]
  },
  {
    "objectID": "w6_neural_networks.html#总结",
    "href": "w6_neural_networks.html#总结",
    "title": "8  第六讲：神经网络基础",
    "section": "8.7 总结",
    "text": "8.7 总结\n\n8.7.1 本讲知识回顾\n\n8.7.1.1 神经元模型\n\n生物神经元 → 人工神经元\n加权求和 + 激活函数\n\n\n\n8.7.1.2 激活函数\n\nSigmoid：输出层（二分类）\nReLU：隐藏层首选\nTanh：RNN 专用\n\n\n\n8.7.1.3 多层感知机\n\n输入层 → 隐藏层 → 输出层\n参数：权重 W + 偏置 b\n多层 → 学习复杂非线性模式\n\n\n\n8.7.1.4 训练过程\n\n前向传播：输入 → 输出\n损失函数：衡量误差\n反向传播：计算梯度\n优化器：更新参数（推荐 Adam）\n\n\n\n8.7.1.5 MLP vs 树模型\n\n\n\n场景\n推荐模型\n\n\n\n\n表格数据\n树模型\n\n\n图像\nCNN\n\n\n文本\nTransformer\n\n\n音频\nRNN/CNN\n\n\n\n\n\n\n8.7.2 核心要点\n\n深度学习不神秘\n基于简单的数学运算累积\n激活函数很重要\n隐藏层用 ReLU，输出层看任务\n归一化是必须的\n神经网络对数据尺度敏感\n表格数据树模型更好\n不要迷信深度学习\nKeras 很简单\nSequential API 易上手",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>第六讲：神经网络基础</span>"
    ]
  },
  {
    "objectID": "w6_neural_networks.html#qa",
    "href": "w6_neural_networks.html#qa",
    "title": "8  第六讲：神经网络基础",
    "section": "8.8 Q&A",
    "text": "8.8 Q&A\nQ1：人工神经元是如何模拟生物神经元的？请写出人工神经元的基本数学模型。\nA： 人工神经元模拟生物神经元“接收信号-整合处理-激活发火”的过程。\n它的数学模型是：\n\n加权求和： \\(z = \\sum_{i=1}^{n} w_i x_i + b\\)\n激活函数： \\(y = f(z)\\) （其中 \\(x_i\\) 是输入特征，\\(w_i\\) 是权重，\\(b\\) 是偏置，\\(f\\) 是激活函数）\n\nQ2：为什么神经网络中必须使用“非线性”激活函数（如 ReLU）？如果只用线性激活（或不用激活），多层网络会退化成什么？\nA：\n\n原因：激活函数的作用是引入非线性，使得网络能够学习和拟合复杂的非线性模式（例如 XOR 问题）。\n退化：如果只用线性激活，多层线性叠加的结果仍然是线性的（\\(W'x + b'\\)）。这会导致整个深度神经网络退化成一个单层的线性模型（如逻辑回归），失去深度学习的意义。\n\nQ3：为神经网络的“隐藏层”和“二分类输出层”选择激活函数时，首选的推荐分别是什么？\nA：\n\n隐藏层首选：ReLU。因为它计算快，并能有效缓解梯度消失问题。\n二分类输出层首选：Sigmoid。因为它的输出范围是 (0, 1) ，可以将输出结果解释为概率。\n\nQ4：请简要描述“前向传播”（Forward Propagation）和“反向传播”（Backward Propagation）在神经网络训练中的角色。\nA：\n\n前向传播：是指数据从输入层开始，逐层计算，直到在输出层得到预测值（\\(\\hat{y}\\)）的过程。\n反向传播：是指在得到预测值并计算出 Loss（误差）后，从输出层反向逐层计算 Loss 对每个参数（W 和 b）的梯度（贡献度）的过程。\n\nQ5：为什么 ReLU (\\(\\max(0, z)\\)) 作为隐藏层激活函数，通常优于 Sigmoid？Sigmoid 用在隐藏层时有什么主要缺陷？\nA： ReLU 之所以更优，主要是因为它解决了 Sigmoid 的一个主要缺陷：梯度消失（Gradient Vanishing）。\n\nSigmoid 的缺陷：Sigmoid 函数在输入值（z）很大或很小时，其曲线非常平坦，导致梯度（导数）接近于 0。在反向传播时，这些接近 0 的梯度逐层相乘，导致深层网络的梯度变得极小，使得参数几乎无法更新。\nReLU 的优势：当输入 \\(z &gt; 0\\) 时，ReLU 的梯度恒为 1。这使得梯度在反向传播时能够更顺畅地流动，极大地缓解了梯度消失问题，让网络训练得更快、更深。\n\nQ6：假设一个 MLP 网络结构为 Input(10) -&gt; Dense(32, ReLU) -&gt; Output(1, Sigmoid)。请问从 Input 层到 Dense(32) 层（第一个隐藏层）总共有多少个可训练参数？\nA： 可训练参数 = 权重（Weights）+ 偏置（Biases）。\n\n权重 (W)：每个输入神经元都连接到每个隐藏神经元。\n\n计算：输入维度 × 隐藏层维度 = \\(10 \\times 32 = 320\\) 个。\n\n偏置 (b)：隐藏层中的每个神经元都有 1 个偏置项。\n\n计算：隐藏层维度 = \\(32\\) 个。\n\n总计： \\(320 + 32 = \\mathbf{352}\\) 个可训练参数。\n\nQ7：在反向传播中，我们计算出 Loss 对权重 W 的梯度（\\(\\frac{\\partial \\text{Loss}}{\\partial W}\\)）后，是如何更新这个权重 W 的？（请写出更新规则）。在这个规则中，“学习率（\\(\\eta\\)）”扮演了什么角色？\nA：\n\n更新规则： \\(W_{\\text{new}} = W_{\\text{old}} - \\eta \\times \\frac{\\partial \\text{Loss}}{\\partial W}\\) 。\n学习率（\\(\\eta\\)）的角色：学习率（Learning Rate）扮演着“步长”的角色。它控制了模型在“下山”（降低 Loss）时每一步迈多大。\n\n\\(\\eta\\) 太大：可能会导致“步子迈太大”，越过最低点，导致 Loss 震荡或发散。\n\\(\\eta\\) 太小：会导致“小碎步”下山，训练速度过慢，可能需要很久才能收敛。\n\n\nQ8：对于绝大多数金融场景中的“表格数据”（像一个 Excel 表格、数据库表类型的数据），推荐首选哪一类模型（树模型还是MLP）？为什么？\nA：\n\n首选模型：树模型（特别是 GBDT）。\n原因：对于表格数据，树模型通常训练速度更快、调参更简单、可解释性更强，并且在中小规模的数据集上（金融领域很常见）表现往往优于需要大量数据和复杂调参的 MLP。\n\nQ9：一个金融科技团队想用 MLP（神经网络）来预测客户流失，他们的数据集只有 5000 行（样本）和 20 个特征（表格数据）。你认为他们应该优先使用 MLP 吗？为什么？\nA： 不应该优先使用 MLP。\n理由如下：\n\n数据量太小：MLP 通常需要大量数据（例如 1 万条以上）才能学习其数千个参数并防止过拟合。5000 行数据对于 MLP 来说太少了。\n树模型更优：对于这种中小型表格数据，树模型（如 GBDT 或 随机森林）通常表现更好，并且训练更快、可解释性更强（这对业务很重要）。",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>第六讲：神经网络基础</span>"
    ]
  },
  {
    "objectID": "project_list.html",
    "href": "project_list.html",
    "title": "9  项目列表",
    "section": "",
    "text": "9.1 入门级（难度系数 0.9）",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>项目列表</span>"
    ]
  },
  {
    "objectID": "project_list.html#入门级难度系数-0.9",
    "href": "project_list.html#入门级难度系数-0.9",
    "title": "9  项目列表",
    "section": "",
    "text": "California House Prices：回归问题，特征较少，提供数据清洗模板\nUCI Credit Card Default：分类问题，数据集小，特征清晰",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>项目列表</span>"
    ]
  },
  {
    "objectID": "project_list.html#进阶级难度系数-1.0",
    "href": "project_list.html#进阶级难度系数-1.0",
    "title": "9  项目列表",
    "section": "9.2 进阶级（难度系数 1.0）",
    "text": "9.2 进阶级（难度系数 1.0）\n\nLendingClub Default Risk：评估 AUC、剔除泄露字段\nHome Credit Default Risk：评估 AUC，可合并外部表",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>项目列表</span>"
    ]
  },
  {
    "objectID": "project_list.html#挑战级难度系数-1.1需要一定编程基础",
    "href": "project_list.html#挑战级难度系数-1.1需要一定编程基础",
    "title": "9  项目列表",
    "section": "9.3 挑战级（难度系数 1.1，需要一定编程基础）",
    "text": "9.3 挑战级（难度系数 1.1，需要一定编程基础）\n\nIEEE-CIS Fraud Detection：极不平衡、严格时序、多表合并\nG-Research Crypto Forecasting：回归/排序、多币种、时间序列",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>项目列表</span>"
    ]
  },
  {
    "objectID": "1_california.html",
    "href": "1_california.html",
    "title": "10  项目1：California House Prices 学生项目要求",
    "section": "",
    "text": "10.1 项目背景",
    "crumbs": [
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>项目1：California House Prices 学生项目要求</span>"
    ]
  },
  {
    "objectID": "1_california.html#项目背景",
    "href": "1_california.html#项目背景",
    "title": "10  项目1：California House Prices 学生项目要求",
    "section": "",
    "text": "项目名称：加州房价预测\n应用场景 / 价值：根据加州各地区的地理和社会经济数据，预测未来房屋的中位数价格（MedInc）。该模型可以用于房产投资、政府规划和房地产风险管理等场景。\n数据来源：课程提供自 Kaggle 数据集 California Housing Prices 的子集，包含 20640 行，10 个特征，目标变量为 MedHouseVal（房屋中位数价值，单位千美元）。\n任务类型：回归（预测目标变量 MedHouseVal）。",
    "crumbs": [
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>项目1：California House Prices 学生项目要求</span>"
    ]
  },
  {
    "objectID": "1_california.html#项目任务必须完成",
    "href": "1_california.html#项目任务必须完成",
    "title": "10  项目1：California House Prices 学生项目要求",
    "section": "10.2 项目任务（必须完成）",
    "text": "10.2 项目任务（必须完成）\n\n目标变量口径：以 MedHouseVal 为目标变量，表示房屋中位数价格（单位：千美元）；在报告中解释其含义并打印分布（均值、标准差、分位数）。\n数据读取与检查：打印行列数、缺失概览、关键列存在性；将摘要记录在 README.md 中。\n数据清洗与预处理：\n\n缺失处理：对于数值特征使用中位数/均值填充，类别特征使用众数填充；\n异常值：识别并处理明显异常值（如负数的房价或人口数）。\n\n特征工程：\n\n对类别变量（如 ocean_proximity）进行 One-Hot 编码；\n创建一些新的数值特征，例如：\n\npopulation_per_household = Population / Households；\n\n对数值特征（如 HouseAge、AveRooms）做标准化/归一化。\n根据具体情况，尝试使用箱体图或Z-score来识别并处理极端值。\n\n训练/测试切分：按比例随机切分数据集为训练集与测试集（默认 80% 训练，20% 测试）；确保固定随机种子。\n基线模型：至少使用线性回归（Linear Regression）作为基线模型；\n\n使用 RMSE（均方根误差）、MAE（平均绝对误差） 和 R²（决定系数）作为评估指标。\n\n结果导出：在 outputs/ 目录输出预测值与实际值。\n模型解释：打印和可视化模型的系数或特征重要性，结合业务给出 2–3 条有价值的见解（例如“面积与房价的关系”）。",
    "crumbs": [
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>项目1：California House Prices 学生项目要求</span>"
    ]
  },
  {
    "objectID": "1_california.html#团队与分工6-10-人",
    "href": "1_california.html#团队与分工6-10-人",
    "title": "10  项目1：California House Prices 学生项目要求",
    "section": "10.3 团队与分工（6-10 人）",
    "text": "10.3 团队与分工（6-10 人）\n\n推荐规模：6-10 人；可根据团队实际人数灵活调整。\n核心角色（必须）：\nA. 数据读取与清洗（clean_data）\nB. 数据探索（explore_data）\nC. 特征工程（feature_engineering）\nD. 数据切分（split_data）\nE. 训练模型（train_model）\nF. 评估与导出（evaluate_model / save_predictions）\n可选角色（7-8 人时添加）：\nG. 可视化与报告排版（负责图表制作、报告编写）\nH. presenter（做PPT、项目答辩汇报）\n协作角色（9-10 人时添加）：\nI. 数据探索辅助（协助 A 完成数据理解、可视化探索）\nJ. 特征工程辅助（协助 C 完成特征构造、验证）\nK. 模型调参辅助（协助 E 完成超参数调优、模型对比）\n署名规范：每位成员在自己负责的函数顶部写 (owner 学号)+姓名；不得修改他人代码；合并由队长负责。\n分工建议：\n\n6 人：每人 1 个核心角色\n7 人：6 个核心角色 + 1 个可选角色（G 或 H）\n8 人：6 个核心角色 + 2 个可选角色（G + H）\n9 人：6 个核心角色 + 2 个可选角色 + 1 个协作角色\n10 人：6 个核心角色 + 2 个可选角色 + 2 个协作角色",
    "crumbs": [
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>项目1：California House Prices 学生项目要求</span>"
    ]
  },
  {
    "objectID": "1_california.html#数据与合规",
    "href": "1_california.html#数据与合规",
    "title": "10  项目1：California House Prices 学生项目要求",
    "section": "10.4 数据与合规",
    "text": "10.4 数据与合规\n\n数据说明：在 README.md 或报告中写明数据来源、时间范围、字段描述、目标变量口径、特征清洗和处理方式。\n隐私与伦理：数据来自公开的加州房产市场，不含个人敏感信息。\n数据字典：提供关键字段释义，特别是对于 ocean_proximity 的编码和其他处理。",
    "crumbs": [
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>项目1：California House Prices 学生项目要求</span>"
    ]
  },
  {
    "objectID": "1_california.html#交付与时间线统一里程碑",
    "href": "1_california.html#交付与时间线统一里程碑",
    "title": "10  项目1：California House Prices 学生项目要求",
    "section": "10.5 交付与时间线（统一里程碑）",
    "text": "10.5 交付与时间线（统一里程碑）\n\nW3：立项检查（第四周上课前提交到学习通/GitHub）\n\n项目仓库建立（包含相关文件夹）\nREADME 包含题目、数据来源、成员分工\n能在 Python程序脚本/Jupyter Notebook 中加载数据并展示基本统计信息\n至少一张数据可视化图\n\nW7：结项答辩（答辩时）\n\n提交完整复现包（见下目录）+ 报告（6–8 页）+ 幻灯（6–8 页）+ AI 使用记录。\n代码能运行：按照 README 步骤能复现结果\n结果齐全：\n\n至少对比 2 种模型\n评估指标表格（回归：RMSE/MAE）\n2-3 张关键图（特征重要性/残差图）\n\n文档完整：\n\nREADME 有复现步骤\n报告有问题描述、方法、结果、分析",
    "crumbs": [
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>项目1：California House Prices 学生项目要求</span>"
    ]
  },
  {
    "objectID": "1_california.html#交付清单统一目录",
    "href": "1_california.html#交付清单统一目录",
    "title": "10  项目1：California House Prices 学生项目要求",
    "section": "10.6 交付清单（统一目录）",
    "text": "10.6 交付清单（统一目录）\nproject_root/\n  README.md                # 项目背景、分工、数据来源与口径摘要、运行命令\n  main.py                  # 单文件分工脚本\n  requirements.txt         # 依赖（pandas/numpy/scikit-learn 等）\n  data/\n    sample.csv             # 样本（数据不上传）\n    README.md              # 数据文件夹结构\n  outputs/\n    predictions.csv        # 模型输出样例（运行脚本可覆盖生成）\n  report.pdf  (或 .md)     # 6–8 页项目报告（请在结题时添加）\n  slides.pdf               # 6–8 页答辩幻灯（请在结题时添加）\n  ai_usage_log.md          # AI 使用记录（日期/工具/用途/采纳与否）\n  .gitignore               # 忽略大文件（保留示例数据与示例输出）",
    "crumbs": [
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>项目1：California House Prices 学生项目要求</span>"
    ]
  },
  {
    "objectID": "1_california.html#技术要求",
    "href": "1_california.html#技术要求",
    "title": "10  项目1：California House Prices 学生项目要求",
    "section": "10.7 技术要求",
    "text": "10.7 技术要求\n最低要求（必须达成）\n\n按照README可以复刻结果。\n最小流程：读取 → 清洗 → 特征 → 切分 → 训练（基线）→ 评估 → 导出。\n基线模型：分类=逻辑回归 / 回归=线性回归；至少 1 个评估指标；固定随机种子；输出预测到 outputs/。\n可复现性：写清版本号与数据来源；提交样例数据与样例输出。\n代码协作：每人仅编辑自己的函数；完成 TODO 后改为 DONE；合并由队长统一执行。\n\n额外加分点（任选 1–4 项）\n\n特征选择：使用 Lasso 回归或其他正则方法筛选特征，评估模型性能变化。\n模型集成：使用 随机森林 或 轻量 GBDT 模型，比较与基线回归模型的性能差异。\n非线性特征工程：将一些重要特征转换为多项式特征（如 HouseAge^2），并进行模型比较。\n可视化 ≥2 张：绘制特征重要性图、预测与实际房价对比图、残差图等。\n工程性：友好报错与自动日志（数据形状、缺失/异常统计、耗时、随机种子）。",
    "crumbs": [
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>项目1：California House Prices 学生项目要求</span>"
    ]
  },
  {
    "objectID": "1_california.html#评分与-rubric统一口径可微调",
    "href": "1_california.html#评分与-rubric统一口径可微调",
    "title": "10  项目1：California House Prices 学生项目要求",
    "section": "10.8 评分与 Rubric（统一口径，可微调）",
    "text": "10.8 评分与 Rubric（统一口径，可微调）\n\n总评 = 团队分 90% + 互评 10%；如公布难度系数（0.9 / 1.0 / 1.1），按乘数计算。\n\n\n10.8.1 团队分（90%）\n\n其中”报告与可读性”仅针对报告文本与图表评分。\n\n\n\n\n\n\n\n\n\n\n\n维度\nA（优秀）\nB（良好）\nC（合格）\nD（需改进）\n\n\n\n\n可运行性(10)\n一键跑通；无报错；跨平台稳定\n一键跑通，小问题可自解\n基本跑通，需老师介入\n无法跑通\n\n\n正确性(20)\n任务实现到位，评估合理\n基本实现，评估略单薄\n只完成部分流程\n偏离题意\n\n\n稳健性(10)\n缺失/异常/边界处理到位\n处理常见问题\n处理有限\n几乎未处理\n\n\n代码质量(10)\n变量/注释清晰，结构整洁\n基本清晰\n可读性一般\n可读性差\n\n\n报告与可读性(30)\n结构清晰、图表规范、叙述有因有据\n大体清晰\n说明不全/结构混乱\n缺失关键说明\n\n\n演示表达(20)\n逻辑清楚，答辩到位\n讲清主要结论\n表达一般\n不能自洽\n\n\n\n\n\n10.8.2 互评（10%）\n\n每位成员对其他人打分；与教师评分结合。\n若互评明显失真，教师可依据提交记录与痕迹进行调整。",
    "crumbs": [
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>项目1：California House Prices 学生项目要求</span>"
    ]
  },
  {
    "objectID": "1_california.html#报告与答辩内容统一骨架",
    "href": "1_california.html#报告与答辩内容统一骨架",
    "title": "10  项目1：California House Prices 学生项目要求",
    "section": "10.9 报告与答辩内容（统一骨架）",
    "text": "10.9 报告与答辩内容（统一骨架）\n报告（6–8 页）\n\n背景与任务（场景、目标、评估指标）\n数据与变量（来源、清洗摘要、口径与过滤、数据字典）\n方法（流程图、基线模型、评估方案；不平衡处理、特征选择）\n结果（表/图 + 解读 + 业务含义；Top 特征/混淆矩阵）\n误差来源与改进（异常值、特征选择、数据清洗）\n结论与建议（面向房地产投资/风控的建议：信号阈值、更新频率等）\n\n答辩幻灯（6–8 页）：与报告同结构，突出关键结论与可视化（ROC/PR、特征贡献等）。",
    "crumbs": [
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>项目1：California House Prices 学生项目要求</span>"
    ]
  },
  {
    "objectID": "1_california.html#提交与命名规范",
    "href": "1_california.html#提交与命名规范",
    "title": "10  项目1：California House Prices 学生项目要求",
    "section": "10.10 提交与命名规范",
    "text": "10.10 提交与命名规范\n\n打包：提交 .zip，保留目录结构；不要包含超大无关文件。\n命名：【CHP】_【班级】_【队名】.zip；报告/幻灯使用相同前缀。\n提交方式：按课程平台要求（学习通 / GitHub Release）。",
    "crumbs": [
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>项目1：California House Prices 学生项目要求</span>"
    ]
  },
  {
    "objectID": "1_california.html#学术诚信与-ai-使用政策",
    "href": "1_california.html#学术诚信与-ai-使用政策",
    "title": "10  项目1：California House Prices 学生项目要求",
    "section": "10.11 学术诚信与 AI 使用政策",
    "text": "10.11 学术诚信与 AI 使用政策\n\n允许用 AI 工具进行资料查询、代码解释、调试建议；\n禁止：粘贴未理解的大段生成代码、虚构数据/结果、抄袭他组；\n必交 ai_usage_log.md（日期、工具、用途、是否采纳与原因 2–3 句）；\n发现学术不端将按校规处理。",
    "crumbs": [
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>项目1：California House Prices 学生项目要求</span>"
    ]
  },
  {
    "objectID": "2_uci.html",
    "href": "2_uci.html",
    "title": "11  项目2：UCI Credit Card Default 学生项目要求",
    "section": "",
    "text": "11.1 项目背景",
    "crumbs": [
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>项目2：UCI Credit Card Default 学生项目要求</span>"
    ]
  },
  {
    "objectID": "2_uci.html#项目背景",
    "href": "2_uci.html#项目背景",
    "title": "11  项目2：UCI Credit Card Default 学生项目要求",
    "section": "",
    "text": "项目名称：UCI 信用卡违约预测（Default of Credit Card Clients）\n应用场景 / 价值：在账单日/还款日前，根据用户历史账单与还款记录、基本属性，预估下个月是否违约（逾期未还），以支持授信与催收策略。\n数据来源：课程提供自 UCI 数据集 Default of Credit Card Clients 的子集。常见字段包括：\n\n基本属性：LIMIT_BAL, SEX, EDUCATION, MARRIAGE, AGE\n最近 6 期还款状态：PAY_0 ... PAY_6（ 注意：编码为 −2/−1/0/1/2…，代表还款/按时/逾期月数等，详见数据说明）\n最近 6 期账单金额：BILL_AMT1 ... BILL_AMT6\n最近 6 期还款金额：PAY_AMT1 ... PAY_AMT6\n目标变量：default.payment.next.month（1=违约，0=未违约）\n\n任务类型：二分类（违约/未违约）。",
    "crumbs": [
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>项目2：UCI Credit Card Default 学生项目要求</span>"
    ]
  },
  {
    "objectID": "2_uci.html#项目任务必须完成",
    "href": "2_uci.html#项目任务必须完成",
    "title": "11  项目2：UCI Credit Card Default 学生项目要求",
    "section": "11.2 项目任务（必须完成）",
    "text": "11.2 项目任务（必须完成）\n\n目标变量口径：以 default.payment.next.month 为标签；在报告中解释 1/0 含义并打印类比例（说明可能存在不平衡）。\n口径统一与映射：\n\nEDUCATION、MARRIAGE 中的非常规编码（如 0/5/6）需合并映射到“其他/未知”，在报告给出映射表；\nPAY_* 的取值语义需在报告中文字说明（如 1/2/3 分别对应逾期月数）。\n\n数据读取与检查：打印行列数、缺失概览、关键列存在性；将摘要写入 README.md。\n数据清洗：\n\n缺失处理与异常值（负龄/异常额度）检查；\n类别规范：SEX/EDUCATION/MARRIAGE One‑Hot 或合适编码；\n可选：金额变量对数化（如 log(1+x)）。\n\n特征工程（至少 2 项）：示例——\n\n逾期强度：max(PAY_0..PAY_6)、sum(PAY_*&gt;0)（逾期月数计数）；\n还款能力：PAY_AMT1 / BILL_AMT1（最近一期还款率）、近 3/6 期均值；\n余额/利用率：BILL_AMT1 / LIMIT_BAL、滚动均值/方差；\n趋势特征：BILL_AMT 近 6 期线性斜率、PAY_AMT 趋势。\n\n训练/测试切分：固定随机种子；说明比例与分层策略（建议 stratify=label）。\n基线模型：逻辑回归（必做）；至少 1 个评估指标（推荐 Accuracy + F1，可加 ROC AUC）。\n阈值与业务解读：给出一个示例阈值下的混淆矩阵与精查名单解释（例如“高风险 Top‑K”）。\n结果导出：在 outputs/ 输出预测概率与标签。\n\n\n若本项目另有字段筛选或不同口径，由任课老师发布时补充；你们需在报告中如实记录。",
    "crumbs": [
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>项目2：UCI Credit Card Default 学生项目要求</span>"
    ]
  },
  {
    "objectID": "2_uci.html#团队与分工6-10-人",
    "href": "2_uci.html#团队与分工6-10-人",
    "title": "11  项目2：UCI Credit Card Default 学生项目要求",
    "section": "11.3 团队与分工（6-10 人）",
    "text": "11.3 团队与分工（6-10 人）\n\n推荐规模：6-10 人；可根据团队实际人数灵活调整。\n核心角色（必须）：\nA. 数据读取与清洗（clean_data）\nB. 数据探索（explore_data）\nC. 特征工程（feature_engineering）\nD. 数据切分（split_data）\nE. 训练模型（train_model）\nF. 评估与导出（evaluate_model / save_predictions）\n可选角色（7-8 人时添加）：\nG. 可视化与报告排版（负责图表制作、报告编写）\nH. presenter（做PPT、项目答辩汇报）\n协作角色（9-10 人时添加）：\nI. 数据探索辅助（协助 A 完成数据理解、可视化探索）\nJ. 特征工程辅助（协助 C 完成特征构造、验证）\nK. 模型调参辅助（协助 E 完成超参数调优、模型对比）\n署名规范：每位成员在自己负责的函数顶部写 (owner 学号)+姓名；不得修改他人代码；合并由队长负责。\n分工建议：\n\n6 人：每人 1 个核心角色\n7 人：6 个核心角色 + 1 个可选角色（G 或 H）\n8 人：6 个核心角色 + 2 个可选角色（G + H）\n9 人：6 个核心角色 + 2 个可选角色 + 1 个协作角色\n10 人：6 个核心角色 + 2 个可选角色 + 2 个协作角色",
    "crumbs": [
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>项目2：UCI Credit Card Default 学生项目要求</span>"
    ]
  },
  {
    "objectID": "2_uci.html#数据与合规",
    "href": "2_uci.html#数据与合规",
    "title": "11  项目2：UCI Credit Card Default 学生项目要求",
    "section": "11.4 数据与合规",
    "text": "11.4 数据与合规\n\n数据说明：在 README.md 或报告中写明来源、时间范围、关键字段、目标变量口径、过滤规则与编码映射表。\n隐私与伦理：数据为匿名化样本；如追加外部数据（如利率、宏观指标），需要注明来源与许可。\n数据字典：提供关键字段释义（尤其是 PAY_* 语义与 EDUCATION/MARRIAGE 的重编码）。",
    "crumbs": [
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>项目2：UCI Credit Card Default 学生项目要求</span>"
    ]
  },
  {
    "objectID": "2_uci.html#交付与时间线统一里程碑",
    "href": "2_uci.html#交付与时间线统一里程碑",
    "title": "11  项目2：UCI Credit Card Default 学生项目要求",
    "section": "11.5 交付与时间线（统一里程碑）",
    "text": "11.5 交付与时间线（统一里程碑）\n\nW3：立项检查（第四周上课前提交到学习通/GitHub）\n\n项目仓库建立（包含相关文件夹）\nREADME 包含题目、数据来源、成员分工\n能在 Python程序脚本/Jupyter Notebook 中加载数据并展示基本统计信息\n至少一张数据可视化图\n\nW7：结项答辩（答辩时）\n\n提交完整复现包（见下目录）+ 报告（6–8 页）+ 幻灯（6–8 页）+ AI 使用记录。\n代码能运行：按照 README 步骤能复现结果\n结果齐全：\n\n至少对比 2 种模型\n评估指标表格（分类：准确率/召回率/AUC）\n2-3 张关键图（混淆矩阵/ROC 曲线/特征重要性）\n\n文档完整：\n\nREADME 有复现步骤\n报告有问题描述、方法、结果、分析",
    "crumbs": [
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>项目2：UCI Credit Card Default 学生项目要求</span>"
    ]
  },
  {
    "objectID": "2_uci.html#交付清单统一目录",
    "href": "2_uci.html#交付清单统一目录",
    "title": "11  项目2：UCI Credit Card Default 学生项目要求",
    "section": "11.6 交付清单（统一目录）",
    "text": "11.6 交付清单（统一目录）\nproject_root/\n  README.md                # 项目背景、分工、数据来源与口径摘要、运行命令\n  main.py                  # 单文件分工脚本\n  requirements.txt         # 依赖（pandas/numpy/scikit-learn 等）\n  data/\n    sample.csv             # 样本（数据不上传）\n    README.md              # 数据文件夹结构\n  outputs/\n    predictions.csv        # 模型输出样例（运行脚本可覆盖生成）\n  report.pdf  (或 .md)     # 6–8 页项目报告（请在结题时添加）\n  slides.pdf               # 6–8 页答辩幻灯（请在结题时添加）\n  ai_usage_log.md          # AI 使用记录（日期/工具/用途/采纳与否）\n  .gitignore               # 忽略大文件（保留示例数据与示例输出）",
    "crumbs": [
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>项目2：UCI Credit Card Default 学生项目要求</span>"
    ]
  },
  {
    "objectID": "2_uci.html#技术要求",
    "href": "2_uci.html#技术要求",
    "title": "11  项目2：UCI Credit Card Default 学生项目要求",
    "section": "11.7 技术要求",
    "text": "11.7 技术要求\n最低要求（必须达成）\n\n按照README可以复刻结果。\n最小流程：读取 → 清洗 → 特征 → 切分 → 训练（基线）→ 评估 → 导出。\n基线模型：分类=逻辑回归 / 回归=线性回归；至少 1 个评估指标；固定随机种子；输出预测到 outputs/。\n可复现性：写清版本号与数据来源；提交样例数据与样例输出。\n代码协作：每人仅编辑自己的函数；完成 TODO 后改为 DONE；合并由队长统一执行。\n\n额外加分点（任选 1–5 项）\n\n不平衡处理：类权重/欠采样/过采样/SMOTE；比较对 F1 / AUC 的影响。\n成本敏感评估：设定示例成本矩阵（漏判成本 &gt; 误杀成本），计算期望成本并与默认阈值对比。\n特征选择/稳定性：用单变量筛选或正则（L1/L2）做特征压缩；报告系数稳定性。\n校准：Platt/等距分箱校准概率，并用校准曲线展示结果。\n可视化 ≥2 张：PAY_* 分布与违约率、还款率分布、ROC/PR 曲线、特征贡献条形图等。\n工程性：友好报错与自动日志（数据形状、缺失/异常统计、耗时、随机种子）。",
    "crumbs": [
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>项目2：UCI Credit Card Default 学生项目要求</span>"
    ]
  },
  {
    "objectID": "2_uci.html#评分与-rubric统一口径可微调",
    "href": "2_uci.html#评分与-rubric统一口径可微调",
    "title": "11  项目2：UCI Credit Card Default 学生项目要求",
    "section": "11.8 评分与 Rubric（统一口径，可微调）",
    "text": "11.8 评分与 Rubric（统一口径，可微调）\n\n总评 = 团队分 90% + 互评 10%；如公布难度系数（0.9 / 1.0 / 1.1），按乘数计算。\n\n\n11.8.1 团队分（90%）\n\n其中”报告与可读性”仅针对报告文本与图表评分。\n\n\n\n\n\n\n\n\n\n\n\n维度\nA（优秀）\nB（良好）\nC（合格）\nD（需改进）\n\n\n\n\n可运行性(10)\n一键跑通；无报错；跨平台稳定\n一键跑通，小问题可自解\n基本跑通，需老师介入\n无法跑通\n\n\n正确性(20)\n任务实现到位，评估合理\n基本实现，评估略单薄\n只完成部分流程\n偏离题意\n\n\n稳健性(10)\n缺失/异常/边界处理到位\n处理常见问题\n处理有限\n几乎未处理\n\n\n代码质量(10)\n变量/注释清晰，结构整洁\n基本清晰\n可读性一般\n可读性差\n\n\n报告与可读性(30)\n结构清晰、图表规范、叙述有因有据\n大体清晰\n说明不全/结构混乱\n缺失关键说明\n\n\n演示表达(20)\n逻辑清楚，答辩到位\n讲清主要结论\n表达一般\n不能自洽\n\n\n\n\n\n11.8.2 互评（10%）\n\n每位成员对其他人打分；与教师评分结合。\n若互评明显失真，教师可依据提交记录与痕迹进行调整。",
    "crumbs": [
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>项目2：UCI Credit Card Default 学生项目要求</span>"
    ]
  },
  {
    "objectID": "2_uci.html#报告与答辩内容统一骨架",
    "href": "2_uci.html#报告与答辩内容统一骨架",
    "title": "11  项目2：UCI Credit Card Default 学生项目要求",
    "section": "11.9 报告与答辩内容（统一骨架）",
    "text": "11.9 报告与答辩内容（统一骨架）\n报告（6–8 页）\n\n背景与任务（场景、目标、评估指标）\n数据与变量（来源、清洗摘要、编码与映射、口径与过滤）\n方法（流程图、基线模型、评估方案；不平衡与阈值策略）\n结果（表/图 + 解读 + 业务含义；混淆矩阵与阈值敏感性）\n误差来源与改进（口径差异、特征选择、校准、类不平衡等）\n结论与建议（面向授信/催收的建议：阈值、名单规模、复核策略）\n\n答辩幻灯（6–8 页）：与报告同结构，突出关键结论与可视化（ROC/PR、Top 特征等）。",
    "crumbs": [
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>项目2：UCI Credit Card Default 学生项目要求</span>"
    ]
  },
  {
    "objectID": "2_uci.html#提交与命名规范",
    "href": "2_uci.html#提交与命名规范",
    "title": "11  项目2：UCI Credit Card Default 学生项目要求",
    "section": "11.10 提交与命名规范",
    "text": "11.10 提交与命名规范\n\n打包：提交 .zip，保留目录结构；不要包含超大无关文件。\n命名：【UCI】_【班级】_【队名】.zip；报告/幻灯使用相同前缀。\n提交方式：按课程平台要求（学习通 / GitHub Release）。",
    "crumbs": [
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>项目2：UCI Credit Card Default 学生项目要求</span>"
    ]
  },
  {
    "objectID": "2_uci.html#学术诚信与-ai-使用政策",
    "href": "2_uci.html#学术诚信与-ai-使用政策",
    "title": "11  项目2：UCI Credit Card Default 学生项目要求",
    "section": "11.11 学术诚信与 AI 使用政策",
    "text": "11.11 学术诚信与 AI 使用政策\n\n允许用 AI 工具进行资料查询、代码解释、调试建议；\n禁止：粘贴未理解的大段生成代码、虚构数据/结果、抄袭他组；\n必交 ai_usage_log.md（日期、工具、用途、是否采纳与原因 2–3 句）；\n发现学术不端将按校规处理。",
    "crumbs": [
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>项目2：UCI Credit Card Default 学生项目要求</span>"
    ]
  },
  {
    "objectID": "3_lendingclub.html",
    "href": "3_lendingclub.html",
    "title": "12  项目3：Lending Club（借贷违约风险）学生项目要求",
    "section": "",
    "text": "12.1 项目背景",
    "crumbs": [
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>项目3：Lending Club（借贷违约风险）学生项目要求</span>"
    ]
  },
  {
    "objectID": "3_lendingclub.html#项目背景",
    "href": "3_lendingclub.html#项目背景",
    "title": "12  项目3：Lending Club（借贷违约风险）学生项目要求",
    "section": "",
    "text": "项目名称：借贷违约风险评估（Lending Club）\n应用场景 / 价值：在线撮合的个人信用贷需要在放款前评估违约概率，以定价利率、设定授信或拒绝申请。你们将基于历史贷款数据构建一个放款前可用的违约预测模型，理解信用风险关键因素，并以图表与文字解释业务含义。\n数据来源：Lending Club 历史贷款公开数据（课程提供子集）。原始数据覆盖 2007.06–2018.12，字段约 145 个、记录约 200 万条；本项目使用其中子集。\n任务类型：二分类（是否违约 / 坏账）。\n数据说明：变量说明见 LCDataDictionary.xlsx 。",
    "crumbs": [
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>项目3：Lending Club（借贷违约风险）学生项目要求</span>"
    ]
  },
  {
    "objectID": "3_lendingclub.html#项目任务必须完成",
    "href": "3_lendingclub.html#项目任务必须完成",
    "title": "12  项目3：Lending Club（借贷违约风险）学生项目要求",
    "section": "12.2 项目任务（必须完成）",
    "text": "12.2 项目任务（必须完成）\n\n目标变量口径：将 loan_status 统一映射为二分类标签：违约=1、非违约=0；请在报告中提供映射表与口径解释。\n样本选择：统一使用 2013–2014 年发放且期限 36 个月的贷款作为训练/测试样本（这些贷款在 2018 年底前已结束，结局可观察）。\n可用字段原则（非常重要）：只使用放款前可获得信息进行建模；剔除所有放款后的贷后信息，例如变量名包含 recover、settlement、pymnt、以 total_rec 开头、以 out_prncp 开头等（报告中请列出你们剔除的字段清单）。\n数据读取与检查：打印行列数、前 3 行、关键列存在性；形成 README.md 的数据摘要。\n数据清洗：缺失值、异常值、类别统一（大小写/空格）；说明口径与处理理由。\n特征工程：至少 2 个新增特征（示例：DTI 分箱、revol_util 分段、annual_inc 对数、grade/sub_grade 编码等）；必要的 One-Hot/分箱。\n训练/测试切分：固定随机种子；说明比例与分层策略。\n基线模型：逻辑回归（Logistic Regression）作为必做基线；至少提供 1 个评估指标（推荐 Accuracy + F1 或 AUC）。\n模型解释：打印或可视化关键特征影响（如系数/重要性），并结合业务给出 2–3 条洞见。\n结果导出：在 outputs/ 目录输出预测结果（含概率列），并在报告中说明阈值选择与业务含义。\n\n\n允许在基线之上追加 1–2 个简单模型作对比（如决策树/随机森林），见“额外加分”。",
    "crumbs": [
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>项目3：Lending Club（借贷违约风险）学生项目要求</span>"
    ]
  },
  {
    "objectID": "3_lendingclub.html#团队与分工6-10-人",
    "href": "3_lendingclub.html#团队与分工6-10-人",
    "title": "12  项目3：Lending Club（借贷违约风险）学生项目要求",
    "section": "12.3 团队与分工（6-10 人）",
    "text": "12.3 团队与分工（6-10 人）\n\n推荐规模：6-10 人；可根据团队实际人数灵活调整。\n核心角色（必须）：\nA. 数据读取与清洗（clean_data）\nB. 数据探索（explore_data）\nC. 特征工程（feature_engineering）\nD. 数据切分（split_data）\nE. 训练模型（train_model）\nF. 评估与导出（evaluate_model / save_predictions）\n可选角色（7-8 人时添加）：\nG. 可视化与报告排版（负责图表制作、报告编写）\nH. presenter（做PPT、项目答辩汇报）\n协作角色（9-10 人时添加）：\nI. 数据探索辅助（协助 A 完成数据理解、可视化探索）\nJ. 特征工程辅助（协助 C 完成特征构造、验证）\nK. 模型调参辅助（协助 E 完成超参数调优、模型对比）\n署名规范：每位成员在自己负责的函数顶部写 (owner 学号)+姓名；不得修改他人代码；合并由队长负责。\n分工建议：\n\n6 人：每人 1 个核心角色\n7 人：6 个核心角色 + 1 个可选角色（G 或 H）\n8 人：6 个核心角色 + 2 个可选角色（G + H）\n9 人：6 个核心角色 + 2 个可选角色 + 1 个协作角色\n10 人：6 个核心角色 + 2 个可选角色 + 2 个协作角色",
    "crumbs": [
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>项目3：Lending Club（借贷违约风险）学生项目要求</span>"
    ]
  },
  {
    "objectID": "3_lendingclub.html#数据与合规",
    "href": "3_lendingclub.html#数据与合规",
    "title": "12  项目3：Lending Club（借贷违约风险）学生项目要求",
    "section": "12.4 数据与合规",
    "text": "12.4 数据与合规\n\n数据说明：在 README.md 或报告中写明来源、时间范围（本项目用 2013–2014, 36 期）、关键字段、目标变量口径、过滤规则。\n隐私与伦理：数据不含个人敏感信息；如追加外部数据，请确保合法来源并说明许可与处理。\n数据字典：提供关键字段释义（表格或清单）。",
    "crumbs": [
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>项目3：Lending Club（借贷违约风险）学生项目要求</span>"
    ]
  },
  {
    "objectID": "3_lendingclub.html#交付与时间线统一里程碑",
    "href": "3_lendingclub.html#交付与时间线统一里程碑",
    "title": "12  项目3：Lending Club（借贷违约风险）学生项目要求",
    "section": "12.5 交付与时间线（统一里程碑）",
    "text": "12.5 交付与时间线（统一里程碑）\n\nW3：立项检查（第四周上课前提交到学习通/GitHub）\n\n项目仓库建立（包含相关文件夹）\nREADME 包含题目、数据来源、成员分工\n能在 Python程序脚本/Jupyter Notebook 中加载数据并展示基本统计信息\n至少一张数据可视化图\n\nW7：结项答辩（答辩时）\n\n提交完整复现包（见下目录）+ 报告（6–8 页）+ 幻灯（6–8 页）+ AI 使用记录。\n代码能运行：按照 README 步骤能复现结果\n结果齐全：\n\n至少对比 2 种模型\n评估指标表格（分类：准确率/召回率/AUC）\n2-3 张关键图（混淆矩阵/ROC 曲线/特征重要性）\n\n文档完整：\n\nREADME 有复现步骤\n报告有问题描述、方法、结果、分析",
    "crumbs": [
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>项目3：Lending Club（借贷违约风险）学生项目要求</span>"
    ]
  },
  {
    "objectID": "3_lendingclub.html#交付清单统一目录",
    "href": "3_lendingclub.html#交付清单统一目录",
    "title": "12  项目3：Lending Club（借贷违约风险）学生项目要求",
    "section": "12.6 交付清单（统一目录）",
    "text": "12.6 交付清单（统一目录）\nproject_root/\n  README.md                # 项目背景、分工、数据来源与口径摘要、运行命令\n  main.py                  # 单文件分工脚本\n  requirements.txt         # 依赖（pandas/numpy/scikit-learn 等）\n  data/\n    sample.csv             # 样本（数据不上传）\n    README.md              # 数据文件夹结构\n  outputs/\n    predictions.csv        # 模型输出样例（运行脚本可覆盖生成）\n  report.pdf  (或 .md)     # 6–8 页项目报告（请在结题时添加）\n  slides.pdf               # 6–8 页答辩幻灯（请在结题时添加）\n  ai_usage_log.md          # AI 使用记录（日期/工具/用途/采纳与否）\n  .gitignore               # 忽略大文件（保留示例数据与示例输出）",
    "crumbs": [
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>项目3：Lending Club（借贷违约风险）学生项目要求</span>"
    ]
  },
  {
    "objectID": "3_lendingclub.html#技术要求",
    "href": "3_lendingclub.html#技术要求",
    "title": "12  项目3：Lending Club（借贷违约风险）学生项目要求",
    "section": "12.7 技术要求",
    "text": "12.7 技术要求\n最低要求（必须达成）\n\n按照README可以复刻结果。\n最小流程：读取 → 清洗 → 特征 → 切分 → 训练（基线）→ 评估 → 导出。\n基线模型：分类=逻辑回归 / 回归=线性回归；至少 1 个评估指标；固定随机种子；输出预测到 outputs/。\n可复现性：写清版本号与数据来源；提交样例数据与样例输出。\n代码协作：每人仅编辑自己的函数；完成 TODO 后改为 DONE；合并由队长统一执行。\n\n额外加分点\n\n新增 1-3 个简单模型并与基线对比（如 决策树/随机森林），解释差异。\n类别不平衡处理（如类权重/欠采样/过采样/SMOTE）并报告对指标的影响。\n关键图表（分布、相关、特征重要性/系数、ROC/PR 曲线）。\n友好报错与自动日志（数据形状、特征清单、耗时、随机种子）。",
    "crumbs": [
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>项目3：Lending Club（借贷违约风险）学生项目要求</span>"
    ]
  },
  {
    "objectID": "3_lendingclub.html#评分与-rubric统一口径可微调",
    "href": "3_lendingclub.html#评分与-rubric统一口径可微调",
    "title": "12  项目3：Lending Club（借贷违约风险）学生项目要求",
    "section": "12.8 评分与 Rubric（统一口径，可微调）",
    "text": "12.8 评分与 Rubric（统一口径，可微调）\n\n总评 = 团队分 90% + 互评 10%；如公布难度系数（0.9 / 1.0 / 1.1），按乘数计算。\n\n\n12.8.1 团队分（90%）\n\n其中”报告与可读性”仅针对报告文本与图表评分。\n\n\n\n\n\n\n\n\n\n\n\n维度\nA（优秀）\nB（良好）\nC（合格）\nD（需改进）\n\n\n\n\n可运行性(10)\n一键跑通；无报错；跨平台稳定\n一键跑通，小问题可自解\n基本跑通，需老师介入\n无法跑通\n\n\n正确性(20)\n任务实现到位，评估合理\n基本实现，评估略单薄\n只完成部分流程\n偏离题意\n\n\n稳健性(10)\n缺失/异常/边界处理到位\n处理常见问题\n处理有限\n几乎未处理\n\n\n代码质量(10)\n变量/注释清晰，结构整洁\n基本清晰\n可读性一般\n可读性差\n\n\n报告与可读性(30)\n结构清晰、图表规范、叙述有因有据\n大体清晰\n说明不全/结构混乱\n缺失关键说明\n\n\n演示表达(20)\n逻辑清楚，答辩到位\n讲清主要结论\n表达一般\n不能自洽\n\n\n\n\n\n12.8.2 互评（10%）\n\n每位成员对其他人打分；与教师评分结合。\n若互评明显失真，教师可依据提交记录与痕迹进行调整。",
    "crumbs": [
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>项目3：Lending Club（借贷违约风险）学生项目要求</span>"
    ]
  },
  {
    "objectID": "3_lendingclub.html#报告与答辩内容统一骨架",
    "href": "3_lendingclub.html#报告与答辩内容统一骨架",
    "title": "12  项目3：Lending Club（借贷违约风险）学生项目要求",
    "section": "12.9 报告与答辩内容（统一骨架）",
    "text": "12.9 报告与答辩内容（统一骨架）\n报告（6–8 页）\n\n背景与任务（场景、目标、评估指标）\n数据与变量（来源、时间、清洗摘要、口径与过滤、数据字典片段）\n方法（流程图、基线模型、评估方案；说明为何剔除贷后字段）\n结果（表/图 + 解读 + 业务含义；阈值选择与收益/风险权衡）\n误差来源与改进（不平衡处理、特征选择、阈值策略等）\n结论与建议（面向风控/定价/营销的要点）\n\n答辩幻灯（6–8 页）：与报告同结构，突出关键结论与可视化（ROC/PR、Top 特征等）。",
    "crumbs": [
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>项目3：Lending Club（借贷违约风险）学生项目要求</span>"
    ]
  },
  {
    "objectID": "3_lendingclub.html#提交与命名规范",
    "href": "3_lendingclub.html#提交与命名规范",
    "title": "12  项目3：Lending Club（借贷违约风险）学生项目要求",
    "section": "12.10 提交与命名规范",
    "text": "12.10 提交与命名规范\n\n打包：提交 .zip，保留目录结构；不要包含超大无关文件。\n命名：【LC】_【班级】_【组别】.zip；报告/幻灯使用相同前缀。\n提交方式：按课程平台要求（学习通）。",
    "crumbs": [
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>项目3：Lending Club（借贷违约风险）学生项目要求</span>"
    ]
  },
  {
    "objectID": "3_lendingclub.html#学术诚信与-ai-使用政策",
    "href": "3_lendingclub.html#学术诚信与-ai-使用政策",
    "title": "12  项目3：Lending Club（借贷违约风险）学生项目要求",
    "section": "12.11 学术诚信与 AI 使用政策",
    "text": "12.11 学术诚信与 AI 使用政策\n\n允许用 AI 工具进行资料查询、代码解释、调试建议；\n禁止：粘贴未理解的大段生成代码、虚构数据/结果、抄袭他组；\n必交 ai_usage_log.md（日期、工具、用途、是否采纳与原因 2–3 句）；\n发现学术不端将按校规处理。",
    "crumbs": [
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>项目3：Lending Club（借贷违约风险）学生项目要求</span>"
    ]
  },
  {
    "objectID": "4_homecredit.html",
    "href": "4_homecredit.html",
    "title": "13  项目4：Home Credit Default Risk 学生项目要求",
    "section": "",
    "text": "13.1 项目背景",
    "crumbs": [
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>项目4：Home Credit Default Risk 学生项目要求</span>"
    ]
  },
  {
    "objectID": "4_homecredit.html#项目背景",
    "href": "4_homecredit.html#项目背景",
    "title": "13  项目4：Home Credit Default Risk 学生项目要求",
    "section": "",
    "text": "项目名称：Home Credit 个人信用违约风险评估\n应用场景 / 价值：在放款前预测申请人的违约概率（Probability of Default, PD），以支持授信额度、定价与拒绝策略；理解影响违约的关键因素，并用图表与文字解释业务含义。\n数据来源：Kaggle Home Credit Default Risk 公共数据（课程提供子集）。原始数据为多表结构：\n\napplication_train（训练表含 TARGET 标签）\nbureau, bureau_balance（征信局历史贷款与月度余额）\nprevious_application（在本机构的历史申请）\ninstallments_payments（历史分期还款记录）\ncredit_card_balance, POS_CASH_balance（信用卡与消费分期历史月度余额）\n\n任务类型：二分类（TARGET = 1 表示违约，0 表示未违约）。\n数据说明：",
    "crumbs": [
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>项目4：Home Credit Default Risk 学生项目要求</span>"
    ]
  },
  {
    "objectID": "4_homecredit.html#项目任务必须完成",
    "href": "4_homecredit.html#项目任务必须完成",
    "title": "13  项目4：Home Credit Default Risk 学生项目要求",
    "section": "13.2 项目任务（必须完成）",
    "text": "13.2 项目任务（必须完成）\n\n目标变量口径：以 application_train.TARGET 为标签；在报告中明确 TARGET=1/0 的含义，并打印标签比例（说明类别不平衡）。\n样本选择：本项目默认使用课程提供的 application_train 子集作为训练/测试样本（最低要求仅用主表，见 §6）。\n仅用放款前可得信息：严禁使用放款后才可观测的字段或“未来信息”。若进行多表汇总，必须确保仅基于申请日前的历史（见 §6“加分项”约束）。\n数据读取与检查：打印行列数、前 3 行、关键列存在性；在 README.md 记录数据摘要。\n数据清洗：缺失处理、类别规范（大小写/空格）、明显异常值处置（如极端年限、金额）。\n特征工程：至少 2 个新增特征（示例：金额类对数化、AMT_CREDIT/AMT_INCOME 比率、DAYS_EMPLOYED 合理截断、EXT_SOURCE_* 组合）；必要的 One-Hot/分箱。\n训练/测试切分：固定随机种子；说明比例与分层策略（建议 stratify=TARGET）。\n基线模型：逻辑回归（必做基线）；至少 1 个评估指标（推荐 ROC AUC + F1）。\n模型解释：打印或可视化关键特征影响（系数/重要性），并给出 2–3 条业务洞见（如收入负担、征信外部评分等）。\n结果导出：在 outputs/ 输出预测概率列，并在报告中说明阈值选择与业务含义（识别高风险客群）。\n\n\n若本项目有额外口径或字段限制，由任课教师在发布时补充；你们需在报告中如实记录所有口径与过滤规则。",
    "crumbs": [
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>项目4：Home Credit Default Risk 学生项目要求</span>"
    ]
  },
  {
    "objectID": "4_homecredit.html#团队与分工6-10-人",
    "href": "4_homecredit.html#团队与分工6-10-人",
    "title": "13  项目4：Home Credit Default Risk 学生项目要求",
    "section": "13.3 团队与分工（6-10 人）",
    "text": "13.3 团队与分工（6-10 人）\n\n推荐规模：6-10 人；可根据团队实际人数灵活调整。\n核心角色（必须）：\nA. 数据读取与清洗（clean_data）\nB. 数据探索（explore_data）\nC. 特征工程（feature_engineering）\nD. 数据切分（split_data）\nE. 训练模型（train_model）\nF. 评估与导出（evaluate_model / save_predictions）\n可选角色（7-8 人时添加）：\nG. 可视化与报告排版（负责图表制作、报告编写）\nH. presenter（做PPT、项目答辩汇报）\n协作角色（9-10 人时添加）：\nI. 数据探索辅助（协助 A 完成数据理解、可视化探索）\nJ. 特征工程辅助（协助 C 完成特征构造、验证）\nK. 模型调参辅助（协助 E 完成超参数调优、模型对比）\n署名规范：每位成员在自己负责的函数顶部写 (owner 学号)+姓名；不得修改他人代码；合并由队长负责。\n分工建议：\n\n6 人：每人 1 个核心角色\n7 人：6 个核心角色 + 1 个可选角色（G 或 H）\n8 人：6 个核心角色 + 2 个可选角色（G + H）\n9 人：6 个核心角色 + 2 个可选角色 + 1 个协作角色\n10 人：6 个核心角色 + 2 个可选角色 + 2 个协作角色",
    "crumbs": [
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>项目4：Home Credit Default Risk 学生项目要求</span>"
    ]
  },
  {
    "objectID": "4_homecredit.html#数据与合规",
    "href": "4_homecredit.html#数据与合规",
    "title": "13  项目4：Home Credit Default Risk 学生项目要求",
    "section": "13.4 数据与合规",
    "text": "13.4 数据与合规\n\n数据说明：在 README.md 或报告中写明来源、时间范围、关键字段、目标变量口径、过滤规则。\n隐私与伦理：数据已匿名化；如追加外部数据，确保合法来源并说明许可与处理。\n数据字典：提供关键字段释义（表格或清单）。",
    "crumbs": [
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>项目4：Home Credit Default Risk 学生项目要求</span>"
    ]
  },
  {
    "objectID": "4_homecredit.html#交付与时间线统一里程碑",
    "href": "4_homecredit.html#交付与时间线统一里程碑",
    "title": "13  项目4：Home Credit Default Risk 学生项目要求",
    "section": "13.5 交付与时间线（统一里程碑）",
    "text": "13.5 交付与时间线（统一里程碑）\n\nW3：立项检查（第四周上课前提交到学习通/GitHub）\n\n项目仓库建立（包含相关文件夹）\nREADME 包含题目、数据来源、成员分工\n能在 Python程序脚本/Jupyter Notebook 中加载数据并展示基本统计信息\n至少一张数据可视化图\n\nW7：结项答辩（答辩时）\n\n提交完整复现包（见下目录）+ 报告（6–8 页）+ 幻灯（6–8 页）+ AI 使用记录。\n代码能运行：按照 README 步骤能复现结果\n结果齐全：\n\n至少对比 2 种模型\n评估指标表格（分类：准确率/召回率/AUC）\n2-3 张关键图（混淆矩阵/ROC 曲线/特征重要性）\n\n文档完整：\n\nREADME 有复现步骤\n报告有问题描述、方法、结果、分析",
    "crumbs": [
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>项目4：Home Credit Default Risk 学生项目要求</span>"
    ]
  },
  {
    "objectID": "4_homecredit.html#交付清单统一目录",
    "href": "4_homecredit.html#交付清单统一目录",
    "title": "13  项目4：Home Credit Default Risk 学生项目要求",
    "section": "13.6 交付清单（统一目录）",
    "text": "13.6 交付清单（统一目录）\nproject_root/\n  README.md                # 项目背景、分工、数据来源与口径摘要、运行命令\n  main.py                  # 单文件分工脚本\n  requirements.txt         # 依赖（pandas/numpy/scikit-learn 等）\n  data/\n    sample.csv             # 样本（数据不上传）\n    README.md              # 数据文件夹结构\n  outputs/\n    predictions.csv        # 模型输出样例（运行脚本可覆盖生成）\n  report.pdf  (或 .md)     # 6–8 页项目报告（请在结题时添加）\n  slides.pdf               # 6–8 页答辩幻灯（请在结题时添加）\n  ai_usage_log.md          # AI 使用记录（日期/工具/用途/采纳与否）\n  .gitignore               # 忽略大文件（保留示例数据与示例输出）",
    "crumbs": [
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>项目4：Home Credit Default Risk 学生项目要求</span>"
    ]
  },
  {
    "objectID": "4_homecredit.html#技术要求",
    "href": "4_homecredit.html#技术要求",
    "title": "13  项目4：Home Credit Default Risk 学生项目要求",
    "section": "13.7 技术要求",
    "text": "13.7 技术要求\n最低要求（必须达成）\n\n按照README可以复刻结果。\n最小流程：读取 → 清洗 → 特征 → 切分 → 训练（基线）→ 评估 → 导出。\n基线模型：分类=逻辑回归 / 回归=线性回归；至少 1 个评估指标；固定随机种子；输出预测到 outputs/。\n可复现性：写清版本号与数据来源；提交样例数据与样例输出。\n代码协作：每人仅编辑自己的函数；完成 TODO 后改为 DONE；合并由队长统一执行。\n\n额外加分点\n\n单表增强：处理类别不平衡（类权重/欠采样/过采样/SMOTE），报告对指标的影响；或加入 1-3 个简单模型对比（决策树/随机森林）。\n一张辅助表汇总（二选一）：\n\nbureau → 以 SK_ID_CURR 分组，做 历史统计特征（如 过去授信数量/活跃授信占比/逾期笔数 等）；\nprevious_application → 以 SK_ID_CURR 分组，做 历史申请/通过率/拒绝率/延期次数 等统计； 约束：仅使用申请日前的历史信息；只能做左连接到主表，不能使用 installments_payments 等需精细时间对齐的表；在报告中画一张关系图解释你的汇总路径。\n\n可视化：特征分布、相关、系数/重要性、ROC/PR 曲线等。\n工程性：友好报错与自动日志（数据形状、特征清单、耗时、随机种子）。",
    "crumbs": [
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>项目4：Home Credit Default Risk 学生项目要求</span>"
    ]
  },
  {
    "objectID": "4_homecredit.html#评分与-rubric统一口径可微调",
    "href": "4_homecredit.html#评分与-rubric统一口径可微调",
    "title": "13  项目4：Home Credit Default Risk 学生项目要求",
    "section": "13.8 评分与 Rubric（统一口径，可微调）",
    "text": "13.8 评分与 Rubric（统一口径，可微调）\n\n总评 = 团队分 90% + 互评 10%；如公布难度系数（0.9 / 1.0 / 1.1），按乘数计算。\n\n\n13.8.1 团队分（90%）\n\n其中”报告与可读性”仅针对报告文本与图表评分。\n\n\n\n\n\n\n\n\n\n\n\n维度\nA（优秀）\nB（良好）\nC（合格）\nD（需改进）\n\n\n\n\n可运行性(10)\n一键跑通；无报错；跨平台稳定\n一键跑通，小问题可自解\n基本跑通，需老师介入\n无法跑通\n\n\n正确性(20)\n任务实现到位，评估合理\n基本实现，评估略单薄\n只完成部分流程\n偏离题意\n\n\n稳健性(10)\n缺失/异常/边界处理到位\n处理常见问题\n处理有限\n几乎未处理\n\n\n代码质量(10)\n变量/注释清晰，结构整洁\n基本清晰\n可读性一般\n可读性差\n\n\n报告与可读性(30)\n结构清晰、图表规范、叙述有因有据\n大体清晰\n说明不全/结构混乱\n缺失关键说明\n\n\n演示表达(20)\n逻辑清楚，答辩到位\n讲清主要结论\n表达一般\n不能自洽\n\n\n\n\n\n13.8.2 互评（10%）\n\n每位成员对其他人打分；与教师评分结合。\n若互评明显失真，教师可依据提交记录与痕迹进行调整。",
    "crumbs": [
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>项目4：Home Credit Default Risk 学生项目要求</span>"
    ]
  },
  {
    "objectID": "4_homecredit.html#报告与答辩内容统一骨架",
    "href": "4_homecredit.html#报告与答辩内容统一骨架",
    "title": "13  项目4：Home Credit Default Risk 学生项目要求",
    "section": "13.9 报告与答辩内容（统一骨架）",
    "text": "13.9 报告与答辩内容（统一骨架）\n报告（6–8 页）\n\n背景与任务（场景、目标、评估指标）\n数据与变量（来源、时间、清洗摘要、口径与过滤、数据字典片段；若有多表汇总请画数据关系图）\n方法（流程图、基线模型、评估方案；说明为何限制为放款前信息）\n结果（表/图 + 解读 + 业务含义；阈值选择与收益/风险权衡）\n误差来源与改进（类别不平衡、特征选择、时间对齐、阈值策略等）\n结论与建议（面向风控/定价/营销的要点）\n\n答辩幻灯（6–8 页）：与报告同结构，突出关键结论与可视化（ROC/PR、Top 特征等）。",
    "crumbs": [
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>项目4：Home Credit Default Risk 学生项目要求</span>"
    ]
  },
  {
    "objectID": "4_homecredit.html#提交与命名规范",
    "href": "4_homecredit.html#提交与命名规范",
    "title": "13  项目4：Home Credit Default Risk 学生项目要求",
    "section": "13.10 提交与命名规范",
    "text": "13.10 提交与命名规范\n\n打包：提交 .zip，保留目录结构；不要包含超大无关文件。\n命名：【HC】_【班级】_【组别】.zip；报告/幻灯使用相同前缀。\n提交方式：按课程平台要求（学习通）。",
    "crumbs": [
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>项目4：Home Credit Default Risk 学生项目要求</span>"
    ]
  },
  {
    "objectID": "4_homecredit.html#学术诚信与-ai-使用政策",
    "href": "4_homecredit.html#学术诚信与-ai-使用政策",
    "title": "13  项目4：Home Credit Default Risk 学生项目要求",
    "section": "13.11 学术诚信与 AI 使用政策",
    "text": "13.11 学术诚信与 AI 使用政策\n\n允许用 AI 工具进行资料查询、代码解释、调试建议；\n禁止：粘贴未理解的大段生成代码、虚构数据/结果、抄袭他组；\n必交 ai_usage_log.md（日期、工具、用途、是否采纳与原因 2–3 句）；\n发现学术不端将按校规处理。",
    "crumbs": [
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>项目4：Home Credit Default Risk 学生项目要求</span>"
    ]
  },
  {
    "objectID": "5_ieee-cis.html",
    "href": "5_ieee-cis.html",
    "title": "14  项目5：IEEE‑CIS Fraud Detection 学生项目要求",
    "section": "",
    "text": "14.1 项目背景",
    "crumbs": [
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>项目5：IEEE‑CIS Fraud Detection 学生项目要求</span>"
    ]
  },
  {
    "objectID": "5_ieee-cis.html#项目背景",
    "href": "5_ieee-cis.html#项目背景",
    "title": "14  项目5：IEEE‑CIS Fraud Detection 学生项目要求",
    "section": "",
    "text": "项目名称：线上交易实时反欺诈（IEEE‑CIS / Vesta）\n应用场景 / 价值：在交易授权前识别高风险交易，降低欺诈损失与误拒率（减少“好人被拒”）。你们将基于历史交易数据构建一个可在线部署的欺诈概率模型，并解释关键风险特征与业务取舍（查得率 vs. 误杀率）。\n数据来源：课程提供自 Kaggle IEEE‑CIS Fraud Detection 的子集。核心数据表：\n\ntrain_transaction.csv（主表，含标签 isFraud）\ntrain_identity.csv（设备/浏览器/网络指纹，按 TransactionID 可左连接）\n测试集在 Kaggle 为无标签格式，本课程不提交 Kaggle 榜，仅做课程内评估。\n\n任务类型：二分类（isFraud = 1 表示欺诈）。",
    "crumbs": [
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>项目5：IEEE‑CIS Fraud Detection 学生项目要求</span>"
    ]
  },
  {
    "objectID": "5_ieee-cis.html#项目任务必须完成",
    "href": "5_ieee-cis.html#项目任务必须完成",
    "title": "14  项目5：IEEE‑CIS Fraud Detection 学生项目要求",
    "section": "14.2 项目任务（必须完成）",
    "text": "14.2 项目任务（必须完成）\n\n目标变量口径：以主表 isFraud 为标签，1=欺诈/0=正常；报告中打印类比例（说明极度不平衡）。\n样本选择：统一使用课程提供的 ieee_train_sample.csv（主表子集）作为训练/测试样本（最低要求只用主表）。\n仅用授权前可得信息：禁止任何基于未来时点或标签构造的泄漏特征（如在全体数据上先用 isFraud 计算用户的“历史欺诈率”，再用于同一切分的训练/测试）。\n数据读取与检查：打印行列数、前 3 行、关键列存在性；在 README.md 记录数据摘要。\n数据清洗：缺失处理、类别统一（大小写/空格）、明显异常值处置（如不合理金额/时间戳）。\n特征工程（主表）：至少 2 个新增特征（示例：TransactionAmt 对数、金额分箱、addr1/dist1 组合、邮箱域名 Top‑K One‑Hot、card* 频次或长度特征等）；必要的 One‑Hot/分箱。\n训练/测试切分：固定随机种子；说明比例与分层策略（建议 stratify=isFraud）。\n基线模型：逻辑回归（必做基线）；至少 1 个评估指标（推荐 ROC AUC + PR AUC，并给出阈值下的查得率/准确率）。\n模型解释：打印或可视化关键特征影响（系数/重要性），并给出 2–3 条业务洞见（如金额、设备一致性、邮箱域名等）。\n结果导出：在 outputs/ 输出预测概率列，并在报告中说明阈值选择与业务含义（拦截阈值 vs. 人工复核阈值）。\n\n\n允许在基线之上追加 1–2 个简单模型作对比（如 决策树/随机森林/轻量级梯度提升），见“额外加分”。",
    "crumbs": [
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>项目5：IEEE‑CIS Fraud Detection 学生项目要求</span>"
    ]
  },
  {
    "objectID": "5_ieee-cis.html#团队与分工6-10-人",
    "href": "5_ieee-cis.html#团队与分工6-10-人",
    "title": "14  项目5：IEEE‑CIS Fraud Detection 学生项目要求",
    "section": "14.3 团队与分工（6-10 人）",
    "text": "14.3 团队与分工（6-10 人）\n\n推荐规模：6-10 人；可根据团队实际人数灵活调整。\n核心角色（必须）：\nA. 数据读取与清洗（clean_data）\nB. 数据探索（explore_data）\nC. 特征工程（feature_engineering）\nD. 数据切分（split_data）\nE. 训练模型（train_model）\nF. 评估与导出（evaluate_model / save_predictions）\n可选角色（7-8 人时添加）：\nG. 可视化与报告排版（负责图表制作、报告编写）\nH. presenter（做PPT、项目答辩汇报）\n协作角色（9-10 人时添加）：\nI. 数据探索辅助（协助 A 完成数据理解、可视化探索）\nJ. 特征工程辅助（协助 C 完成特征构造、验证）\nK. 模型调参辅助（协助 E 完成超参数调优、模型对比）\n署名规范：每位成员在自己负责的函数顶部写 (owner 学号)+姓名；不得修改他人代码；合并由队长负责。\n分工建议：\n\n6 人：每人 1 个核心角色\n7 人：6 个核心角色 + 1 个可选角色（G 或 H）\n8 人：6 个核心角色 + 2 个可选角色（G + H）\n9 人：6 个核心角色 + 2 个可选角色 + 1 个协作角色\n10 人：6 个核心角色 + 2 个可选角色 + 2 个协作角色",
    "crumbs": [
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>项目5：IEEE‑CIS Fraud Detection 学生项目要求</span>"
    ]
  },
  {
    "objectID": "5_ieee-cis.html#数据与合规",
    "href": "5_ieee-cis.html#数据与合规",
    "title": "14  项目5：IEEE‑CIS Fraud Detection 学生项目要求",
    "section": "14.4 数据与合规",
    "text": "14.4 数据与合规\n\n数据说明：在 README.md 或报告中写明来源、时间范围、关键字段、目标变量口径、过滤规则。\n隐私与伦理：数据已匿名化；如追加外部数据，确保合法来源并说明许可与处理。\n数据字典：提供关键字段释义（表格或清单）。",
    "crumbs": [
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>项目5：IEEE‑CIS Fraud Detection 学生项目要求</span>"
    ]
  },
  {
    "objectID": "5_ieee-cis.html#交付与时间线统一里程碑",
    "href": "5_ieee-cis.html#交付与时间线统一里程碑",
    "title": "14  项目5：IEEE‑CIS Fraud Detection 学生项目要求",
    "section": "14.5 交付与时间线（统一里程碑）",
    "text": "14.5 交付与时间线（统一里程碑）\n\nW3：立项检查（第四周上课前提交到学习通/GitHub）\n\n项目仓库建立（包含相关文件夹）\nREADME 包含题目、数据来源、成员分工\n能在 Python程序脚本/Jupyter Notebook 中加载数据并展示基本统计信息\n至少一张数据可视化图\n\nW7：结项答辩（答辩时）\n\n提交完整复现包（见下目录）+ 报告（6–8 页）+ 幻灯（6–8 页）+ AI 使用记录。\n代码能运行：按照 README 步骤能复现结果\n结果齐全：\n\n至少对比 2 种模型\n评估指标表格（分类：准确率/召回率/AUC）\n2-3 张关键图（混淆矩阵/ROC 曲线/特征重要性）\n\n文档完整：\n\nREADME 有复现步骤\n报告有问题描述、方法、结果、分析",
    "crumbs": [
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>项目5：IEEE‑CIS Fraud Detection 学生项目要求</span>"
    ]
  },
  {
    "objectID": "5_ieee-cis.html#交付清单统一目录",
    "href": "5_ieee-cis.html#交付清单统一目录",
    "title": "14  项目5：IEEE‑CIS Fraud Detection 学生项目要求",
    "section": "14.6 交付清单（统一目录）",
    "text": "14.6 交付清单（统一目录）\nproject_root/\n  README.md                # 项目背景、分工、数据来源与口径摘要、运行命令\n  main.py                  # 单文件分工脚本\n  requirements.txt         # 依赖（pandas/numpy/scikit-learn 等）\n  data/\n    sample.csv             # 样本（数据不上传）\n    README.md              # 数据文件夹结构\n  outputs/\n    predictions.csv        # 模型输出样例（运行脚本可覆盖生成）\n  report.pdf  (或 .md)     # 6–8 页项目报告（请在结题时添加）\n  slides.pdf               # 6–8 页答辩幻灯（请在结题时添加）\n  ai_usage_log.md          # AI 使用记录（日期/工具/用途/采纳与否）\n  .gitignore               # 忽略大文件（保留示例数据与示例输出）",
    "crumbs": [
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>项目5：IEEE‑CIS Fraud Detection 学生项目要求</span>"
    ]
  },
  {
    "objectID": "5_ieee-cis.html#技术要求",
    "href": "5_ieee-cis.html#技术要求",
    "title": "14  项目5：IEEE‑CIS Fraud Detection 学生项目要求",
    "section": "14.7 技术要求",
    "text": "14.7 技术要求\n最低要求（必须达成）\n\n按照README可以复刻结果。\n最小流程：读取 → 清洗 → 特征 → 切分 → 训练（基线）→ 评估 → 导出。\n基线模型：分类=逻辑回归 / 回归=线性回归；至少 1 个评估指标；固定随机种子；输出预测到 outputs/。\n可复现性：写清版本号与数据来源；提交样例数据与样例输出。\n代码协作：每人仅编辑自己的函数；完成 TODO 后改为 DONE；合并由队长统一执行。\n\n额外加分点（任选 1–4 项）\n\n时间感知切分：用 TransactionDT 做时间顺序切分（前 80% 时间训练，后 20% 测试），并对比随机切分差异。\n类别不平衡处理：类权重/下采样/上采样/SMOTE；并报告对 PR AUC / 查得率@固定误杀率 的影响。\n单张辅助表汇总（≤1 张，identity 表优先）：以 TransactionID 左连接到主表，抽取设备/浏览器/网络的聚合特征（如出现频次、稳定度、近期多端登录计数）。\n可视化 ≥2 张：金额分布、邮箱域名 Top‑K、设备/浏览器稳定性、ROC/PR 曲线等。\n工程性：友好报错与自动日志（数据形状、特征清单、耗时、随机种子）。",
    "crumbs": [
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>项目5：IEEE‑CIS Fraud Detection 学生项目要求</span>"
    ]
  },
  {
    "objectID": "5_ieee-cis.html#评分与-rubric统一口径可微调",
    "href": "5_ieee-cis.html#评分与-rubric统一口径可微调",
    "title": "14  项目5：IEEE‑CIS Fraud Detection 学生项目要求",
    "section": "14.8 评分与 Rubric（统一口径，可微调）",
    "text": "14.8 评分与 Rubric（统一口径，可微调）\n\n总评 = 团队分 90% + 互评 10%；如公布难度系数（0.9 / 1.0 / 1.1），按乘数计算。\n\n\n14.8.1 团队分（90%）\n\n其中”报告与可读性”仅针对报告文本与图表评分。\n\n\n\n\n\n\n\n\n\n\n\n维度\nA（优秀）\nB（良好）\nC（合格）\nD（需改进）\n\n\n\n\n可运行性(10)\n一键跑通；无报错；跨平台稳定\n一键跑通，小问题可自解\n基本跑通，需老师介入\n无法跑通\n\n\n正确性(20)\n任务实现到位，评估合理\n基本实现，评估略单薄\n只完成部分流程\n偏离题意\n\n\n稳健性(10)\n缺失/异常/边界处理到位\n处理常见问题\n处理有限\n几乎未处理\n\n\n代码质量(10)\n变量/注释清晰，结构整洁\n基本清晰\n可读性一般\n可读性差\n\n\n报告与可读性(30)\n结构清晰、图表规范、叙述有因有据\n大体清晰\n说明不全/结构混乱\n缺失关键说明\n\n\n演示表达(20)\n逻辑清楚，答辩到位\n讲清主要结论\n表达一般\n不能自洽\n\n\n\n\n\n14.8.2 互评（10%）\n\n每位成员对其他人打分；与教师评分结合。\n若互评明显失真，教师可依据提交记录与痕迹进行调整。",
    "crumbs": [
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>项目5：IEEE‑CIS Fraud Detection 学生项目要求</span>"
    ]
  },
  {
    "objectID": "5_ieee-cis.html#报告与答辩内容统一骨架",
    "href": "5_ieee-cis.html#报告与答辩内容统一骨架",
    "title": "14  项目5：IEEE‑CIS Fraud Detection 学生项目要求",
    "section": "14.9 报告与答辩内容（统一骨架）",
    "text": "14.9 报告与答辩内容（统一骨架）\n报告（6–8 页）\n\n背景与任务（场景、目标、评估指标）\n数据与变量（来源、时间、清洗摘要、口径与过滤、数据字典片段；如有 identity 汇总请画数据关系图）\n方法（流程图、基线模型、评估方案；强调如何防止信息泄漏）\n结果（表/图 + 解读 + 业务含义；阈值选择与查得/误杀权衡；PR 曲线解读）\n误差来源与改进（类别不平衡、时间漂移、特征选择、编码方式等）\n结论与建议（面向风控的可执行建议：拦截阈值、人工复核策略等）\n\n答辩幻灯（6–8 页）：与报告同结构，突出关键结论与可视化（ROC/PR、Top 特征等）。",
    "crumbs": [
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>项目5：IEEE‑CIS Fraud Detection 学生项目要求</span>"
    ]
  },
  {
    "objectID": "5_ieee-cis.html#提交与命名规范",
    "href": "5_ieee-cis.html#提交与命名规范",
    "title": "14  项目5：IEEE‑CIS Fraud Detection 学生项目要求",
    "section": "14.10 提交与命名规范",
    "text": "14.10 提交与命名规范\n\n打包：提交 .zip，保留目录结构；不要包含超大无关文件。\n命名：【IEEE】_【班级】_【队名】.zip；报告/幻灯使用相同前缀。\n提交方式：按课程平台要求（学习通 / LMS / GitHub Release）。",
    "crumbs": [
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>项目5：IEEE‑CIS Fraud Detection 学生项目要求</span>"
    ]
  },
  {
    "objectID": "5_ieee-cis.html#学术诚信与-ai-使用政策",
    "href": "5_ieee-cis.html#学术诚信与-ai-使用政策",
    "title": "14  项目5：IEEE‑CIS Fraud Detection 学生项目要求",
    "section": "14.11 学术诚信与 AI 使用政策",
    "text": "14.11 学术诚信与 AI 使用政策\n\n允许用 AI 工具进行资料查询、代码解释、调试建议；\n禁止：粘贴未理解的大段生成代码、虚构数据/结果、抄袭他组；\n必交 ai_usage_log.md（日期、工具、用途、是否采纳与原因 2–3 句）；\n发现学术不端将按校规处理。",
    "crumbs": [
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>项目5：IEEE‑CIS Fraud Detection 学生项目要求</span>"
    ]
  },
  {
    "objectID": "6_gresearch.html",
    "href": "6_gresearch.html",
    "title": "15  项目6：G‑Research Crypto Forecasting 学生项目要求",
    "section": "",
    "text": "15.1 项目背景",
    "crumbs": [
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>项目6：G‑Research Crypto Forecasting 学生项目要求</span>"
    ]
  },
  {
    "objectID": "6_gresearch.html#项目背景",
    "href": "6_gresearch.html#项目背景",
    "title": "15  项目6：G‑Research Crypto Forecasting 学生项目要求",
    "section": "",
    "text": "项目名称：加密资产短期收益率预测（G‑Research Crypto）\n应用场景 / 价值：针对多种主流加密货币（BTC、ETH 等），在未来15分钟（或指定窗口）内预测其对数收益率（Target），用于风险控制与交易信号。你们需要在“仅基于过去可见信息”的前提下构建回归模型，并用图表与文字解释关键驱动因素与业务含义。\n数据来源：课程提供自 Kaggle G‑Research Crypto Forecasting 的单表子集（已对齐列名），典型列：timestamp, Asset_ID, Count, Open, High, Low, Close, Volume, VWAP, Target（不同发放版本以教师说明为准）。\n任务类型：回归（预测 Target 连续值；Target 常表示未来短窗的残差化/相对市场的对数收益）。",
    "crumbs": [
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>项目6：G‑Research Crypto Forecasting 学生项目要求</span>"
    ]
  },
  {
    "objectID": "6_gresearch.html#项目任务必须完成",
    "href": "6_gresearch.html#项目任务必须完成",
    "title": "15  项目6：G‑Research Crypto Forecasting 学生项目要求",
    "section": "15.2 项目任务（必须完成）",
    "text": "15.2 项目任务（必须完成）\n\n目标变量口径：以数据中的 Target 为标签；报告中解释其含义（未来短窗收益/对数收益的残差化）并打印分布（均值、标准差、分位数）。\n样本选择：使用课程提供的 crypto_train_sample.csv（主表子集）作为训练/测试样本（最低要求只用主表）。\n仅用过去可得信息：所有特征必须由当前及之前时刻的数据构造；严格禁止使用未来时间或标签泄漏（详见 §6“防泄漏约束”）。\n数据读取与检查：打印行列数、时间范围、资产数（Asset_ID 去重数量）、关键列存在性；在 README.md 记录数据摘要。\n数据清洗：缺失处理、异常值（如非正价格）、时间排序与去重；说明处理口径与理由。\n特征工程（主表）：至少 2 个新增时序特征（示例：基于 Close/VWAP/Volume 的滞后项、滚动均值/标准差/偏度、收益/波动率分箱、价量比率等）；必要时对高基数类别（如邮箱域名不涉及，本题多为数值/ID）。\n时间感知切分：按时间先后切分（建议前80%时间训练，后20%时间测试），并说明是否做资产分层或同时建模。\n基线模型：线性回归（Linear Regression）作为必做基线；至少 2 个评估指标（推荐 RMSE + 皮尔逊相关系数）。\n模型解释：可视化/打印关键特征影响（系数/重要性/部分依赖），结合业务提出 2–3 条洞见（如“近15分钟波动率上升与负回报相关”）。\n结果导出：在 outputs/ 输出预测值列（与 Target 对齐），并在报告中说明在不同阈值/排序下的业务含义（如取 Top‑K 作为交易信号的直觉）。\n\n\n允许在基线之上追加 1–2 个轻量模型对比（如 岭回归/Ridge、随机森林、轻量GBDT），见“额外加分”。",
    "crumbs": [
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>项目6：G‑Research Crypto Forecasting 学生项目要求</span>"
    ]
  },
  {
    "objectID": "6_gresearch.html#团队与分工6-10-人",
    "href": "6_gresearch.html#团队与分工6-10-人",
    "title": "15  项目6：G‑Research Crypto Forecasting 学生项目要求",
    "section": "15.3 团队与分工（6-10 人）",
    "text": "15.3 团队与分工（6-10 人）\n\n推荐规模：6-10 人；可根据团队实际人数灵活调整。\n核心角色（必须）：\nA. 数据读取与清洗（clean_data）\nB. 数据探索（explore_data）\nC. 特征工程（feature_engineering）\nD. 数据切分（split_data）\nE. 训练模型（train_model）\nF. 评估与导出（evaluate_model / save_predictions）\n可选角色（7-8 人时添加）：\nG. 可视化与报告排版（负责图表制作、报告编写）\nH. presenter（做PPT、项目答辩汇报）\n协作角色（9-10 人时添加）：\nI. 数据探索辅助（协助 A 完成数据理解、可视化探索）\nJ. 特征工程辅助（协助 C 完成特征构造、验证）\nK. 模型调参辅助（协助 E 完成超参数调优、模型对比）\n署名规范：每位成员在自己负责的函数顶部写 (owner 学号)+姓名；不得修改他人代码；合并由队长负责。\n分工建议：\n\n6 人：每人 1 个核心角色\n7 人：6 个核心角色 + 1 个可选角色（G 或 H）\n8 人：6 个核心角色 + 2 个可选角色（G + H）\n9 人：6 个核心角色 + 2 个可选角色 + 1 个协作角色\n10 人：6 个核心角色 + 2 个可选角色 + 2 个协作角色",
    "crumbs": [
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>项目6：G‑Research Crypto Forecasting 学生项目要求</span>"
    ]
  },
  {
    "objectID": "6_gresearch.html#数据与合规",
    "href": "6_gresearch.html#数据与合规",
    "title": "15  项目6：G‑Research Crypto Forecasting 学生项目要求",
    "section": "15.4 数据与合规",
    "text": "15.4 数据与合规\n\n数据说明：在 README.md 或报告中写明来源、时间范围、资产覆盖、关键字段、目标变量口径、过滤规则。\n隐私与伦理：数据为公开市场数据；如追加外部因子（如比特币主导度、恐慌贪婪指数），须注明来源与许可，并严格对齐时间戳，避免引入未来信息。\n数据字典：提供关键字段释义（表格或清单）。",
    "crumbs": [
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>项目6：G‑Research Crypto Forecasting 学生项目要求</span>"
    ]
  },
  {
    "objectID": "6_gresearch.html#交付与时间线统一里程碑",
    "href": "6_gresearch.html#交付与时间线统一里程碑",
    "title": "15  项目6：G‑Research Crypto Forecasting 学生项目要求",
    "section": "15.5 交付与时间线（统一里程碑）",
    "text": "15.5 交付与时间线（统一里程碑）\n\nW3：立项检查（第四周上课前提交到学习通/GitHub）\n\n项目仓库建立（包含相关文件夹）\nREADME 包含题目、数据来源、成员分工\n能在 Python程序脚本/Jupyter Notebook 中加载数据并展示基本统计信息\n至少一张数据可视化图\n\nW7：结项答辩（答辩时）\n\n提交完整复现包（见下目录）+ 报告（6–8 页）+ 幻灯（6–8 页）+ AI 使用记录。\n代码能运行：按照 README 步骤能复现结果\n结果齐全：\n\n至少对比 2 种模型\n评估指标表格（回归：RMSE/MAE）\n2-3 张关键图（特征重要性/残差图）\n\n文档完整：\n\nREADME 有复现步骤\n报告有问题描述、方法、结果、分析",
    "crumbs": [
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>项目6：G‑Research Crypto Forecasting 学生项目要求</span>"
    ]
  },
  {
    "objectID": "6_gresearch.html#交付清单统一目录",
    "href": "6_gresearch.html#交付清单统一目录",
    "title": "15  项目6：G‑Research Crypto Forecasting 学生项目要求",
    "section": "15.6 交付清单（统一目录）",
    "text": "15.6 交付清单（统一目录）\nproject_root/\n  README.md                # 项目背景、分工、数据来源与口径摘要、运行命令\n  main.py                  # 单文件分工脚本\n  requirements.txt         # 依赖（pandas/numpy/scikit-learn 等）\n  data/\n    sample.csv             # 样本（数据不上传）\n    README.md              # 数据文件夹结构\n  outputs/\n    predictions.csv        # 模型输出样例（运行脚本可覆盖生成）\n  report.pdf  (或 .md)     # 6–8 页项目报告（请在结题时添加）\n  slides.pdf               # 6–8 页答辩幻灯（请在结题时添加）\n  ai_usage_log.md          # AI 使用记录（日期/工具/用途/采纳与否）\n  .gitignore               # 忽略大文件（保留示例数据与示例输出）",
    "crumbs": [
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>项目6：G‑Research Crypto Forecasting 学生项目要求</span>"
    ]
  },
  {
    "objectID": "6_gresearch.html#技术要求",
    "href": "6_gresearch.html#技术要求",
    "title": "15  项目6：G‑Research Crypto Forecasting 学生项目要求",
    "section": "15.7 技术要求",
    "text": "15.7 技术要求\n最低要求（必须达成）\n\n按照README可以复刻结果。\n最小流程：读取 → 清洗 → 特征 → 切分 → 训练（基线）→ 评估 → 导出。\n基线模型：分类=逻辑回归 / 回归=线性回归；至少 1 个评估指标；固定随机种子；输出预测到 outputs/。\n可复现性：写清版本号与数据来源；提交样例数据与样例输出。\n代码协作：每人仅编辑自己的函数；完成 TODO 后改为 DONE；合并由队长统一执行。\n\n额外加分点（任选 1–4 项）\n\n多资产学习：同一模型联合建模（加入 Asset_ID One‑Hot/嵌入）或分资产建模+加权融合；报告跨资产表现差异。\n市场因子/残差化：构造市场收益因子（按资产权重的横截面加权收益），模型预测个体资产相对市场的超额/残差收益，并与基线对比。\n滑窗验证：使用滚动/扩展窗口交叉验证；报告随时间的稳定性（绘制滚动相关/滚动RMSE）。\n可视化 ≥2 张：时间序列趋势、滚动波动、特征重要性、残差随时间/资产分布等。\n工程性：友好报错与自动日志（数据形状、资产列表、时间范围、耗时、随机种子）。",
    "crumbs": [
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>项目6：G‑Research Crypto Forecasting 学生项目要求</span>"
    ]
  },
  {
    "objectID": "6_gresearch.html#评分与-rubric统一口径可微调",
    "href": "6_gresearch.html#评分与-rubric统一口径可微调",
    "title": "15  项目6：G‑Research Crypto Forecasting 学生项目要求",
    "section": "15.8 评分与 Rubric（统一口径，可微调）",
    "text": "15.8 评分与 Rubric（统一口径，可微调）\n\n总评 = 团队分 90% + 互评 10%；如公布难度系数（0.9 / 1.0 / 1.1），按乘数计算。\n\n\n15.8.1 团队分（90%）\n\n其中”报告与可读性”仅针对报告文本与图表评分。\n\n\n\n\n\n\n\n\n\n\n\n维度\nA（优秀）\nB（良好）\nC（合格）\nD（需改进）\n\n\n\n\n可运行性(10)\n一键跑通；无报错；跨平台稳定\n一键跑通，小问题可自解\n基本跑通，需老师介入\n无法跑通\n\n\n正确性(20)\n任务实现到位，评估合理\n基本实现，评估略单薄\n只完成部分流程\n偏离题意\n\n\n稳健性(10)\n缺失/异常/边界处理到位\n处理常见问题\n处理有限\n几乎未处理\n\n\n代码质量(10)\n变量/注释清晰，结构整洁\n基本清晰\n可读性一般\n可读性差\n\n\n报告与可读性(30)\n结构清晰、图表规范、叙述有因有据\n大体清晰\n说明不全/结构混乱\n缺失关键说明\n\n\n演示表达(20)\n逻辑清楚，答辩到位\n讲清主要结论\n表达一般\n不能自洽\n\n\n\n\n\n15.8.2 互评（10%）\n\n每位成员对其他人打分；与教师评分结合。\n若互评明显失真，教师可依据提交记录与痕迹进行调整。",
    "crumbs": [
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>项目6：G‑Research Crypto Forecasting 学生项目要求</span>"
    ]
  },
  {
    "objectID": "6_gresearch.html#报告与答辩内容统一骨架",
    "href": "6_gresearch.html#报告与答辩内容统一骨架",
    "title": "15  项目6：G‑Research Crypto Forecasting 学生项目要求",
    "section": "15.9 报告与答辩内容（统一骨架）",
    "text": "15.9 报告与答辩内容（统一骨架）\n报告（6–8 页）\n\n背景与任务（场景、目标、评估指标）\n数据与变量（来源、时间、资产、清洗摘要、口径与过滤、数据字典片段）\n方法（流程图、基线模型、评估方案；强调时间切分与防泄漏）\n结果（表/图 + 解读 + 业务含义；滚动窗口稳定性；多资产对比）\n误差来源与改进（特征时效、非平稳/漂移、窗口大小、跨资产泛化等）\n结论与建议（面向交易/风控的可执行建议：信号阈值、更新频率等）\n\n答辩幻灯（6–8 页）：与报告同结构，突出关键结论与可视化（滚动相关/Top 特征等）。",
    "crumbs": [
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>项目6：G‑Research Crypto Forecasting 学生项目要求</span>"
    ]
  },
  {
    "objectID": "6_gresearch.html#提交与命名规范",
    "href": "6_gresearch.html#提交与命名规范",
    "title": "15  项目6：G‑Research Crypto Forecasting 学生项目要求",
    "section": "15.10 提交与命名规范",
    "text": "15.10 提交与命名规范\n\n打包：提交 .zip，保留目录结构；不要包含超大无关文件。\n命名：【CRYPTO】_【班级】_【队名】.zip；报告/幻灯使用相同前缀。\n提交方式：按课程平台要求（学习通 / LMS / GitHub Release）。",
    "crumbs": [
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>项目6：G‑Research Crypto Forecasting 学生项目要求</span>"
    ]
  },
  {
    "objectID": "6_gresearch.html#学术诚信与-ai-使用政策",
    "href": "6_gresearch.html#学术诚信与-ai-使用政策",
    "title": "15  项目6：G‑Research Crypto Forecasting 学生项目要求",
    "section": "15.11 学术诚信与 AI 使用政策",
    "text": "15.11 学术诚信与 AI 使用政策\n\n允许用 AI 工具进行资料查询、代码解释、调试建议；\n禁止：粘贴未理解的大段生成代码、虚构数据/结果、抄袭他组；\n必交 ai_usage_log.md（日期、工具、用途、是否采纳与原因 2–3 句）；\n发现学术不端将按校规处理。",
    "crumbs": [
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>项目6：G‑Research Crypto Forecasting 学生项目要求</span>"
    ]
  }
]