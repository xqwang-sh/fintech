---
title: 第二讲：数据处理与线性回归实践
---

```{python}
#| echo: false
import matplotlib.pyplot as plt
# 根据操作系统设置不同的字体
import platform

# 获取操作系统类型
system = platform.system()

# 设置 matplotlib 字体
if system == 'Windows':
    plt.rcParams['font.sans-serif'] = ['SimHei']  # Windows 使用黑体
elif system == 'Darwin':
    plt.rcParams['font.sans-serif'] = ['Songti SC']  # Mac 使用宋体
else:
    plt.rcParams['font.sans-serif'] = ['WenQuanYi Zen Hei']  # Linux 使用文泉驿正黑

# 解决负号显示问题
plt.rcParams['axes.unicode_minus'] = False

```

## 开场：为什么数据预处理如此重要？

---

### 一个真实的场景

**假设你收到这样一份数据...**

| 面积 | 卧室数 | 房龄 | 价格 |
|------|--------|------|------|
| 100  | 2      | 5    | 200  |
| 120  | ?      | 8    | 250  |
| -50  | 3      | 10   | 150  |
| 110  | 2      | 999  | 280  |

**问题**：

- 第 2 行：卧室数缺失
- 第 3 行：面积为负数（不合理）
- 第 4 行：房龄 999 年（明显异常）

**能直接训练模型吗？**

::: {.fragment}
❌ **不能！** 模型会学到错误的规律，或者直接报错。
:::

---

### 本周学习目标

#### 知识目标
1. 理解数据预处理的重要性（缺失值、异常值、归一化）
2. 掌握回归模型的评估指标（MAE、RMSE、R²）
3. 理解残差的概念及其诊断作用
4. 掌握数据可视化的基本原则

#### 技能目标
1. 使用 pandas 探索和清洗数据
2. 使用 matplotlib/seaborn 绘制多种图表
3. 训练完整的线性回归模型并评估
4. 进行残差分析

#### 核心理念
**"垃圾进，垃圾出"（Garbage In, Garbage Out）**  
数据质量决定模型质量！

---

## 第一部分：数据预处理

---

### 缺失值处理

#### 什么是缺失值？

- 数据收集过程中未记录的值
- 在 pandas 中显示为 `NaN`（Not a Number）
- 例子：客户忘记填年龄、传感器故障

---

#### 🔍 缺失值处理的首要原则：理解业务逻辑

**业务理解优先于技术方法**

- **为什么缺失？** 分析缺失的根本原因
- **隐形缺失**：有些缺失并非数据错误，而是业务逻辑的一部分
- **填补策略**：优先基于业务逻辑，然后考虑统计方法

---

#### 📊 隐形缺失的经典案例

**R&D支出示例**：

```python
#| echo: true

# 金融数据中的R&D支出
company_data = {
    '公司名称': ['科技公司A', '传统公司B', '创业公司C'],
    'R&D支出': [1000, np.nan, 500]  # 传统公司显示为NaN
}

# 业务逻辑分析：
# - 传统公司B没有R&D部门，所以R&D支出应该是0，不是缺失值！
# - 错误填补：用均值(750) → 传统公司被高估
# - 正确填补：根据业务逻辑填0 → 准确反映业务现实
```

**其他隐形缺失案例**：

- 学生成绩单中"实习经历"为空 → 可能从未实习，应填"无"
- 电商数据中"退货原因"为空 → 可能未退货，应填"无退货"
- 医疗数据中"家族遗传病史"为空 → 需要区分"未询问"vs"无家族史"

---

#### 缺失值处理决策流程

```{mermaid}
graph TD
    A[发现缺失值] --> B[理解业务逻辑<br/>为何缺失？]
    B --> C{是否为<br/>隐形缺失？}

    C -->|是| D[根据业务规则填补<br/>如R&D=0, 退货原因=无]
    C -->|否| E[检查缺失比例]

    E -->|很小 <5%| F[删除法]
    E -->|中等 5-20%| G[统计填充法]
    E -->|较大 >20%| H[高级方法或<br/>放弃特征]

    D --> I[验证业务合理性]
    F --> I
    G --> I
    H --> I

    style D fill:#4caf50,color:#fff
    style I fill:#2196f3,color:#fff
```

---

#### 删除法

**原始数据**：`[100, NaN, 120, 110, NaN]`

**删除后**：`[100, 120, 110]`

**优点**：
- 简单直接
- 不引入偏差

**缺点**：
- 丢失信息
- 样本量减少

**适用场景**：缺失比例很小（<5%）

---

#### 填充法

**常用填充值**：

| 特征类型 | 推荐填充值 | 原因 |
|---------|-----------|------|
| 连续型（如年龄） | 中位数 | 不受极端值影响 |
| 计数型（如卧室数） | 众数 | 符合实际分布 |
| 二元型（如性别） | 众数 | 最常见类别 |

**示例**：

```
原始: [10, 20, NaN, 30, 100]
均值填充: [10, 20, 32, 30, 100]  ← 受极端值影响
中位数填充: [10, 20, 25, 30, 100]  ← 更稳健 ✓
```

---

#### 高级方法（简介）

**模型预测填充**：
- 用其他特征预测缺失值
- 例子：根据房屋面积、位置预测缺失的房龄
- 后续课程会学习

**多重插补**：
- 生成多个填充版本
- 综合结果
- 统计学高级方法

---

### 异常值检测与处理

#### 什么是异常值？

**定义**：明显偏离正常范围的数据点

**例子**：

- 房价数据中出现 1 元/平米（可能是录入错误）
- 年龄数据中出现 999 岁（占位符未替换）
- 收入数据中出现负值（除非是亏损）

**关键问题**：**异常值 ≠ 错误值**

- 亿万富翁买豪宅（真实但极端） → 保留
- 录入错误（如 1 元/平米） → 删除/修正

---

#### 异常值识别：箱线图

```{python}
import numpy as np
import pandas as pd
import seaborn as sns

np.random.seed(42)
# 正常数据 + 几个异常值
normal_data = np.random.normal(100, 15, 100)
outliers = np.array([50, 55, 180, 190])
price_data = np.concatenate([normal_data, outliers])

plt.figure(figsize=(10, 6))
plt.subplot(1, 2, 1)
plt.boxplot(price_data, vert=True)
plt.ylabel('房价 (万元)')
plt.title('箱线图：异常值检测')
plt.grid(True, alpha=0.3)

# 标注关键位置
Q1 = np.percentile(price_data, 25)
Q3 = np.percentile(price_data, 75)
IQR = Q3 - Q1
lower_bound = Q1 - 1.5 * IQR
upper_bound = Q3 + 1.5 * IQR

plt.axhline(y=Q1, color='green', linestyle='--', alpha=0.5, label=f'Q1={Q1:.1f}')
plt.axhline(y=Q3, color='blue', linestyle='--', alpha=0.5, label=f'Q3={Q3:.1f}')
plt.axhline(y=lower_bound, color='red', linestyle='--', alpha=0.5, label=f'下界={lower_bound:.1f}')
plt.axhline(y=upper_bound, color='red', linestyle='--', alpha=0.5, label=f'上界={upper_bound:.1f}')
plt.legend(fontsize=8)

plt.subplot(1, 2, 2)
plt.hist(price_data, bins=20, edgecolor='black', alpha=0.7)
plt.xlabel('房价 (万元)')
plt.ylabel('频数')
plt.title('直方图：数据分布')
plt.axvline(x=lower_bound, color='red', linestyle='--', label='异常值边界')
plt.axvline(x=upper_bound, color='red', linestyle='--')
plt.legend()
plt.grid(True, alpha=0.3)

plt.tight_layout()
plt.show()
```

**箱线图组成**：

- **箱体**：Q1 到 Q3（中间 50% 数据）
- **中线**：中位数
- **须**：正常数据范围
- **点**：异常值

---

#### 异常值识别：统计方法

**1. IQR 方法（四分位距）**

```
Q1 = 25% 分位数
Q3 = 75% 分位数
IQR = Q3 - Q1
下界 = Q1 - 1.5 × IQR
上界 = Q3 + 1.5 × IQR

异常值 = 低于下界 或 高于上界
```

**2. 3σ 原则**

```
异常值 = 超出 [均值 - 3×标准差, 均值 + 3×标准差]
```

---

#### 异常值处理决策

```{mermaid}
graph TD
    A[发现异常值] --> B{分析原因}
    B --> C{是否错误?}
    C -->|明确错误<br/>如负数面积| D[删除]
    C -->|不确定| E{业务判断}
    C -->|真实极端值<br/>如豪宅| F[保留]
    
    E -->|影响大| D
    E -->|影响小| G[替换为边界值<br/>Winsorization]
    E -->|需要建模| F
    
    style D fill:#f44336,color:#fff
    style F fill:#4caf50,color:#fff
    style G fill:#ff9800,color:#fff
```

**关键原则**：**先分析，再处理！不要盲目删除！**

---

### 归一化（Normalization）

#### 为什么需要归一化？

**问题场景**：

| 特征 | 范围 | 单位 |
|------|------|------|
| 面积 | 50-200 | 平米 |
| 房龄 | 0-50 | 年 |
| 票价 | 10-5000 | 元 |

**影响**：

- 某些模型（如神经网络、SVM）对特征尺度敏感
- 大数值特征会主导梯度下降
- 导致收敛慢或不收敛

**线性回归影响较小，但归一化仍有益**

---

#### 两种常用归一化方法

**1. Min-Max 归一化（缩放到 [0, 1]）**

$$
x' = \frac{x - \min(x)}{\max(x) - \min(x)}
$$

**示例**：`[10, 20, 30]` → `[0, 0.5, 1]`

**优点**：
- 保留原始分布形状
- 结果有界

**缺点**：
- 对异常值敏感

---

**2. Z-score 标准化（均值 0，标准差 1）**

$$
x' = \frac{x - \mu}{\sigma}
$$

**示例**：`[10, 20, 30]` → `[-1, 0, 1]`

**优点**：
- 不受异常值影响（相对）
- 适合正态分布数据

**缺点**：
- 结果无界

---

#### 归一化前后对比

```{python}
from sklearn.preprocessing import MinMaxScaler, StandardScaler

# 模拟三个特征
np.random.seed(42)
area = np.random.uniform(50, 200, 100)    # 面积 50-200
age = np.random.uniform(0, 50, 100)       # 房龄 0-50
price = np.random.uniform(100, 500, 100)  # 价格 100-500

# 创建 DataFrame
data_orig = pd.DataFrame({
    '面积': area,
    '房龄': age,
    '价格': price
})

# Min-Max 归一化
scaler_minmax = MinMaxScaler()
data_minmax = pd.DataFrame(
    scaler_minmax.fit_transform(data_orig),
    columns=data_orig.columns
)

# Z-score 标准化
scaler_std = StandardScaler()
data_std = pd.DataFrame(
    scaler_std.fit_transform(data_orig),
    columns=data_orig.columns
)

# 可视化
fig, axes = plt.subplots(1, 3, figsize=(15, 5))

# 原始数据
data_orig.boxplot(ax=axes[0])
axes[0].set_title('原始数据')
axes[0].set_ylabel('数值')
axes[0].grid(True, alpha=0.3)

# Min-Max
data_minmax.boxplot(ax=axes[1])
axes[1].set_title('Min-Max 归一化 [0,1]')
axes[1].set_ylabel('归一化值')
axes[1].grid(True, alpha=0.3)

# Z-score
data_std.boxplot(ax=axes[2])
axes[2].set_title('Z-score 标准化 (μ=0, σ=1)')
axes[2].set_ylabel('标准化值')
axes[2].grid(True, alpha=0.3)

plt.tight_layout()
plt.show()
```

---

#### 何时使用哪种归一化？

| 方法 | 适用场景 | 例子 |
|------|---------|------|
| **Min-Max** | 数据分布均匀<br/>需要固定范围<br/>图像数据（0-255 → 0-1） | 神经网络输入层 |
| **Z-score** | 数据有异常值<br/>正态分布<br/>需要保留分布形状 | 逻辑回归<br/>SVM |
| **不归一化** | 树模型<br/>（决策树、随机森林、GBDT） | 线性回归影响小<br/>但建议归一化 |

---

## 第二部分：回归模型评估

---

### 残差（Residual）

#### 核心概念

**定义**：
$$
\text{残差} = \text{真实值} - \text{预测值} = y - \hat{y}
$$

**例子**：

| 样本 | 真实价格 | 预测价格 | 残差 |
|------|---------|---------|------|
| 1 | 250 | 240 | +10 |
| 2 | 200 | 210 | -10 |
| 3 | 300 | 295 | +5 |

---

#### 理想的残差

```{python}
# 模拟好的模型和差的模型
np.random.seed(42)
X = np.linspace(0, 10, 100)
y_true = 2*X + 3 + np.random.randn(100)*0.5

# 好的模型
y_pred_good = 2*X + 3
residuals_good = y_true - y_pred_good

# 差的模型（欠拟合）
y_pred_bad = 1.5*X + 2
residuals_bad = y_true - y_pred_bad

fig, axes = plt.subplots(2, 2, figsize=(14, 10))

# 好的模型：拟合图
axes[0, 0].scatter(X, y_true, alpha=0.5, label='真实数据')
axes[0, 0].plot(X, y_pred_good, 'r-', linewidth=2, label='拟合线')
axes[0, 0].set_xlabel('特征 X')
axes[0, 0].set_ylabel('目标 y')
axes[0, 0].set_title('好的模型：拟合图')
axes[0, 0].legend()
axes[0, 0].grid(True, alpha=0.3)

# 好的模型：残差图
axes[0, 1].scatter(y_pred_good, residuals_good, alpha=0.5)
axes[0, 1].axhline(y=0, color='red', linestyle='--', linewidth=2)
axes[0, 1].set_xlabel('预测值')
axes[0, 1].set_ylabel('残差')
axes[0, 1].set_title('好的模型：残差随机分布 ✓')
axes[0, 1].grid(True, alpha=0.3)

# 差的模型：拟合图
axes[1, 0].scatter(X, y_true, alpha=0.5, label='真实数据')
axes[1, 0].plot(X, y_pred_bad, 'r-', linewidth=2, label='拟合线（欠拟合）')
axes[1, 0].set_xlabel('特征 X')
axes[1, 0].set_ylabel('目标 y')
axes[1, 0].set_title('差的模型：拟合图')
axes[1, 0].legend()
axes[1, 0].grid(True, alpha=0.3)

# 差的模型：残差图
axes[1, 1].scatter(y_pred_bad, residuals_bad, alpha=0.5, color='orange')
axes[1, 1].axhline(y=0, color='red', linestyle='--', linewidth=2)
axes[1, 1].set_xlabel('预测值')
axes[1, 1].set_ylabel('残差')
axes[1, 1].set_title('差的模型：残差有趋势 ✗')
axes[1, 1].grid(True, alpha=0.3)

plt.tight_layout()
plt.show()
```

**判断标准**：

- ✓ **好的残差图**：点随机分布在 y=0 附近，无明显趋势
- ✗ **差的残差图**：有漏斗形、U 形、趋势线等规律

---

### MAE（平均绝对误差）

#### 定义

$$
\text{MAE} = \frac{1}{n}\sum_{i=1}^{n}|y_i - \hat{y}_i|
$$

**直观理解**：所有预测误差的绝对值的平均

---

#### MAE 的优缺点

**优点**：

- 🎯 直观：单位与原数据相同
- 🛡️ 稳健：对异常值不敏感
- 📊 易解释：适合向业务人员汇报

**缺点**：

- 😐 不区分大小误差：误差 10 和误差 100 被同等对待

**适用场景**：

- 关注平均误差水平
- 对所有误差一视同仁
- 例子：房价预测、销量预测

---

### RMSE（均方根误差）

#### 定义

$$
\text{RMSE} = \sqrt{\frac{1}{n}\sum_{i=1}^{n}(y_i - \hat{y}_i)^2}
$$

**步骤**：

1. 计算残差的平方
2. 求平均
3. 开根号

---

#### MAE vs RMSE 对比

```{python}
# 对比两个场景
# 场景1：误差均匀分布
errors_uniform = np.array([5, 5, 5, 5, 5])

# 场景2：存在一个大误差
errors_outlier = np.array([1, 1, 1, 1, 21])

mae_uniform = np.mean(np.abs(errors_uniform))
rmse_uniform = np.sqrt(np.mean(errors_uniform**2))

mae_outlier = np.mean(np.abs(errors_outlier))
rmse_outlier = np.sqrt(np.mean(errors_outlier**2))

comparison_data = pd.DataFrame({
    '场景': ['均匀误差', '存在大误差'],
    '误差分布': ['[5,5,5,5,5]', '[1,1,1,1,21]'],
    'MAE': [mae_uniform, mae_outlier],
    'RMSE': [rmse_uniform, rmse_outlier],
    'RMSE/MAE': [rmse_uniform/mae_uniform, rmse_outlier/mae_outlier]
})

print(comparison_data.to_string(index=False))
```

**观察**：

- 场景 1（均匀误差）：RMSE ≈ MAE
- 场景 2（有大误差）：RMSE >> MAE（RMSE 对大误差更敏感）

---

#### MAE vs RMSE 总结

| 指标 | 计算 | 优点 | 缺点 | 何时使用 |
|------|------|------|------|---------|
| **MAE** | 绝对值平均 | 直观<br/>稳健 | 不区分大小误差 | 关注平均误差<br/>垃圾邮件分类 |
| **RMSE** | 平方平均开根 | 惩罚大误差<br/>常用 | 对异常值敏感 | 大误差代价高<br/>医疗诊断<br/>金融风控 |

**选择建议**：

- 不确定 → **两个都算**
- 业务对大误差敏感 → RMSE
- 只关心平均水平 → MAE

---

### R² 决定系数

#### 定义

$$
R^2 = 1 - \frac{SS_{res}}{SS_{tot}} = 1 - \frac{\sum(y_i - \hat{y}_i)^2}{\sum(y_i - \bar{y})^2}
$$

**直观理解**：模型解释了多少变异

- $SS_{res}$：残差平方和（模型的误差）
- $SS_{tot}$：总平方和（数据的总变异）

---

#### R² 的含义

**取值范围**：

- R² = 1：完美预测
- R² = 0.8：模型解释了 80% 的变异
- R² = 0：模型等同于预测平均值
- R² < 0：模型比预测平均值还差（很糟糕）

```{python}
# 可视化 R² 的含义
np.random.seed(42)
X_demo = np.linspace(0, 10, 50).reshape(-1, 1)
y_demo = 2*X_demo.flatten() + 3 + np.random.randn(50)*2

from sklearn.linear_model import LinearRegression

model_demo = LinearRegression()
model_demo.fit(X_demo, y_demo)
y_pred_demo = model_demo.predict(X_demo)
y_mean = np.mean(y_demo)

# 计算 R²
r2 = model_demo.score(X_demo, y_demo)

plt.figure(figsize=(12, 5))

plt.subplot(1, 2, 1)
plt.scatter(X_demo, y_demo, alpha=0.6, label='真实数据')
plt.plot(X_demo, y_pred_demo, 'r-', linewidth=2, label='模型预测')
plt.axhline(y=y_mean, color='green', linestyle='--', linewidth=2, label=f'平均值 = {y_mean:.1f}')
plt.xlabel('X')
plt.ylabel('y')
plt.title(f'模型拟合 (R² = {r2:.3f})')
plt.legend()
plt.grid(True, alpha=0.3)

# 残差对比
plt.subplot(1, 2, 2)
residuals_model = y_demo - y_pred_demo
residuals_mean = y_demo - y_mean

x_pos = np.arange(len(residuals_model))
width = 0.35
plt.bar(x_pos - width/2, np.abs(residuals_mean), width, label='预测平均值的误差', alpha=0.6)
plt.bar(x_pos + width/2, np.abs(residuals_model), width, label='模型的误差', alpha=0.6)
plt.xlabel('样本序号')
plt.ylabel('|残差|')
plt.title('模型 vs 基线（预测平均值）')
plt.legend()
plt.grid(True, alpha=0.3)

plt.tight_layout()
plt.show()
```

---

## 第三部分：数据可视化

---

### 为什么需要可视化？

#### Anscombe's Quartet（安斯库姆四重奏）

**四组数据，统计量完全相同**：

- 均值、方差、相关系数、回归线都一样
- 但数据分布完全不同！

```{python}
# Anscombe's Quartet
datasets = {
    'I': {'x': [10, 8, 13, 9, 11, 14, 6, 4, 12, 7, 5],
          'y': [8.04, 6.95, 7.58, 8.81, 8.33, 9.96, 7.24, 4.26, 10.84, 4.82, 5.68]},
    'II': {'x': [10, 8, 13, 9, 11, 14, 6, 4, 12, 7, 5],
           'y': [9.14, 8.14, 8.74, 8.77, 9.26, 8.10, 6.13, 3.10, 9.13, 7.26, 4.74]},
    'III': {'x': [10, 8, 13, 9, 11, 14, 6, 4, 12, 7, 5],
            'y': [7.46, 6.77, 12.74, 7.11, 7.81, 8.84, 6.08, 5.39, 8.15, 6.42, 5.73]},
    'IV': {'x': [8, 8, 8, 8, 8, 8, 8, 19, 8, 8, 8],
           'y': [6.58, 5.76, 7.71, 8.84, 8.47, 7.04, 5.25, 12.50, 5.56, 7.91, 6.89]}
}

fig, axes = plt.subplots(2, 2, figsize=(12, 10))
axes = axes.flatten()

for idx, (name, data) in enumerate(datasets.items()):
    x = np.array(data['x'])
    y = np.array(data['y'])
    
    # 回归线
    from scipy import stats
    slope, intercept, r_value, p_value, std_err = stats.linregress(x, y)
    line = slope * x + intercept
    
    axes[idx].scatter(x, y, s=100, alpha=0.6)
    axes[idx].plot(x, line, 'r-', linewidth=2)
    axes[idx].set_xlabel('X')
    axes[idx].set_ylabel('Y')
    axes[idx].set_title(f'数据集 {name}\n均值X={np.mean(x):.1f}, 均值Y={np.mean(y):.2f}, r={r_value:.3f}')
    axes[idx].grid(True, alpha=0.3)
    axes[idx].set_xlim(0, 20)
    axes[idx].set_ylim(2, 14)

plt.tight_layout()
plt.show()
```

**教训**：**永远要可视化数据！数字不会说谎，但会隐藏真相。**

---

### 常用图表类型

#### 散点图（Scatter Plot）

**用途**：观察两个变量的关系

```{python}
# 生成示例数据
np.random.seed(42)
area_demo = np.random.uniform(50, 200, 100)
price_demo = 2*area_demo + np.random.randn(100)*30 + 50

plt.figure(figsize=(10, 6))
plt.scatter(area_demo, price_demo, alpha=0.6, s=50)
plt.xlabel('面积 (平米)', fontsize=12)
plt.ylabel('价格 (万元)', fontsize=12)
plt.title('散点图示例：房屋面积 vs 价格', fontsize=14)
plt.grid(True, alpha=0.3)

# 添加趋势线
z = np.polyfit(area_demo, price_demo, 1)
p = np.poly1d(z)
plt.plot(area_demo, p(area_demo), "r--", linewidth=2, alpha=0.8, label=f'趋势线: y={z[0]:.2f}x+{z[1]:.2f}')
plt.legend()
plt.show()
```

**能看出什么**：

- 正相关/负相关/无关系
- 线性/非线性
- 离群点

---

#### 直方图（Histogram）

**用途**：观察单个变量的分布

```{python}
fig, axes = plt.subplots(1, 3, figsize=(15, 5))

# 正态分布
data_normal = np.random.normal(100, 15, 1000)
axes[0].hist(data_normal, bins=30, edgecolor='black', alpha=0.7)
axes[0].set_xlabel('数值')
axes[0].set_ylabel('频数')
axes[0].set_title('正态分布（对称）')
axes[0].grid(True, alpha=0.3)

# 右偏分布
data_skewed = np.random.exponential(50, 1000)
axes[1].hist(data_skewed, bins=30, edgecolor='black', alpha=0.7, color='orange')
axes[1].set_xlabel('数值')
axes[1].set_ylabel('频数')
axes[1].set_title('右偏分布（收入、房价常见）')
axes[1].grid(True, alpha=0.3)

# 双峰分布
data_bimodal = np.concatenate([np.random.normal(50, 10, 500), np.random.normal(100, 10, 500)])
axes[2].hist(data_bimodal, bins=30, edgecolor='black', alpha=0.7, color='green')
axes[2].set_xlabel('数值')
axes[2].set_ylabel('频数')
axes[2].set_title('双峰分布（可能有两个群体）')
axes[2].grid(True, alpha=0.3)

plt.tight_layout()
plt.show()
```

---

#### 相关系数热力图（Heatmap）

**用途**：一次性看所有特征之间的相关性

```{python}
# 生成相关数据
np.random.seed(42)
n = 100
data_corr = pd.DataFrame({
    '面积': np.random.uniform(50, 200, n),
})
data_corr['卧室数'] = 0.7 * data_corr['面积'] / 30 + np.random.randn(n) * 0.5
data_corr['房龄'] = np.random.uniform(0, 50, n)
data_corr['价格'] = 2 * data_corr['面积'] + 20 * data_corr['卧室数'] - 1 * data_corr['房龄'] + np.random.randn(n) * 20

# 计算相关系数矩阵
corr_matrix = data_corr.corr()

plt.figure(figsize=(8, 6))
sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', center=0, 
            square=True, linewidths=1, cbar_kws={"shrink": 0.8},
            vmin=-1, vmax=1)
plt.title('特征相关系数热力图', fontsize=14)
plt.show()
```

**解读**：

- **红色（接近 +1）**：强正相关（面积↑价格↑）
- **蓝色（接近 -1）**：强负相关（房龄↑价格↓）
- **白色（接近 0）**：无线性关系

---

### 可视化陷阱

#### 陷阱 1：截断 Y 轴

```{python}
# 示例：夸大差异
categories = ['产品A', '产品B']
values = [100, 102]

fig, axes = plt.subplots(1, 2, figsize=(12, 5))

# 诚实的图
axes[0].bar(categories, values, color=['blue', 'orange'])
axes[0].set_ylabel('销量')
axes[0].set_title('诚实的图：差异很小')
axes[0].set_ylim(0, 120)
axes[0].grid(True, alpha=0.3, axis='y')

# 误导的图（截断Y轴）
axes[1].bar(categories, values, color=['blue', 'orange'])
axes[1].set_ylabel('销量')
axes[1].set_title('误导的图：看起来差距巨大！')
axes[1].set_ylim(99, 103)  # 截断 Y 轴
axes[1].grid(True, alpha=0.3, axis='y')

plt.tight_layout()
plt.show()
```

**教训**：始终检查 Y 轴起点是否为 0

---

#### 陷阱 2：忽略样本量

```{python}
# 示例：样本量差异
data_large = np.random.normal(100, 15, 1000)
data_small = np.random.normal(105, 15, 10)

fig, axes = plt.subplots(1, 2, figsize=(12, 5))

axes[0].hist(data_large, bins=30, alpha=0.7, label=f'样本量=1000\n均值={np.mean(data_large):.1f}')
axes[0].set_xlabel('数值')
axes[0].set_ylabel('频数')
axes[0].set_title('大样本：分布稳定')
axes[0].legend()
axes[0].grid(True, alpha=0.3)

axes[1].hist(data_small, bins=10, alpha=0.7, color='orange', label=f'样本量=10\n均值={np.mean(data_small):.1f}')
axes[1].set_xlabel('数值')
axes[1].set_ylabel('频数')
axes[1].set_title('小样本：分布不稳定')
axes[1].legend()
axes[1].grid(True, alpha=0.3)

plt.tight_layout()
plt.show()
```

**教训**：报告统计量时，务必说明样本量

---

## 第四部分：完整实战流程

---

### 完整流程概览

```{mermaid}
graph TD
    A[读取数据] --> B[探索性数据分析<br>EDA]
    B --> C[数据清洗]
    C --> D[特征工程<br>可选]
    D --> E[数据切分]
    E --> F[训练模型]
    F --> G[模型评估]
    G --> H[残差分析]
    H --> I{满意?}
    I -->|否| J[调整模型/特征]
    J --> F
    I -->|是| K[完成]
    
    style A fill:#e3f2fd
    style C fill:#fff9c4
    style F fill:#c8e6c9
    style G fill:#ffccbc
    style K fill:#4caf50,color:#fff
```

---

## 总结

---

### 本讲知识回顾

#### 数据预处理

- **缺失值**：删除 vs 填充
- **异常值**：IQR 方法、3σ 原则、业务判断
- **归一化**：Min-Max vs Z-score

#### 模型评估

- **残差**：模型诊断的核心
- **MAE**：平均绝对误差，直观稳健
- **RMSE**：均方根误差，惩罚大误差
- **R²**：解释变异的比例

#### 数据可视化

- 散点图、直方图、箱线图、热力图
- **永远先可视化，再建模！**

---

### 核心要点

1. **数据质量决定模型质量**  
   "Garbage In, Garbage Out" → 数据清洗是基础

2. **评估指标要多角度**  
   不要只看一个指标，MAE + RMSE + R² + 残差图

3. **可视化是必须的**  
   Anscombe's Quartet 的教训

4. **模型诊断很重要**  
   残差图能发现很多问题

---

## Q&A

**Q1：请简述 Min-Max 归一化和 Z-score 标准化各自的计算目标（或特点）。根据讲义，为什么树模型（如决策树、随机森林）通常不需要进行归一化处理？**

**A：**

* Min-Max 归一化：其目标是将数据线性缩放到一个固定的区间，通常是 [0, 1]。
* Z-score 标准化：其目标是将数据转换为均值为 0、标准差为 1 的分布。
* 树模型不需要的原因：树模型是基于“分裂点”来做决策的（例如“面积 > 80平米”），它关心的是特征的顺序和阈值，而不关心特征的绝对尺度。归一化不会改变特征值的相对顺序，因此对树模型的决策几乎没有影响。

---

**Q2：在处理缺失值时，为什么讲义强调第一步是“理解业务逻辑”？请结合课程中“R&D支出”的例子说明。**

**A：**
因为某些缺失值（`NaN`）可能并非真正的“数据丢失”，而是具有特定业务含义的“隐形缺失”。

* 例子：在“R&D支出”的例子中，一家“传统公司”的R&D支出显示为 `NaN`。
* 错误处理：如果盲目用均值或中位数填充，会错误地高估这家公司的研发投入。
* 正确处理：通过业务逻辑理解，这家公司很可能没有R&D部门，因此 `NaN` 的真实含义是 0。此时应将其填充为 0 才能准确反映业务现实。

---

**Q3：MAE (平均绝对误差) 和 RMSE (均方根误差) 都是评估回归模型的指标。请问 RMSE 的计算方式（平方-求均-开方）有何特点，这导致它对哪种类型的误差（大误差还是小误差）更敏感？**

**A：**
* 特点：RMSE 的计算涉及“平方”步骤（ $(y_i - \hat{y}_i)^2$ ）。
* 敏感性：这个“平方”操作会显著放大那些数值较大的误差。
* 结论：因此，RMSE 相比 MAE 对“大误差”（即预测错得离谱的异常点）更为敏感。如果业务上无法容忍大的预测失误（例如金融风控），RMSE 是一个很重要的参考指标。

---

**Q4：课程中的“安斯库姆四重奏”(Anscombe's Quartet) 案例告诉了我们一个关于数据分析的什么重要教训？**

**A：**
它告诉我们的教训是：“永远要可视化你的数据！”

这四组数据的均值、方差、相关系数、甚至回归线都完全相同，但它们的数据分布形态却截然不同。如果只看统计数字，我们会误以为它们是一样的数据；只有通过可视化（如散点图），才能发现真相和数据中隐藏的模式。

---

**Q5：某回归模型的 R² (决定系数) 值为 0.8 [cite: 83]。这句话的直观解释是什么？R² 是否有可能为负数？**

**A：**

* 解释：R² = 0.8 意味着，这个模型解释了数据中 80% 的变异性（或方差）。换句话说，相比于“盲猜”所有样本的平均值，这个模型能将预测的误差（用平方和衡量）减少 80%。
* 是否为负：有可能。R² 为负数意味着模型的预测表现比“直接预测平均值”这个最简单的基线还要差。这通常说明模型非常糟糕，或者数据完全不适合该模型。

---

**Q6：你在使用箱线图（Boxplot）进行异常值检测时，发现了一个明显偏离上界（Q3 + 1.5*IQR）的“异常值”。你的下一步处理流程是什么？**

**A：**

* 不应该立即删除。发现异常值只是第一步，关键是分析其产生的原因：

1.  分析原因：这个异常值是录入错误、测量错误，还是一个真实但极端的数据点？
2.  业务判断：
    * 如果是明确的错误：例如“面积-50”或“房龄999年”，这种数据应予以删除或修正（如果可能）。
    * 如果是真实极端值：例如“亿万富翁买豪宅”导致的极高房价，这个数据是真实有效的，应该保留。盲目删除会扭曲数据分布，使模型失去对高端市场的预测能力。
    * 如果不确定：可以尝试替换（例如用边界值替换），或者分别训练“包含”和“不包含”该异常值的模型，对比其对模型稳定性和评估指标的影响，再做决策。

---

**Q7：在对线性回归模型进行“残差分析”时，如果你发现残差图（横轴为预测值，纵轴为残差）中的点呈现出明显的“喇叭口”形状（即预测值越大，残差的波动范围越大），这揭示了模型可能存在什么问题？**

**A：**
这揭示了模型可能存在“异方差性”（Heteroscedasticity）。

* 含义：“异方差性”意味着模型的误差（残差）不是恒定的，而是随着预测值的变化而变化。
* 具体表现：在“喇叭口”形态中，当预测值（例如房价）较低时，模型预测得较准（误差小）；但当预测值较高时，模型的预测误差变得非常不稳定（时而偏高，时而偏低，波动范围大）。
* 影响：这违反了线性回归的基本假设之一（误差方差恒定），可能导致模型的参数估计和置信区间不准确。

---

**Q8：假设你在构建两个金融模型：**
1.  **模型A：预测银行网点的平均每日取款量，用于常规运营规划**。
2.  **模型B：预测高频交易中的极端风险敞口，用于触发熔断机制**。

**在评估时，模型A 和 模型B 应该分别更侧重 MAE 还是 RMSE？为什么？**

**A：**

* 模型A (平均取款量)：应该更侧重 MAE (平均绝对误差)。
    * 原因：运营规划关心的是“平均”误差水平。MAE 能够直观地反映模型平均预测偏差了多少金额，且它对少数几天的极端值（例如节假日）不那么敏感（即更稳健），适合评估模型的整体稳健性。
* 模型B (极端风险)：应该更侧重 RMSE (均方根误差)。
    * 原因：风险控制和熔断机制的核心就是识别和惩罚“大误差”。RMSE 因为计算时有平方项，会极大地惩罚那些预测偏差大的点，侧重 RMSE 能确保模型在“错得最离谱”的极端情况下表现得更好，这对于风控至关重要。

---

**Q9：在第一讲我们学到要先切分训练集/测试集。在第二讲我们学习了归一化。为什么“归一化”这个操作（例如 Z-score）必须在“切分数据”之后进行？如果顺序反了，会导致什么严重后果？**

**A：**
这是为了防止“数据泄露”（Data Leakage）。

* 后果：Z-score 归一化需要计算数据的均值($\mu$)和标准差($\sigma$)。如果先对所有数据（1000条）进行归一化，再切分为训练集（800条）和测试集（200条），那么在计算均值和标准差时，测试集的 200 条数据信息已经被用到了。
* 影响：这导致模型在训练阶段就已经“偷看”到了测试集的分布信息。这违反了“测试集必须是模型在训练过程中从未见过的数据”这一核心原则。这会导致模型在测试集上的评估结果过于乐观（分数虚高），而无法代表模型在未来真实新数据上的泛化能力。
* 正确做法：1. 先切分。 2. 只在训练集上计算 $\mu$ 和 $\sigma$。 3. 用这个（来自训练集的）$\mu$ 和 $\sigma$ 去归一化训练集，并用同一个 $\mu$ 和 $\sigma$ 去归一化测试集。