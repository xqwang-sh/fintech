{
  "hash": "dae185e6fa24c3b1db37d4454776b0a4",
  "result": {
    "engine": "jupyter",
    "markdown": "---\ntitle: 第四讲：分类问题、决策树与评估指标\n---\n\n\n\n## 开场：从预测数值到预测类别\n\n\n### 上周回顾\n\n**上两周学了什么？**\n\n- 数据预处理（缺失值、异常值、归一化）\n- 回归模型的评估指标（MAE、RMSE、R²）\n- 线性回归模型\n- 线性回归模型的正则化（Ridge、Lasso、Elastic Net）\n\n**核心任务**：**回归**（预测连续数值）\n\n**例子**：预测房价 250 万元\n\n\n### 本周的新挑战\n\n**新任务**：**分类**（预测离散类别）\n\n**例子**：\n\n- 这笔贷款会违约吗？（是/否）\n- 这封邮件是垃圾邮件吗？（是/否）\n- 这个肿瘤是良性还是恶性？（良性/恶性）\n- 泰坦尼克号上的乘客会存活吗？（存活/死亡）\n\n**关键区别**：输出不再是数字，而是**类别标签**\n\n\n### 本周学习目标\n\n#### 知识目标\n1. 理解分类与回归的本质区别\n2. 理解逻辑回归与 Sigmoid 函数\n3. 掌握决策树的基本原理\n4. 理解混淆矩阵（TP、FP、TN、FN）\n5. 掌握分类模型评估指标（准确率、精确率、召回率、F1、AUC）\n6. 理解 ROC 曲线的含义\n\n#### 技能目标\n1. 使用 sklearn 训练逻辑回归与决策树分类器\n2. 计算并可视化混淆矩阵\n3. 绘制 ROC 曲线并计算 AUC\n4. 处理类别型特征（编码）\n\n\n## 第一部分：分类 vs 回归\n\n\n### 核心区别\n\n\n\n\n```{mermaid}\ngraph LR\n    A[机器学习任务] --> B[监督学习]\n    B --> C[回归<br/>Regression]\n    B --> D[分类<br/>Classification]\n    \n    C --> C1[预测连续值]\n    C1 --> C2[例: 250.5万]\n    \n    D --> D1[预测离散类别]\n    D1 --> D2[例: 存活/死亡]\n    \n    style C fill:#c8e6c9\n    style D fill:#bbdefb\n```\n\n\n\n\n\n### 对比表格\n\n| 维度 | 回归 (Regression) | 分类 (Classification) |\n|------|------------------|---------------------|\n| **输出类型** | 连续数值 | 离散类别 |\n| **输出例子** | 250.5 万、3.14、-5.2 | 是/否、猫/狗/鸟 |\n| **典型应用** | 房价预测、温度预测、销量预测 | 垃圾邮件识别、疾病诊断、图像识别 |\n| **评估指标** | MAE、RMSE、R² | 准确率、精确率、召回率、AUC |\n| **可视化** | 拟合曲线、残差图 | 混淆矩阵、ROC 曲线 |\n| **常用模型** | 线性回归、回归树 | 逻辑回归、决策树、SVM |\n\n\n### 快速判断练习\n\n**判断以下问题是分类还是回归？**\n\n1. 预测明天的最高气温 → **回归**（连续值：25.5°C）\n2. 判断肿瘤是良性还是恶性 → **分类**（两个类别）\n3. 预测用户会花多少钱 → **回归**（连续值：$123.45）\n4. 识别手写数字 0-9 → **分类**（10 个类别）\n5. 预测股票明天的收盘价 → **回归**（连续值）\n6. 预测客户是否会流失 → **分类**（是/否）\n\n\n### 金融场景中的分类问题\n\n#### 信用风险评估\n\n- **问题**：这个贷款申请人会违约吗？\n- **类别**：违约 / 不违约\n- **特征**：收入、信用评分、负债率、工作年限\n\n#### 欺诈检测\n\n- **问题**：这笔交易是否欺诈？\n- **类别**：欺诈 / 正常\n- **特征**：交易金额、时间、地点、历史行为\n\n#### 客户流失预测\n\n- **问题**：客户下个月是否会流失？\n- **类别**：流失 / 留存\n- **特征**：使用频率、投诉次数、余额、会员等级\n\n\n## 第二部分：逻辑回归（Logistic Regression）\n\n\n### 名字的误区\n\n虽然名字里有**回归**，但它是一个**分类**算法！\n\n*   **线性回归**：预测连续值（房价、温度）\n*   **逻辑回归**：预测概率（属于某一类的可能性）\n\n\n### 为什么要用逻辑回归？\n\n**问题**：如果用线性回归做分类（0或1），输出可能是 1.5 或 -0.2，这代表什么？\n\n**解决**：我们需要把输出压缩到 **0 到 1 之间**，代表概率。\n\n**核心工具：Sigmoid 函数**\n\n$$\nP(y=1|x) = \\frac{1}{1 + e^{-z}}\n$$\n\n其中 $z = w \\cdot x + b$ （线性方程）\n\n::: {#de4585c8 .cell execution_count=2}\n``` {.python .cell-code}\nimport numpy as np\nimport matplotlib.pyplot as plt\n\ndef sigmoid(z):\n    return 1 / (1 + np.exp(-z))\n\nz = np.linspace(-10, 10, 100)\nphi_z = sigmoid(z)\n\nplt.figure(figsize=(8, 5))\nplt.plot(z, phi_z)\nplt.axvline(0.0, color='k')\nplt.ylim(-0.1, 1.1)\nplt.xlabel('z (线性输出)', fontsize=12)\nplt.ylabel('$\\phi (z)$ (概率)', fontsize=12)\nplt.title('Sigmoid 函数：将数值压缩到 (0, 1)', fontsize=14)\nplt.yticks([0.0, 0.5, 1.0])\nplt.grid(True, alpha=0.3)\nplt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![](w4_classification_decision_tree_files/figure-html/cell-3-output-1.png){width=663 height=454}\n:::\n:::\n\n\n**特点**：\n\n*   $z = 0$ 时，概率 = 0.5（决策边界）\n*   $z > 0$ 时，概率 > 0.5（预测为正类 1）\n*   $z < 0$ 时，概率 < 0.5（预测为负类 0）\n\n\n### 决策边界（Decision Boundary）\n\n逻辑回归试图找到一条直线（或平面）来分开两类数据。\n\n::: {#1db0c305 .cell execution_count=3}\n``` {.python .cell-code}\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.datasets import make_blobs\n\n# 生成模拟数据\nX, y = make_blobs(n_samples=100, centers=2, random_state=42, cluster_std=2.0)\n\n# 训练模型\nlr_model = LogisticRegression()\nlr_model.fit(X, y)\n\n# 可视化决策边界\nx_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1\ny_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1\nxx, yy = np.meshgrid(np.arange(x_min, x_max, 0.1),\n                     np.arange(y_min, y_max, 0.1))\n\nZ = lr_model.predict(np.c_[xx.ravel(), yy.ravel()])\nZ = Z.reshape(xx.shape)\n\nplt.figure(figsize=(8, 6))\nplt.contourf(xx, yy, Z, alpha=0.3, cmap='coolwarm')\nplt.scatter(X[:, 0], X[:, 1], c=y, cmap='coolwarm', edgecolors='k')\nplt.title('逻辑回归的线性决策边界', fontsize=14)\nplt.xlabel('特征 1')\nplt.ylabel('特征 2')\nplt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![](w4_classification_decision_tree_files/figure-html/cell-4-output-1.png){width=654 height=525}\n:::\n:::\n\n\n### 优缺点分析\n\n#### 优点 ✓\n\n*   **输出概率**：不仅告诉你“是/否”，还告诉你“可能性多大”（如 80% 违约概率）。\n*   **简单高效**：计算速度快，适合大规模数据。\n*   **可解释性**：权重 $w$ 直接反映特征的重要性（正权重促进正类，负权重抑制）。\n\n#### 缺点 ✗\n\n*   **线性边界**：只能处理线性可分的数据（除非做特征工程）。\n*   **依赖特征独立性**：假设特征之间相互独立（虽然现实中很难满足）。\n\n\n## 第三部分：决策树（Decision Tree）\n\n\n### 引入：人类如何做决策？\n\n**场景：银行如何决定是否发放贷款？**\n\n**传统规则（专家经验）**：\n\n```\nIF 收入 > 5000 AND 信用评分 > 700 THEN\n    批准贷款\nELSE IF 收入 > 8000 THEN\n    批准贷款\nELSE\n    拒绝贷款\n```\n\n**问题**：规则由人工制定，可能不准确\n\n**决策树**：**让机器从数据中自动学习这些规则！**\n\n\n### 决策树的结构\n\n\n\n\n```{mermaid}\ngraph TD\n    A[收入 > 5000?] -->|是| B[信用评分 > 700?]\n    A -->|否| C[拒绝贷款]\n    B -->|是| D[批准贷款]\n    B -->|否| E[拒绝贷款]\n    \n    style A fill:#fff9c4\n    style B fill:#fff9c4\n    style D fill:#c8e6c9,color:#000\n    style C fill:#ffccbc,color:#000\n    style E fill:#ffccbc,color:#000\n```\n\n\n\n\n**关键概念**：\n\n- **根节点**：第一个判断条件（收入 > 5000?）\n- **内部节点**：中间的判断条件（信用评分 > 700?）\n- **叶节点**：最终决策（批准/拒绝）\n- **分裂**：根据某个特征的某个值进行分组\n\n\n### 决策树如何学习？\n\n#### 核心思想\n\n**每次选择\"最能区分两类\"的特征进行分裂**\n\n**类比**：20 个问题猜动物游戏\n\n- 好问题：\"是哺乳动物吗？\" → 能区分很多动物\n- 差问题：\"是蓝色的吗？\" → 区分能力有限\n\n\n#### 示例数据\n\n| 收入 | 信用分 | 是否违约 |\n|------|--------|----------|\n| 3000 | 650 | 是 |\n| 6000 | 750 | 否 |\n| 4000 | 700 | 是 |\n| 7000 | 800 | 否 |\n| 5000 | 600 | 是 |\n| 8000 | 750 | 否 |\n\n**目标**：找到最好的分裂点\n\n\n#### 尝试分裂 1：收入 > 5000\n\n\n\n\n```{mermaid}\ngraph TD\n    A[收入 > 5000?] -->|是<br/>3个样本| B[全部不违约 ✓<br/>纯净]\n    A -->|否<br/>3个样本| C[全部违约 ✓<br/>纯净]\n    \n    style B fill:#c8e6c9\n    style C fill:#ffccbc\n```\n\n\n\n\n**结果**：**完美分类！** 纯度 100%\n\n\n#### 尝试分裂 2：信用分 > 700\n\n\n\n\n```{mermaid}\ngraph TD\n    A[信用分 > 700?] -->|是<br/>3个样本| B[2个不违约<br/>1个违约<br/>纯度67%]\n    A -->|否<br/>3个样本| C[2个违约<br/>1个不违约<br/>纯度67%]\n    \n    style B fill:#fff9c4\n    style C fill:#fff9c4\n```\n\n\n\n\n**结果**：分类不纯净，纯度 67%\n\n**选择**：收入 > 5000（纯度更高）\n\n\n### 决策树的优缺点\n\n#### 优点 ✓\n\n- **易于理解**：可视化，符合人类思维\n- **可解释性强**：能清楚看到决策路径\n- **不需要归一化**：对特征尺度不敏感\n- **能处理非线性**：不像线性回归只能拟合直线\n- **自动特征选择**：重要特征会靠近根节点\n\n#### 缺点 ✗\n\n- **容易过拟合**：树太深会记住训练数据\n- **不稳定**：数据稍微变化，树结构可能完全不同\n- **单棵树精度有限**：后续会学集成方法改进\n\n\n### 控制过拟合：关键参数\n\n| 参数 | 含义 | 效果 | 建议值 |\n|------|------|------|--------|\n| **max_depth** | 树的最大深度 | 越大越复杂 | 3-10 |\n| **min_samples_split** | 分裂所需最小样本数 | 越大越保守 | 2-20 |\n| **min_samples_leaf** | 叶节点最小样本数 | 越大越保守 | 1-10 |\n| **max_leaf_nodes** | 最大叶节点数 | 限制树大小 | 10-100 |\n\n**核心原则**：**限制树的复杂度，防止过拟合**\n\n\n## 第四部分：混淆矩阵\n\n\n### 为什么需要混淆矩阵？\n\n**场景**：违约预测\n\n- **模型 A**：所有人都预测为\"不违约\" → 准确率 99%（因为 99% 人真的不违约）\n- **问题**：完全没有检测出违约！\n\n**教训**：**准确率不够！需要更细致的评估**\n\n**混淆矩阵**：把所有预测结果分成 4 类\n\n\n### 混淆矩阵的定义\n\n**Titanic 例子**：预测乘客是否存活\n\n|  | **预测：存活** | **预测：死亡** |\n|--|--------------|--------------|\n| **真实：存活** | TP = 50 <br/> ✓ 预测对了 | FN = 10 <br/> ✗ 漏报 |\n| **真实：死亡** | FP = 5 <br/> ✗ 误报 | TN = 35 <br/> ✓ 预测对了 |\n\n\n### 四个概念详解\n\n#### TP（True Positive，真阳性）\n\n- **含义**：真实是正类，预测也是正类 ✓\n- **例子**：真的存活，预测存活（50 人）\n- **理解**：预测对了，皆大欢喜\n\n#### FN（False Negative，假阴性）\n\n- **含义**：真实是正类，预测是负类 ✗\n- **例子**：真的存活，预测死亡（10 人）\n- **理解**：**漏报**（本该检测出来，但漏掉了）\n\n\n#### FP（False Positive，假阳性）\n\n- **含义**：真实是负类，预测是正类 ✗\n- **例子**：真的死亡，预测存活（5 人）\n- **理解**：**误报**（本不该报警，但误报了）\n\n#### TN（True Negative，真阴性）\n\n- **含义**：真实是负类，预测也是负类 ✓\n- **例子**：真的死亡，预测死亡（35 人）\n- **理解**：预测对了，正确排除\n\n\n### 记忆方法\n\n\n\n\n```{mermaid}\ngraph TD\n    A[TP/FP/TN/FN] --> B[第一个字母<br/>True/False]\n    A --> C[第二个字母<br/>Positive/Negative]\n    \n    B --> D[预测是否正确]\n    C --> E[预测为哪一类]\n    \n    D --> F[True = 对<br/>False = 错]\n    E --> G[Positive = 正类<br/>Negative = 负类]\n    \n    style F fill:#c8e6c9\n    style G fill:#bbdefb\n```\n\n\n\n\n**口诀**：\n\n- **True/False**：预测对/错\n- **Positive/Negative**：预测为正/负类\n- **P 在前**：Predict Positive（预测为正类）\n\n\n## 第五部分：分类评估指标\n\n\n### 准确率（Accuracy）\n\n#### 定义\n\n$$\n\\text{Accuracy} = \\frac{TP + TN}{\\text{总样本数}} = \\frac{\\text{预测正确的}}{\\text{全部}}\n$$\n\n**例子**：$\\frac{57 + 38}{100} = 95\\%$\n\n\n#### 准确率的问题\n\n**场景：欺诈检测**\n\n- 总样本：10000 笔交易\n- 欺诈：100 笔（1%）\n- 正常：9900 笔（99%）\n\n**\"愚蠢\"模型**：\n\n- 策略：预测所有交易都是正常的\n- 准确率：$\\frac{9900}{10000} = 99\\%$\n- **问题**：完全没有抓到欺诈！\n\n**结论**：**在类别不平衡时，准确率会误导**\n\n\n### 精确率（Precision）\n\n#### 定义\n\n$$\n\\text{Precision} = \\frac{TP}{TP + FP} = \\frac{\\text{真正是正类}}{\\text{预测为正类}}\n$$\n\n**业务含义**：在所有\"预测为正类\"的样本中，真正是正类的比例\n\n**例子（垃圾邮件）**：\n\n- 预测为垃圾邮件的 100 封中，真的垃圾邮件有 90 封\n- Precision = 90/100 = 90%\n\n**关注点**：**误报代价高时**\n\n- 垃圾邮件过滤：不能误删重要邮件\n- 推荐系统：不能推荐用户不喜欢的\n\n\n### 召回率（Recall / TPR）\n\n#### 定义\n\n$$\n\\text{Recall} = \\frac{TP}{TP + FN} = \\frac{\\text{找出来的正类}}{\\text{真正的正类}}\n$$\n\n**业务含义**：在所有\"真正是正类\"的样本中，被正确找出的比例\n\n**例子（疾病诊断）**：\n\n- 真实病人 100 人，模型检测出 80 人\n- Recall = 80/100 = 80%\n\n**关注点**：**漏报代价高时**\n\n- 疾病诊断：不能漏掉病人\n- 欺诈检测：不能放过欺诈\n- 安检：不能漏掉危险品\n\n\n### Precision vs Recall\n\n::: {#4c7274db .cell execution_count=4}\n``` {.python .cell-code}\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nfrom sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n\n# 可视化 Precision vs Recall\nfig, axes = plt.subplots(1, 2, figsize=(14, 6))\n\n# 场景1：高 Precision，低 Recall\ny_true_1 = np.array([1]*50 + [0]*50)\ny_pred_1 = np.array([1]*10 + [0]*40 + [0]*50)  # 只预测10个正类，但都对\ncm_1 = confusion_matrix(y_true_1, y_pred_1)\nTN_1, FP_1, FN_1, TP_1 = cm_1.ravel()\nprecision_1 = TP_1 / (TP_1 + FP_1) if (TP_1 + FP_1) > 0 else 0\nrecall_1 = TP_1 / (TP_1 + FN_1)\n\ndisp_1 = ConfusionMatrixDisplay(confusion_matrix=cm_1, display_labels=['负', '正'])\ndisp_1.plot(cmap='Blues', ax=axes[0])\naxes[0].set_title(f'保守策略\\nPrecision={precision_1:.2f}, Recall={recall_1:.2f}\\n（宁可放过，不可错杀）', fontsize=12)\n\n# 场景2：低 Precision，高 Recall\ny_pred_2 = np.array([1]*80 + [0]*20)  # 预测80个正类，包含30个FP\ncm_2 = confusion_matrix(y_true_1, y_pred_2)\nTN_2, FP_2, FN_2, TP_2 = cm_2.ravel()\nprecision_2 = TP_2 / (TP_2 + FP_2)\nrecall_2 = TP_2 / (TP_2 + FN_2)\n\ndisp_2 = ConfusionMatrixDisplay(confusion_matrix=cm_2, display_labels=['负', '正'])\ndisp_2.plot(cmap='Oranges', ax=axes[1])\naxes[1].set_title(f'激进策略\\nPrecision={precision_2:.2f}, Recall={recall_2:.2f}\\n（宁可错杀，不可放过）', fontsize=12)\n\nplt.tight_layout()\nplt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![](w4_classification_decision_tree_files/figure-html/cell-5-output-1.png){width=1290 height=614}\n:::\n:::\n\n\n**Precision-Recall 权衡**：\n\n- 提高 Precision → 降低 Recall（更保守）\n- 提高 Recall → 降低 Precision（更激进）\n\n\n### F1 分数\n\n#### 定义\n\n$$\nF1 = 2 \\times \\frac{\\text{Precision} \\times \\text{Recall}}{\\text{Precision} + \\text{Recall}}\n$$\n\n**直观理解**：Precision 和 Recall 的**调和平均**\n\n**为什么用调和平均？**\n\n- 算术平均：$(0.9 + 0.1) / 2 = 0.5$\n- 调和平均：$2 \\times \\frac{0.9 \\times 0.1}{0.9 + 0.1} = 0.18$\n\n**调和平均惩罚极端值**：两个指标都高，F1 才高\n\n\n#### F1 的应用场景\n\n**何时使用 F1？**\n\n- Precision 和 Recall 都重要\n- 需要一个综合指标\n- 例子：欺诈检测、信息检索\n\n**示例计算**：\n\n- Precision = 0.9, Recall = 0.8\n- F1 = $2 \\times \\frac{0.9 \\times 0.8}{0.9 + 0.8} = 0.847$\n\n::: {#01561e76 .cell execution_count=5}\n``` {.python .cell-code}\n# F1 分数可视化\nprecisions = np.linspace(0.1, 1, 50)\nrecalls = np.linspace(0.1, 1, 50)\nP, R = np.meshgrid(precisions, recalls)\nF1 = 2 * (P * R) / (P + R)\n\nplt.figure(figsize=(10, 7))\ncontour = plt.contourf(P, R, F1, levels=20, cmap='RdYlGn')\nplt.colorbar(contour, label='F1 分数')\nplt.xlabel('Precision', fontsize=12)\nplt.ylabel('Recall', fontsize=12)\nplt.title('F1 分数热力图\\n（两个指标都高，F1 才高）', fontsize=14)\nplt.grid(True, alpha=0.3)\nplt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![](w4_classification_decision_tree_files/figure-html/cell-6-output-1.png){width=764 height=620}\n:::\n:::\n\n\n### 指标总结对比\n\n| 指标 | 公式 | 关注点 | 何时使用 | 例子 |\n|------|------|--------|---------|------|\n| **准确率** | (TP+TN)/总数 | 整体正确率 | 类别平衡 | 性别识别 |\n| **精确率** | TP/(TP+FP) | 误报 | 误报代价高 | 垃圾邮件 |\n| **召回率** | TP/(TP+FN) | 漏报 | 漏报代价高 | 疾病诊断 |\n| **F1** | 调和平均 | 综合 | 两者都重要 | 欺诈检测 |\n\n\n## 第六部分：ROC 曲线与 AUC\n\n\n### 分类阈值的影响\n\n**问题**：分类器输出的是**概率**，如何转成类别？\n\n**例子**：\n\n| 样本 | 预测概率 | 阈值=0.5 | 阈值=0.7 | 阈值=0.3 |\n|------|---------|---------|---------|---------|\n| A | 0.8 | 存活 | 存活 | 存活 |\n| B | 0.6 | 存活 | 死亡 | 存活 |\n| C | 0.4 | 死亡 | 死亡 | 存活 |\n| D | 0.2 | 死亡 | 死亡 | 死亡 |\n\n**观察**：阈值不同，分类结果不同\n\n\n### 阈值对指标的影响\n\n::: {#1660be5b .cell execution_count=6}\n``` {.python .cell-code}\n# 模拟阈值变化\nnp.random.seed(42)\ny_true_roc = np.array([1]*60 + [0]*40)\ny_score = np.concatenate([np.random.beta(8, 2, 60), np.random.beta(2, 5, 40)])\n\nfrom sklearn.metrics import precision_score, recall_score\n\nthresholds = [0.3, 0.5, 0.7, 0.9]\nresults = []\n\nfor thresh in thresholds:\n    y_pred_thresh = (y_score >= thresh).astype(int)\n    precision = precision_score(y_true_roc, y_pred_thresh)\n    recall = recall_score(y_true_roc, y_pred_thresh)\n    pred_positive = y_pred_thresh.sum()\n    results.append({\n        '阈值': thresh,\n        '预测正类数': pred_positive,\n        'Precision': precision,\n        'Recall': recall\n    })\n\ndf_thresh = pd.DataFrame(results)\nprint(df_thresh.to_string(index=False))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n 阈值  预测正类数  Precision   Recall\n0.3     74   0.810811 1.000000\n0.5     62   0.967742 1.000000\n0.7     51   0.980392 0.833333\n0.9     10   1.000000 0.166667\n```\n:::\n:::\n\n\n**规律**：\n\n- 阈值低 → 预测更多正类 → Recall 高，Precision 低\n- 阈值高 → 预测更少正类 → Precision 高,Recall 低\n\n\n### ROC 曲线\n\n#### 定义\n\n**ROC（Receiver Operating Characteristic）曲线**：\n\n- **横轴**：假正例率 FPR = FP / (FP + TN)\n- **纵轴**：真正例率 TPR = TP / (TP + FN) = Recall\n- **每个点**：一个阈值对应的 (FPR, TPR)\n\n\n#### ROC 曲线可视化\n\n::: {#2cfe411f .cell execution_count=7}\n``` {.python .cell-code}\nfrom sklearn.metrics import roc_curve, auc\n\nfpr, tpr, thresholds_roc = roc_curve(y_true_roc, y_score)\nroc_auc = auc(fpr, tpr)\n\nplt.figure(figsize=(10, 8))\nplt.plot(fpr, tpr, color='darkorange', lw=3, label=f'ROC 曲线 (AUC = {roc_auc:.3f})')\nplt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--', label='随机猜测 (AUC = 0.5)')\n\n# 标注几个关键点\nfor i, thresh in enumerate([0.3, 0.5, 0.7]):\n    idx = np.argmin(np.abs(thresholds_roc - thresh))\n    plt.scatter(fpr[idx], tpr[idx], s=100, zorder=5)\n    plt.annotate(f'阈值={thresh:.1f}', (fpr[idx], tpr[idx]), \n                textcoords=\"offset points\", xytext=(10,5), fontsize=10)\n\nplt.xlim([0.0, 1.0])\nplt.ylim([0.0, 1.05])\nplt.xlabel('假正例率 (FPR) = FP/(FP+TN)', fontsize=12)\nplt.ylabel('真正例率 (TPR) = Recall', fontsize=12)\nplt.title('ROC 曲线', fontsize=14)\nplt.legend(loc=\"lower right\", fontsize=12)\nplt.grid(alpha=0.3)\nplt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![](w4_classification_decision_tree_files/figure-html/cell-8-output-1.png){width=816 height=675}\n:::\n:::\n\n\n### 理解 ROC 曲线\n\n\n\n\n```{mermaid}\ngraph TD\n    A[左下角 0,0] --> B[随机猜测对角线]\n    B --> C[左上角 0,1]\n    \n    A --> D[从不预测正类<br/>TPR=0, FPR=0]\n    C --> E[完美分类器<br/>TPR=1, FPR=0]\n    B --> F[随机猜测<br/>TPR=FPR]\n    \n    style E fill:#4caf50,color:#fff\n    style D fill:#f44336,color:#fff\n    style F fill:#ff9800,color:#fff\n```\n\n\n\n\n**关键点**：\n\n- **左上角 (0, 1)**：完美分类器（TPR=1, FPR=0）\n- **对角线**：随机猜测（瞎蒙）\n- **曲线越靠近左上角越好**\n\n\n### AUC（Area Under Curve）\n\n#### 定义\n\n**AUC**：ROC 曲线下的面积\n\n**取值范围**：0.5 ~ 1.0\n\n\n#### AUC 的含义\n\n**直观解释**：\n\n随机选一个正样本和一个负样本，模型给正样本打分更高的概率\n\n**判断标准**：\n\n| AUC 范围 | 模型质量 | 说明 |\n|---------|---------|------|\n| < 0.7 | 差 | 接近随机猜测 |\n| 0.7 ~ 0.8 | 一般 | 可用但有改进空间 |\n| 0.8 ~ 0.9 | 好 | 较好的分类器 |\n| 0.9 ~ 1.0 | 很好 | 优秀（小心过拟合） |\n\n\n#### 为什么 AUC 重要？\n\n**优点**：\n\n1. **不受阈值影响**：综合评估所有阈值\n2. **不受类别不平衡影响**：比准确率更可靠\n3. **评估排序能力**：而非单点预测\n\n**缺点**：\n\n- 不够直观（不如准确率好理解）\n- 不能直接告诉你用哪个阈值\n\n**推荐**：\n\n- **类别平衡** → 准确率 + AUC\n- **类别不平衡** → **只看 AUC**（准确率会误导）\n\n\n## 总结\n\n\n### 本讲知识回顾\n\n#### 分类 vs 回归\n\n- **回归**：预测连续值（房价、温度）\n- **分类**：预测离散类别（存活/死亡、是/否）\n\n#### 逻辑回归\n\n- **原理**：使用 Sigmoid 函数将线性输出映射到 (0, 1) 概率\n- **决策边界**：概率 > 0.5 预测为正类\n- **优点**：输出概率、可解释\n- **缺点**：处理非线性能力弱\n\n\n#### 决策树\n\n- 结构：根节点、内部节点、叶节点\n- 原理：选择最能区分的特征分裂\n- 优点：易理解、可解释\n- 缺点：易过拟合\n\n\n#### 混淆矩阵与评估指标\n\n| 概念 | 含义 | 何时重要 |\n|------|------|---------|\n| **TP** | 真阳性：预测对了的正类 | 总是好 |\n| **FN** | 假阴性：漏报 | 疾病诊断 |\n| **FP** | 假阳性：误报 | 垃圾邮件 |\n| **TN** | 真阴性：预测对了的负类 | 总是好 |\n| **Precision** | 预测为正类中真正是正类的比例 | 误报代价高 |\n| **Recall** | 真正是正类中被找出的比例 | 漏报代价高 |\n| **F1** | Precision 和 Recall 的调和平均 | 综合评估 |\n\n\n#### ROC 与 AUC\n\n- **ROC 曲线**：不同阈值下的 TPR vs FPR\n- **AUC**：ROC 曲线下面积（0.5~1.0）\n- **优点**：不受阈值和类别不平衡影响\n- **推荐**：类别不平衡时必看 AUC\n\n\n### 核心要点\n\n1. **选对评估指标**  \n   类别平衡 → 准确率；类别不平衡 → AUC\n\n2. **理解业务需求**  \n   误报代价高 → Precision；漏报代价高 → Recall\n\n3. **可视化很重要**  \n   混淆矩阵 + ROC 曲线 比单看数字更直观\n\n4. **决策树易过拟合**  \n   控制 max_depth，下周学更强的模型\n\n\n## Q&A\n\n**Q1：请用一句话概括“分类”与“回归”的本质区别，并判断“预测客户信用评级（A/B/C/D）”属于哪一类？** \n\n**A：**\n\n* 本质区别：回归（Regression）预测的是连续数值（例如房价250.5万），而分类（Classification）预测的是离散类别（例如“存活”/“死亡”）。\n* 判断：“预测客户信用评级”属于分类问题，因为它是在预测有限的几个类别（A、B、C、D）。\n\n\n**Q2：什么是混淆矩阵？请写出 TP、FP、FN、TN 的中文含义。** \n\n**A：**\n混淆矩阵是用来详细评估分类模型性能的工具，它将预测结果分为四种情况：\n\n* TP (True Positive):真阳性（真实为正类，预测也为正类）\n* FN (False Negative):假阴性（真实为正类，预测为负类，即“漏报”）\n* FP (False Positive):假阳性（真实为负类，预测为正类，即“误报”）\n* TN (True Negative):真阴性（真实为负类，预测也为负类）\n\n\n**Q3：为什么“准确率” (Accuracy) 在类别不平衡（例如 99% 正常交易，1% 欺诈交易）的数据集上是一个具有误导性的指标？** \n\n**A：**\n因为在这种情况下，一个“愚蠢”的模型如果把所有样本都预测为占比高的那个类别（例如“正常交易”），它依然可以获得极高的准确率（例如 99%）。但这个模型是完全无用的，因为它一个欺诈样本都检测不出来。\n\n\n**Q4：什么是 AUC？ROC 曲线下面积（AUC）为 0.5 意味着什么？** \n\n**A：**\n* AUC：指的是 ROC 曲线（受试者工作特征曲线）下方的面积（Area Under Curve）。\n* AUC = 0.5：这意味着模型的表现和随机猜测（瞎蒙）一样。ROC 曲线表现为一条从(0,0)到(1,1)的对角线。\n\n\n**Q5：在什么业务场景下，我们应该优先关注“精确率” (Precision)？在什么场景下又该优先关注“召回率” (Recall)？请各举一例。** \n\n**A：**\n这取决于我们更害怕哪种错误（“误报”还是“漏报”）：\n1.  优先 Precision (精确率)：当“误报” (FP) 的代价很高时。\n    * 例子：垃圾邮件过滤。我们更害怕把一封重要邮件（例如 offer 或账单）错判为垃圾邮件（FP），相比之下，漏掉几封垃圾邮件（FN）的代价较低。\n2.  优先 Recall (召回率)：当“漏报” (FN) 的代价很高时。\n    * 例子：疾病诊断 或金融欺诈检测。我们更害怕把一个真正的病人漏诊为“健康”（FN），因为这可能危及生命。相比之下，把健康人误判为“疑似病人”（FP）让他再做一次检查，代价相对较低。\n\n\n**Q6：如果你的决策树模型表现出明显的“过拟合”（即训练集表现很好，测试集表现很差），你应该调整讲义中提到的哪些参数来限制模型的复杂度？** \n\n**A：**\n为了防止过拟合，我们应该限制树的复杂度。讲义中提到了几个关键参数：\n\n1.  `max_depth` (最大深度)：减小这个值，让树变得更浅，防止它学得太细。\n2.  `min_samples_split` (分裂所需最小样本数)：增大这个值，要求一个节点必须有足够多的样本才能继续分裂。\n3.  `min_samples_leaf` (叶节点最小样本数)：增大这个值，确保每个叶节点（最终决策）都代表了足够多的样本。\n\n\n**Q7：为什么 F1 分数要使用 Precision 和 Recall 的“调和平均数”，而不是简单的“算术平均数”（即 (P+R)/2）？** \n\n**A：**\n因为调和平均数会更严厉地惩罚极端情况。\n\n* 例子：假设 Precision = 0.9，Recall = 0.1。\n    * 算术平均 = (0.9 + 0.1) / 2 = 0.5（看起来还不错）\n    * 调和平均 (F1) = $2 \\times \\frac{0.9 \\times 0.1}{0.9 + 0.1} = 0.18$（非常低）\n* 结论：F1 分数的目标是确保 Precision 和 Recall 两者都必须比较高时，F1 分数才会高。如果其中任何一个指标很低，F1 分数都会被拉得很低，这更符合我们对一个“好模型”的综合评估要求。\n\n\n**Q8：分类器输出的“概率阈值”（Threshold）是如何影响 Precision 和 Recall 的？如果我们把阈值从 0.5 提高到 0.8，Precision 和 Recall 会如何变化？** \n\n**A：**\n\n* 影响：阈值决定了模型预测的“激进”程度。\n* 提高阈值 (0.5 $\\rightarrow$ 0.8)：这意味着模型变得“保守”了，只有当它非常有把握（概率 > 0.8）时，才会把样本预测为正类。\n    * Precision (精确率) 会上升：因为被预测为“正类”的门槛高了，这些预测中“猜对”的比例（TP / (TP+FP)）会更高。\n    * Recall (召回率) 会下降：因为模型变得保守，它会漏掉很多“不太确定但确实是正类”的样本（FN 增加），导致“找全”的能力（TP / (TP+FN)）下降。\n* 这就是 Precision-Recall 权衡。\n\n\n**Q9：为什么不能直接用线性回归来处理分类问题（例如预测 0 和 1）？**\n\n**A：**\n\n1.  **输出范围问题**：线性回归的输出可以是任意实数（例如 100 或 -50），这对于表示概率（必须在 0 到 1 之间）没有意义。\n2.  **不稳定性**：线性回归对异常值非常敏感，异常值可能会严重偏移决策边界。\n3.  **逻辑回归的改进**：逻辑回归引入了 Sigmoid 函数，将任意实数压缩到 (0, 1) 区间，非常适合表示概率。\n\n",
    "supporting": [
      "w4_classification_decision_tree_files/figure-html"
    ],
    "filters": [],
    "includes": {}
  }
}