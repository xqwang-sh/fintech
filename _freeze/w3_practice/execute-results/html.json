{
  "hash": "07baea283ee4b501e95cf1dfc47d8fb5",
  "result": {
    "engine": "jupyter",
    "markdown": "---\ntitle: 第三讲上机实践\n---\n\n\n\n\n本上机讲义覆盖以下内容：\n\n- **Part 1**: 环境准备与数据加载\n- **Part 2**: 理解过拟合问题\n- **Part 3**: Ridge、Lasso、Elastic Net 实战\n- **Part 4**: 交叉验证与参数选择\n- **Part 5**: 正则化路径可视化\n\n**学习目标**\n\n✅ 掌握 Ridge、Lasso、Elastic Net 的使用\n✅ 理解正则化参数 α 的作用\n✅ 学会使用交叉验证选择最优参数\n✅ 理解 Lasso 的特征选择功能\n\n⚠️ **重要提醒**\n\n1. 正则化前必须标准化特征\n2. 不要在测试集上选择参数\n3. 多种方法对比，选择最适合的\n\n## 环境准备与数据加载\n\n首先导入必要的库，并加载 Boston 房价数据集。\n\n::: {#a3aa3826 .cell execution_count=1}\n``` {.python .cell-code}\n# 导入必要的库\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n# Boston housing 数据集已从 sklearn 中移除，我们从原始数据源获取\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet\nfrom sklearn.linear_model import RidgeCV, LassoCV, ElasticNetCV\nfrom sklearn.preprocessing import StandardScaler, PolynomialFeatures\nfrom sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n\n# 设置中文字体\nimport platform\nsystem = platform.system()\nif system == 'Windows':\n    plt.rcParams['font.sans-serif'] = ['SimHei']\nelif system == 'Darwin':\n    plt.rcParams['font.sans-serif'] = ['Songti SC']\nelse:\n    plt.rcParams['font.sans-serif'] = ['WenQuanYi Zen Hei']\nplt.rcParams['axes.unicode_minus'] = False\n\n# 设置随机种子\nnp.random.seed(42)\n\nprint(\"✓ 库导入成功！\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n✓ 库导入成功！\n```\n:::\n:::\n\n\n### 加载数据集\n\n::: {#344bcd39 .cell execution_count=2}\n``` {.python .cell-code}\n# 加载 Boston Housing 数据集\ndata_url = \"http://lib.stat.cmu.edu/datasets/boston\"\nraw_df = pd.read_csv(data_url, sep=\"\\s+\", skiprows=22, header=None)\ndata = np.hstack([raw_df.values[::2, :], raw_df.values[1::2, :2]])\ntarget = raw_df.values[1::2, 2]\n\nX = data\ny = target\n\n# 创建DataFrame\nfeature_names = ['CRIM', 'ZN', 'INDUS', 'CHAS', 'NOX', 'RM', 'AGE', 'DIS', 'RAD', 'TAX', 'PTRATIO', 'B', 'LSTAT']\ndf = pd.DataFrame(X, columns=feature_names)\ndf['Price'] = y\n\nprint(f\"数据形状: {X.shape}\")\nprint(f\"样本数: {X.shape[0]}, 特征数: {X.shape[1]}\")\nprint(f\"\\n特征名称: {feature_names}\")\nprint(f\"\\n目标变量: 房价中位数（单位：千美元）\")\nprint(f\"\\n前5行数据:\")\ndf.head()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n数据形状: (506, 13)\n样本数: 506, 特征数: 13\n\n特征名称: ['CRIM', 'ZN', 'INDUS', 'CHAS', 'NOX', 'RM', 'AGE', 'DIS', 'RAD', 'TAX', 'PTRATIO', 'B', 'LSTAT']\n\n目标变量: 房价中位数（单位：千美元）\n\n前5行数据:\n```\n:::\n\n::: {.cell-output .cell-output-display execution_count=2}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>CRIM</th>\n      <th>ZN</th>\n      <th>INDUS</th>\n      <th>CHAS</th>\n      <th>NOX</th>\n      <th>RM</th>\n      <th>AGE</th>\n      <th>DIS</th>\n      <th>RAD</th>\n      <th>TAX</th>\n      <th>PTRATIO</th>\n      <th>B</th>\n      <th>LSTAT</th>\n      <th>Price</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.00632</td>\n      <td>18.0</td>\n      <td>2.31</td>\n      <td>0.0</td>\n      <td>0.538</td>\n      <td>6.575</td>\n      <td>65.2</td>\n      <td>4.0900</td>\n      <td>1.0</td>\n      <td>296.0</td>\n      <td>15.3</td>\n      <td>396.90</td>\n      <td>4.98</td>\n      <td>24.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.02731</td>\n      <td>0.0</td>\n      <td>7.07</td>\n      <td>0.0</td>\n      <td>0.469</td>\n      <td>6.421</td>\n      <td>78.9</td>\n      <td>4.9671</td>\n      <td>2.0</td>\n      <td>242.0</td>\n      <td>17.8</td>\n      <td>396.90</td>\n      <td>9.14</td>\n      <td>21.6</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.02729</td>\n      <td>0.0</td>\n      <td>7.07</td>\n      <td>0.0</td>\n      <td>0.469</td>\n      <td>7.185</td>\n      <td>61.1</td>\n      <td>4.9671</td>\n      <td>2.0</td>\n      <td>242.0</td>\n      <td>17.8</td>\n      <td>392.83</td>\n      <td>4.03</td>\n      <td>34.7</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.03237</td>\n      <td>0.0</td>\n      <td>2.18</td>\n      <td>0.0</td>\n      <td>0.458</td>\n      <td>6.998</td>\n      <td>45.8</td>\n      <td>6.0622</td>\n      <td>3.0</td>\n      <td>222.0</td>\n      <td>18.7</td>\n      <td>394.63</td>\n      <td>2.94</td>\n      <td>33.4</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.06905</td>\n      <td>0.0</td>\n      <td>2.18</td>\n      <td>0.0</td>\n      <td>0.458</td>\n      <td>7.147</td>\n      <td>54.2</td>\n      <td>6.0622</td>\n      <td>3.0</td>\n      <td>222.0</td>\n      <td>18.7</td>\n      <td>396.90</td>\n      <td>5.33</td>\n      <td>36.2</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n```\n:::\n:::\n\n\n### 数据探索\n\n观察数据的基本统计信息和特征尺度。\n\n::: {#e4d10780 .cell execution_count=3}\n``` {.python .cell-code}\n# 基本统计信息\nprint(\"数据统计信息:\")\nprint(df.describe())\n\nprint(\"\\n\" + \"=\"*60)\nprint(\"⚠️ 关键观察：不同特征的尺度差异很大！\")\nprint(\"\\n这就是为什么正则化前需要标准化！\")\nprint(\"=\"*60)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n数据统计信息:\n             CRIM          ZN       INDUS        CHAS         NOX          RM  \\\ncount  506.000000  506.000000  506.000000  506.000000  506.000000  506.000000   \nmean     3.613524   11.363636   11.136779    0.069170    0.554695    6.284634   \nstd      8.601545   23.322453    6.860353    0.253994    0.115878    0.702617   \nmin      0.006320    0.000000    0.460000    0.000000    0.385000    3.561000   \n25%      0.082045    0.000000    5.190000    0.000000    0.449000    5.885500   \n50%      0.256510    0.000000    9.690000    0.000000    0.538000    6.208500   \n75%      3.677083   12.500000   18.100000    0.000000    0.624000    6.623500   \nmax     88.976200  100.000000   27.740000    1.000000    0.871000    8.780000   \n\n              AGE         DIS         RAD         TAX     PTRATIO           B  \\\ncount  506.000000  506.000000  506.000000  506.000000  506.000000  506.000000   \nmean    68.574901    3.795043    9.549407  408.237154   18.455534  356.674032   \nstd     28.148861    2.105710    8.707259  168.537116    2.164946   91.294864   \nmin      2.900000    1.129600    1.000000  187.000000   12.600000    0.320000   \n25%     45.025000    2.100175    4.000000  279.000000   17.400000  375.377500   \n50%     77.500000    3.207450    5.000000  330.000000   19.050000  391.440000   \n75%     94.075000    5.188425   24.000000  666.000000   20.200000  396.225000   \nmax    100.000000   12.126500   24.000000  711.000000   22.000000  396.900000   \n\n            LSTAT       Price  \ncount  506.000000  506.000000  \nmean    12.653063   22.532806  \nstd      7.141062    9.197104  \nmin      1.730000    5.000000  \n25%      6.950000   17.025000  \n50%     11.360000   21.200000  \n75%     16.955000   25.000000  \nmax     37.970000   50.000000  \n\n============================================================\n⚠️ 关键观察：不同特征的尺度差异很大！\n\n这就是为什么正则化前需要标准化！\n============================================================\n```\n:::\n:::\n\n\n### 数据切分与标准化\n\n**重要步骤**：\n1. 先切分训练集和测试集\n2. 在训练集上 fit StandardScaler\n3. 用训练集的参数 transform 训练集和测试集\n\n::: {#962dd048 .cell execution_count=4}\n``` {.python .cell-code}\n# 切分训练集和测试集\nX_train, X_test, y_train, y_test = train_test_split(\n    X, y, test_size=0.2, random_state=42\n)\n\nprint(f\"训练集大小: {X_train.shape}\")\nprint(f\"测试集大小: {X_test.shape}\")\n\n# 标准化（重要！）\nscaler = StandardScaler()\nX_train_scaled = scaler.fit_transform(X_train)  # 在训练集上 fit\nX_test_scaled = scaler.transform(X_test)  # 用训练集的参数 transform\n\n# 验证标准化效果\nprint(\"\\n标准化验证:\")\nprint(f\"训练集均值（应接近0）: {X_train_scaled.mean(axis=0).round(10)}\")\nprint(f\"训练集标准差（应接近1）: {X_train_scaled.std(axis=0).round(3)}\")\nprint(\"\\n✓ 标准化完成！\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n训练集大小: (404, 13)\n测试集大小: (102, 13)\n\n标准化验证:\n训练集均值（应接近0）: [-0.  0.  0. -0. -0. -0. -0. -0. -0. -0.  0.  0. -0.]\n训练集标准差（应接近1）: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n\n✓ 标准化完成！\n```\n:::\n:::\n\n\n## 理解过拟合问题\n\n用多项式回归演示过拟合现象。\n\n### 生成简单数据集\n\n::: {#4b551ab2 .cell execution_count=5}\n``` {.python .cell-code}\n# 生成简单的数据集：y = 2x + 1 + 噪声\nnp.random.seed(42)\nX_simple = np.linspace(0, 10, 20).reshape(-1, 1)\ny_simple = 2 * X_simple.flatten() + 1 + np.random.randn(20) * 3\n\n# 真实关系（无噪声）\nX_true = np.linspace(0, 10, 100).reshape(-1, 1)\ny_true = 2 * X_true.flatten() + 1\n\n# 绘制数据\nplt.figure(figsize=(10, 6))\nplt.scatter(X_simple, y_simple, s=80, alpha=0.6, label='训练数据（有噪声）')\nplt.plot(X_true, y_true, 'k--', linewidth=2, alpha=0.5, label='真实关系')\nplt.xlabel('X', fontsize=12)\nplt.ylabel('y', fontsize=12)\nplt.title('简单线性关系 + 噪声', fontsize=14)\nplt.legend(fontsize=11)\nplt.grid(True, alpha=0.3)\nplt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![](w3_practice_files/figure-html/cell-6-output-1.png){width=813 height=526}\n:::\n:::\n\n\n### 对比不同复杂度的模型\n\n尝试用不同次数的多项式拟合数据。\n\n::: {#8502b751 .cell execution_count=6}\n``` {.python .cell-code}\n# 训练不同次数的多项式回归\ndegrees = [1, 4, 15]\ntitles = ['欠拟合（1次）', '刚刚好（4次）', '过拟合（15次）']\n\nfig, axes = plt.subplots(1, 3, figsize=(15, 5))\n\nfor idx, (degree, title) in enumerate(zip(degrees, titles)):\n    # 生成多项式特征\n    poly = PolynomialFeatures(degree=degree)\n    X_poly = poly.fit_transform(X_simple)\n    X_true_poly = poly.transform(X_true)\n\n    # 训练模型\n    model = LinearRegression()\n    model.fit(X_poly, y_simple)\n    y_pred = model.predict(X_true_poly)\n\n    # 计算误差\n    train_mse = mean_squared_error(y_simple, model.predict(X_poly))\n    test_mse = mean_squared_error(y_true, y_pred)\n\n    # 绘图\n    axes[idx].scatter(X_simple, y_simple, s=80, alpha=0.6, label='训练数据', zorder=3)\n    axes[idx].plot(X_true, y_true, 'k--', linewidth=2, alpha=0.3, label='真实关系')\n    axes[idx].plot(X_true, y_pred, linewidth=2.5, label='拟合曲线')\n    axes[idx].set_xlabel('X', fontsize=11)\n    axes[idx].set_ylabel('y', fontsize=11)\n    axes[idx].set_title(f'{title}\\n训练MSE={train_mse:.1f}, 测试MSE={test_mse:.1f}', fontsize=12)\n    axes[idx].legend(fontsize=9)\n    axes[idx].grid(True, alpha=0.3)\n    axes[idx].set_ylim(-5, 25)\n\nplt.tight_layout()\nplt.show()\n\nprint(\"\\n观察：\")\nprint(\"- 1次多项式：训练误差大，测试误差大 → 欠拟合\")\nprint(\"- 4次多项式：训练误差小，测试误差小 → 刚刚好\")\nprint(\"- 15次多项式：训练误差很小，测试误差大 → 过拟合\")\n```\n\n::: {.cell-output .cell-output-display}\n![](w3_practice_files/figure-html/cell-7-output-1.png){width=1430 height=471}\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n\n观察：\n- 1次多项式：训练误差大，测试误差大 → 欠拟合\n- 4次多项式：训练误差小，测试误差小 → 刚刚好\n- 15次多项式：训练误差很小，测试误差大 → 过拟合\n```\n:::\n:::\n\n\n## Ridge、Lasso、Elastic Net 实战\n\n在 Boston 房价数据上对比四种模型。\n\n### 基线模型：普通线性回归\n\n::: {#79a39397 .cell execution_count=7}\n``` {.python .cell-code}\n# 训练普通线性回归\nlr = LinearRegression()\nlr.fit(X_train_scaled, y_train)\n\n# 预测\ny_train_pred_lr = lr.predict(X_train_scaled)\ny_test_pred_lr = lr.predict(X_test_scaled)\n\n# 评估\ntrain_rmse_lr = np.sqrt(mean_squared_error(y_train, y_train_pred_lr))\ntest_rmse_lr = np.sqrt(mean_squared_error(y_test, y_test_pred_lr))\ntrain_r2_lr = r2_score(y_train, y_train_pred_lr)\ntest_r2_lr = r2_score(y_test, y_test_pred_lr)\n\nprint(\"=\"*50)\nprint(\"普通线性回归（基线模型）\")\nprint(\"=\"*50)\nprint(f\"训练集 RMSE: {train_rmse_lr:.4f}\")\nprint(f\"测试集 RMSE: {test_rmse_lr:.4f}\")\nprint(f\"训练集 R²:   {train_r2_lr:.4f}\")\nprint(f\"测试集 R²:   {test_r2_lr:.4f}\")\nprint(f\"\\n系数L2范数:  {np.linalg.norm(lr.coef_):.4f}\")\nprint(f\"非零系数数:  {np.sum(lr.coef_ != 0)}/{len(lr.coef_)}\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n==================================================\n普通线性回归（基线模型）\n==================================================\n训练集 RMSE: 4.6520\n测试集 RMSE: 4.9286\n训练集 R²:   0.7509\n测试集 R²:   0.6688\n\n系数L2范数:  7.2290\n非零系数数:  13/13\n```\n:::\n:::\n\n\n### Ridge 回归（L2 正则化）\n\n惩罚系数的平方和，让系数变小但不为0。\n\n::: {#4a0b6634 .cell execution_count=8}\n``` {.python .cell-code}\n# 训练 Ridge 回归\nridge = Ridge(alpha=1.0)  # alpha 越大，正则化越强\nridge.fit(X_train_scaled, y_train)\n\n# 预测与评估\ny_train_pred_ridge = ridge.predict(X_train_scaled)\ny_test_pred_ridge = ridge.predict(X_test_scaled)\n\ntrain_rmse_ridge = np.sqrt(mean_squared_error(y_train, y_train_pred_ridge))\ntest_rmse_ridge = np.sqrt(mean_squared_error(y_test, y_test_pred_ridge))\ntrain_r2_ridge = r2_score(y_train, y_train_pred_ridge)\ntest_r2_ridge = r2_score(y_test, y_test_pred_ridge)\n\nprint(\"=\"*50)\nprint(\"Ridge 回归 (α=1.0)\")\nprint(\"=\"*50)\nprint(f\"训练集 RMSE: {train_rmse_ridge:.4f}\")\nprint(f\"测试集 RMSE: {test_rmse_ridge:.4f}\")\nprint(f\"训练集 R²:   {train_r2_ridge:.4f}\")\nprint(f\"测试集 R²:   {test_r2_ridge:.4f}\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n==================================================\nRidge 回归 (α=1.0)\n==================================================\n训练集 RMSE: 4.6522\n测试集 RMSE: 4.9308\n训练集 R²:   0.7509\n测试集 R²:   0.6685\n```\n:::\n:::\n\n\n### Lasso 回归（L1 正则化）\n\n惩罚系数的绝对值和，让某些系数变为0。\n\n::: {#926f76bb .cell execution_count=9}\n``` {.python .cell-code}\n# 训练 Lasso 回归\nlasso = Lasso(alpha=0.01, max_iter=10000)  # alpha 越大，正则化越强\nlasso.fit(X_train_scaled, y_train)\n\n# 预测与评估\ny_train_pred_lasso = lasso.predict(X_train_scaled)\ny_test_pred_lasso = lasso.predict(X_test_scaled)\n\ntrain_rmse_lasso = np.sqrt(mean_squared_error(y_train, y_train_pred_lasso))\ntest_rmse_lasso = np.sqrt(mean_squared_error(y_test, y_test_pred_lasso))\ntrain_r2_lasso = r2_score(y_train, y_train_pred_lasso)\ntest_r2_lasso = r2_score(y_test, y_test_pred_lasso)\n\nprint(\"=\"*50)\nprint(\"Lasso 回归 (α=0.01)\")\nprint(\"=\"*50)\nprint(f\"训练集 RMSE: {train_rmse_lasso:.4f}\")\nprint(f\"测试集 RMSE: {test_rmse_lasso:.4f}\")\nprint(f\"训练集 R²:   {train_r2_lasso:.4f}\")\nprint(f\"测试集 R²:   {test_r2_lasso:.4f}\")\nprint(f\"\\n保留特征数: {np.sum(lasso.coef_ != 0)}/{len(lasso.coef_)}\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n==================================================\nLasso 回归 (α=0.01)\n==================================================\n训练集 RMSE: 4.6528\n测试集 RMSE: 4.9329\n训练集 R²:   0.7508\n测试集 R²:   0.6682\n\n保留特征数: 13/13\n```\n:::\n:::\n\n\n### Elastic Net 回归（L1+L2 正则化）\n\n结合 Ridge 和 Lasso 的优点。\n\n::: {#d700562c .cell execution_count=10}\n``` {.python .cell-code}\n# 训练 Elastic Net 回归\nelastic = ElasticNet(alpha=0.01, l1_ratio=0.5, max_iter=10000)\n# l1_ratio=0.5 表示 L1 和 L2 正则化各占 50%\nelastic.fit(X_train_scaled, y_train)\n\n# 预测与评估\ny_train_pred_elastic = elastic.predict(X_train_scaled)\ny_test_pred_elastic = elastic.predict(X_test_scaled)\n\ntrain_rmse_elastic = np.sqrt(mean_squared_error(y_train, y_train_pred_elastic))\ntest_rmse_elastic = np.sqrt(mean_squared_error(y_test, y_test_pred_elastic))\ntrain_r2_elastic = r2_score(y_train, y_train_pred_elastic)\ntest_r2_elastic = r2_score(y_test, y_test_pred_elastic)\n\nprint(\"=\"*50)\nprint(\"Elastic Net 回归 (α=0.01, l1_ratio=0.5)\")\nprint(\"=\"*50)\nprint(f\"训练集 RMSE: {train_rmse_elastic:.4f}\")\nprint(f\"测试集 RMSE: {test_rmse_elastic:.4f}\")\nprint(f\"训练集 R²:   {train_r2_elastic:.4f}\")\nprint(f\"测试集 R²:   {test_r2_elastic:.4f}\")\nprint(f\"\\n保留特征数: {np.sum(elastic.coef_ != 0)}/{len(elastic.coef_)}\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n==================================================\nElastic Net 回归 (α=0.01, l1_ratio=0.5)\n==================================================\n训练集 RMSE: 4.6533\n测试集 RMSE: 4.9353\n训练集 R²:   0.7507\n测试集 R²:   0.6679\n\n保留特征数: 13/13\n```\n:::\n:::\n\n\n### 模型对比总结\n\n::: {#994b831d .cell execution_count=11}\n``` {.python .cell-code}\n# 创建对比表格\nresults = pd.DataFrame({\n    '模型': ['普通回归', 'Ridge (α=1.0)', 'Lasso (α=0.01)', 'Elastic Net (α=0.01)'],\n    '训练R²': [train_r2_lr, train_r2_ridge, train_r2_lasso, train_r2_elastic],\n    '测试R²': [test_r2_lr, test_r2_ridge, test_r2_lasso, test_r2_elastic],\n    '系数L2范数': [\n        np.linalg.norm(lr.coef_),\n        np.linalg.norm(ridge.coef_),\n        np.linalg.norm(lasso.coef_),\n        np.linalg.norm(elastic.coef_)\n    ],\n    '非零系数': [\n        len(lr.coef_),\n        len(ridge.coef_),\n        np.sum(lasso.coef_ != 0),\n        np.sum(elastic.coef_ != 0)\n    ]\n})\n\nprint(\"=\"*70)\nprint(\"四种模型对比\")\nprint(\"=\"*70)\nprint(results.to_string(index=False, float_format='%.4f'))\n\n# 找出最佳模型\nbest_idx = results['测试R²'].idxmax()\nprint(f\"\\n✓ 测试集表现最好: {results.loc[best_idx, '模型']}\")\nprint(f\"  测试R² = {results.loc[best_idx, '测试R²']:.4f}\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n======================================================================\n四种模型对比\n======================================================================\n                  模型   训练R²   测试R²  系数L2范数  非零系数\n                普通回归 0.7509 0.6688  7.2290    13\n       Ridge (α=1.0) 0.7509 0.6685  7.1528    13\n      Lasso (α=0.01) 0.7508 0.6682  7.0675    13\nElastic Net (α=0.01) 0.7507 0.6679  7.0060    13\n\n✓ 测试集表现最好: 普通回归\n  测试R² = 0.6688\n```\n:::\n:::\n\n\n### 可视化系数对比\n\n::: {#e2006363 .cell execution_count=12}\n``` {.python .cell-code}\n# 绘制系数对比图\nfig, axes = plt.subplots(2, 2, figsize=(14, 10))\naxes = axes.flatten()\n\nmodels_list = [\n    ('普通线性回归', lr.coef_),\n    ('Ridge (α=1.0)', ridge.coef_),\n    ('Lasso (α=0.01)', lasso.coef_),\n    ('Elastic Net', elastic.coef_)\n]\n\nfor idx, (name, coef) in enumerate(models_list):\n    colors = ['green' if c > 0 else 'red' for c in coef]\n    axes[idx].barh(feature_names, coef, color=colors, alpha=0.7)\n    axes[idx].set_xlabel('系数值', fontsize=11)\n    axes[idx].set_title(f'{name}\\n非零系数: {np.sum(coef != 0)}个', fontsize=12, weight='bold')\n    axes[idx].axvline(x=0, color='black', linestyle='-', linewidth=1)\n    axes[idx].grid(True, alpha=0.3, axis='x')\n\nplt.tight_layout()\nplt.show()\n\nprint(\"\\n观察：\")\nprint(\"- 普通回归：所有系数都非零\")\nprint(\"- Ridge：系数变小，但都保留\")\nprint(\"- Lasso：某些系数变为0（特征选择）\")\nprint(\"- Elastic Net：介于 Ridge 和 Lasso 之间\")\n```\n\n::: {.cell-output .cell-output-display}\n![](w3_practice_files/figure-html/cell-13-output-1.png){width=1334 height=951}\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n\n观察：\n- 普通回归：所有系数都非零\n- Ridge：系数变小，但都保留\n- Lasso：某些系数变为0（特征选择）\n- Elastic Net：介于 Ridge 和 Lasso 之间\n```\n:::\n:::\n\n\n## 交叉验证与参数选择\n\n使用交叉验证自动选择最优的正则化参数 α。\n\n### RidgeCV：自动选择最优 α\n\n::: {#a41b8ea0 .cell execution_count=13}\n``` {.python .cell-code}\n# 准备候选的 alpha 值\nalphas_cv = np.logspace(-3, 3, 50)  # 从 0.001 到 1000，50个值\n\n# RidgeCV：5折交叉验证\nridge_cv = RidgeCV(alphas=alphas_cv, cv=5)\nridge_cv.fit(X_train_scaled, y_train)\n\nprint(\"=\"*50)\nprint(\"RidgeCV 结果（5折交叉验证）\")\nprint(\"=\"*50)\nprint(f\"候选 α 范围: {alphas_cv.min():.3f} ~ {alphas_cv.max():.1f}\")\nprint(f\"\\n选出的最优 α: {ridge_cv.alpha_:.4f}\")\nprint(f\"\\n训练集 R²: {ridge_cv.score(X_train_scaled, y_train):.4f}\")\nprint(f\"测试集 R²: {ridge_cv.score(X_test_scaled, y_test):.4f}\")\nprint(f\"\\n对比固定 α=1.0:\")\nprint(f\"  测试R² 提升: {(ridge_cv.score(X_test_scaled, y_test) - test_r2_ridge):.5f}\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n==================================================\nRidgeCV 结果（5折交叉验证）\n==================================================\n候选 α 范围: 0.001 ~ 1000.0\n\n选出的最优 α: 2.6827\n\n训练集 R²: 0.7508\n测试集 R²: 0.6680\n\n对比固定 α=1.0:\n  测试R² 提升: -0.00050\n```\n:::\n:::\n\n\n### LassoCV：自动选择最优 α\n\n::: {#a2cb0a40 .cell execution_count=14}\n``` {.python .cell-code}\n# LassoCV：5折交叉验证\nlasso_cv = LassoCV(alphas=alphas_cv, cv=5, max_iter=10000)\nlasso_cv.fit(X_train_scaled, y_train)\n\nprint(\"=\"*50)\nprint(\"LassoCV 结果（5折交叉验证）\")\nprint(\"=\"*50)\nprint(f\"选出的最优 α: {lasso_cv.alpha_:.4f}\")\nprint(f\"\\n训练集 R²: {lasso_cv.score(X_train_scaled, y_train):.4f}\")\nprint(f\"测试集 R²: {lasso_cv.score(X_test_scaled, y_test):.4f}\")\nprint(f\"\\n保留特征数: {np.sum(lasso_cv.coef_ != 0)}/{len(lasso_cv.coef_)}\")\nprint(f\"被剔除特征: {[feature_names[i] for i in range(len(lasso_cv.coef_)) if lasso_cv.coef_[i] == 0]}\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n==================================================\nLassoCV 结果（5折交叉验证）\n==================================================\n选出的最优 α: 0.0010\n\n训练集 R²: 0.7509\n测试集 R²: 0.6687\n\n保留特征数: 13/13\n被剔除特征: []\n```\n:::\n:::\n\n\n### ElasticNetCV：自动选择最优 α\n\n::: {#2b23922b .cell execution_count=15}\n``` {.python .cell-code}\n# ElasticNetCV：5折交叉验证\nelastic_cv = ElasticNetCV(alphas=alphas_cv, l1_ratio=0.5, cv=5, max_iter=10000)\nelastic_cv.fit(X_train_scaled, y_train)\n\nprint(\"=\"*50)\nprint(\"ElasticNetCV 结果（5折交叉验证）\")\nprint(\"=\"*50)\nprint(f\"选出的最优 α: {elastic_cv.alpha_:.4f}\")\nprint(f\"\\n训练集 R²: {elastic_cv.score(X_train_scaled, y_train):.4f}\")\nprint(f\"测试集 R²: {elastic_cv.score(X_test_scaled, y_test):.4f}\")\nprint(f\"\\n保留特征数: {np.sum(elastic_cv.coef_ != 0)}/{len(elastic_cv.coef_)}\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n==================================================\nElasticNetCV 结果（5折交叉验证）\n==================================================\n选出的最优 α: 0.0013\n\n训练集 R²: 0.7509\n测试集 R²: 0.6686\n\n保留特征数: 13/13\n```\n:::\n:::\n\n\n### 最终模型对比\n\n::: {#5be68f0f .cell execution_count=16}\n``` {.python .cell-code}\n# 汇总所有结果\nfinal_results = pd.DataFrame({\n    '模型': [\n        '普通回归',\n        'Ridge (α=1.0)',\n        'Lasso (α=0.01)',\n        'Elastic Net (α=0.01)',\n        'Ridge (CV)',\n        'Lasso (CV)',\n        'Elastic Net (CV)'\n    ],\n    'α': [\n        '-',\n        '1.0',\n        '0.01',\n        '0.01',\n        f'{ridge_cv.alpha_:.4f}',\n        f'{lasso_cv.alpha_:.4f}',\n        f'{elastic_cv.alpha_:.4f}'\n    ],\n    '测试R²': [\n        test_r2_lr,\n        test_r2_ridge,\n        test_r2_lasso,\n        test_r2_elastic,\n        ridge_cv.score(X_test_scaled, y_test),\n        lasso_cv.score(X_test_scaled, y_test),\n        elastic_cv.score(X_test_scaled, y_test)\n    ],\n    '非零特征': [\n        len(lr.coef_),\n        len(ridge.coef_),\n        np.sum(lasso.coef_ != 0),\n        np.sum(elastic.coef_ != 0),\n        len(ridge_cv.coef_),\n        np.sum(lasso_cv.coef_ != 0),\n        np.sum(elastic_cv.coef_ != 0)\n    ]\n})\n\nprint(\"\\n\" + \"=\"*80)\nprint(\"最终模型对比（包含交叉验证优化后的模型）\")\nprint(\"=\"*80)\nprint(final_results.to_string(index=False))\n\n# 找出最佳模型\nbest_idx = final_results['测试R²'].idxmax()\nprint(f\"\\n\" + \"=\"*80)\nprint(f\"✓ 推荐模型: {final_results.loc[best_idx, '模型']}\")\nprint(f\"  - 测试R²: {final_results.loc[best_idx, '测试R²']:.4f}\")\nprint(f\"  - 最优α: {final_results.loc[best_idx, 'α']}\")\nprint(f\"  - 保留特征: {final_results.loc[best_idx, '非零特征']}个\")\nprint(\"=\"*80)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\n================================================================================\n最终模型对比（包含交叉验证优化后的模型）\n================================================================================\n                  模型      α     测试R²  非零特征\n                普通回归      - 0.668759    13\n       Ridge (α=1.0)    1.0 0.668462    13\n      Lasso (α=0.01)   0.01 0.668182    13\nElastic Net (α=0.01)   0.01 0.667854    13\n          Ridge (CV) 2.6827 0.667965    13\n          Lasso (CV) 0.0010 0.668713    13\n    Elastic Net (CV) 0.0013 0.668648    13\n\n================================================================================\n✓ 推荐模型: 普通回归\n  - 测试R²: 0.6688\n  - 最优α: -\n  - 保留特征: 13个\n================================================================================\n```\n:::\n:::\n\n\n---\n\n## 正则化路径可视化（选做）\n\n观察随着 α 增大，各特征系数如何变化。\n\n### 计算 Lasso 正则化路径\n\n::: {#3c2d5e18 .cell execution_count=17}\n``` {.python .cell-code}\n# 计算不同 alpha 下的系数\nalphas_path = np.logspace(-3, 1, 100)\ncoefs_lasso_path = []\n\nfor alpha in alphas_path:\n    lasso_temp = Lasso(alpha=alpha, max_iter=10000)\n    lasso_temp.fit(X_train_scaled, y_train)\n    coefs_lasso_path.append(lasso_temp.coef_)\n\ncoefs_lasso_path = np.array(coefs_lasso_path)\n\nprint(\"✓ 正则化路径计算完成！\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n✓ 正则化路径计算完成！\n```\n:::\n:::\n\n\n### 绘制正则化路径图\n\n::: {#338fa5e9 .cell execution_count=18}\n``` {.python .cell-code}\nfig, axes = plt.subplots(1, 2, figsize=(14, 5))\n\n# 图1：系数路径\nfor i in range(coefs_lasso_path.shape[1]):\n    axes[0].plot(alphas_path, coefs_lasso_path[:, i],\n                linewidth=2, alpha=0.8, label=feature_names[i])\n\naxes[0].set_xlabel('α (正则化强度)', fontsize=12)\naxes[0].set_ylabel('系数值', fontsize=12)\naxes[0].set_title('Lasso 正则化路径\\nα 增大时，系数逐渐变为 0', fontsize=13, weight='bold')\naxes[0].set_xscale('log')\naxes[0].axhline(y=0, color='black', linestyle='--', linewidth=1)\naxes[0].axvline(x=lasso_cv.alpha_, color='red', linestyle='--', linewidth=2,\n               label=f'CV选择的α={lasso_cv.alpha_:.3f}')\naxes[0].legend(loc='best', fontsize=9, ncol=2)\naxes[0].grid(True, alpha=0.3)\n\n# 图2：非零系数数量\nn_nonzero_path = [np.sum(coefs != 0) for coefs in coefs_lasso_path]\naxes[1].plot(alphas_path, n_nonzero_path, 'b-', linewidth=2.5)\naxes[1].set_xlabel('α (正则化强度)', fontsize=12)\naxes[1].set_ylabel('非零系数个数', fontsize=12)\naxes[1].set_title('Lasso 特征选择效果\\nα 越大，保留的特征越少', fontsize=13, weight='bold')\naxes[1].set_xscale('log')\naxes[1].grid(True, alpha=0.3)\naxes[1].fill_between(alphas_path, 0, n_nonzero_path, alpha=0.3)\naxes[1].axvline(x=lasso_cv.alpha_, color='red', linestyle='--',\n               linewidth=2, label=f'CV选择的α={lasso_cv.alpha_:.3f}')\naxes[1].legend(fontsize=10)\n\nplt.tight_layout()\nplt.show()\n\nprint(\"\\n观察：\")\nprint(f\"- α = {alphas_path[0]:.3f} 时：{n_nonzero_path[0]}个特征保留\")\nprint(f\"- α = {lasso_cv.alpha_:.3f} (CV选择) 时：{np.sum(lasso_cv.coef_ != 0)}个特征保留\")\nprint(f\"- α = {alphas_path[-1]:.1f} 时：{n_nonzero_path[-1]}个特征保留\")\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nFont 'default' does not have a glyph for '\\u2212' [U+2212], substituting with a dummy symbol.\nFont 'default' does not have a glyph for '\\u2212' [U+2212], substituting with a dummy symbol.\nFont 'default' does not have a glyph for '\\u2212' [U+2212], substituting with a dummy symbol.\nFont 'default' does not have a glyph for '\\u2212' [U+2212], substituting with a dummy symbol.\nFont 'default' does not have a glyph for '\\u2212' [U+2212], substituting with a dummy symbol.\nFont 'default' does not have a glyph for '\\u2212' [U+2212], substituting with a dummy symbol.\nFont 'default' does not have a glyph for '\\u2212' [U+2212], substituting with a dummy symbol.\nFont 'default' does not have a glyph for '\\u2212' [U+2212], substituting with a dummy symbol.\nFont 'default' does not have a glyph for '\\u2212' [U+2212], substituting with a dummy symbol.\nFont 'default' does not have a glyph for '\\u2212' [U+2212], substituting with a dummy symbol.\nFont 'default' does not have a glyph for '\\u2212' [U+2212], substituting with a dummy symbol.\nFont 'default' does not have a glyph for '\\u2212' [U+2212], substituting with a dummy symbol.\nFont 'default' does not have a glyph for '\\u2212' [U+2212], substituting with a dummy symbol.\nFont 'default' does not have a glyph for '\\u2212' [U+2212], substituting with a dummy symbol.\nFont 'default' does not have a glyph for '\\u2212' [U+2212], substituting with a dummy symbol.\nFont 'default' does not have a glyph for '\\u2212' [U+2212], substituting with a dummy symbol.\nFont 'default' does not have a glyph for '\\u2212' [U+2212], substituting with a dummy symbol.\nFont 'default' does not have a glyph for '\\u2212' [U+2212], substituting with a dummy symbol.\n```\n:::\n\n::: {.cell-output .cell-output-display}\n![](w3_practice_files/figure-html/cell-19-output-2.png){width=1334 height=470}\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n\n观察：\n- α = 0.001 时：13个特征保留\n- α = 0.001 (CV选择) 时：13个特征保留\n- α = 10.0 时：0个特征保留\n```\n:::\n:::\n\n\n## 总结与思考\n\n### 本次课程要点\n\n✅ **过拟合**：模型太复杂，记住了训练数据的噪声\n✅ **正则化**：限制模型复杂度，提高泛化能力\n✅ **Ridge (L2)**：让系数变小但不为0\n✅ **Lasso (L1)**：让某些系数变为0（特征选择）\n✅ **Elastic Net**：结合 Ridge 和 Lasso\n✅ **交叉验证**：自动选择最优参数\n\n### 重要提醒\n\n⚠️ 正则化前必须标准化特征\n⚠️ 不要在测试集上选参数\n⚠️ 用 RidgeCV/LassoCV 自动选择 α\n\n",
    "supporting": [
      "w3_practice_files/figure-html"
    ],
    "filters": [],
    "includes": {
      "include-in-header": [
        "<script src=\"https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js\" integrity=\"sha512-c3Nl8+7g4LMSTdrm621y7kf9v3SDPnhxLNhcjFJbKECVnmZHTdo+IRO05sNLTH/D3vA6u1X32ehoLC7WFVdheg==\" crossorigin=\"anonymous\"></script>\n<script src=\"https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js\" integrity=\"sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==\" crossorigin=\"anonymous\" data-relocate-top=\"true\"></script>\n<script type=\"application/javascript\">define('jquery', [],function() {return window.jQuery;})</script>\n"
      ]
    }
  }
}