{
  "hash": "36c9fbe74c0c002f434fcf72acb3ddb4",
  "result": {
    "engine": "jupyter",
    "markdown": "---\ntitle: 第二讲：数据处理与线性回归实践\n---\n\n\n\n## 开场：为什么数据预处理如此重要？\n\n\n### 一个真实的场景\n\n**假设你收到这样一份数据...**\n\n| 面积 | 卧室数 | 房龄 | 价格 |\n|------|--------|------|------|\n| 100  | 2      | 5    | 200  |\n| 120  | ?      | 8    | 250  |\n| -50  | 3      | 10   | 150  |\n| 110  | 2      | 999  | 280  |\n\n**问题**：\n\n- 第 2 行：卧室数缺失\n- 第 3 行：面积为负数（不合理）\n- 第 4 行：房龄 999 年（明显异常）\n\n**能直接训练模型吗？**\n\n::: {.fragment}\n❌ **不能！** 模型会学到错误的规律，或者直接报错。\n:::\n\n\n### 本周学习目标\n\n#### 知识目标\n1. 理解数据预处理的重要性（缺失值、异常值、归一化）\n2. 掌握回归模型的评估指标（MAE、RMSE、R²）\n3. 理解残差的概念及其诊断作用\n4. 掌握数据可视化的基本原则\n\n#### 技能目标\n1. 使用 pandas 探索和清洗数据\n2. 使用 matplotlib/seaborn 绘制多种图表\n3. 训练完整的线性回归模型并评估\n4. 进行残差分析\n\n#### 核心理念\n**\"垃圾进，垃圾出\"（Garbage In, Garbage Out）**  \n数据质量决定模型质量！\n\n\n## 第一部分：数据预处理\n\n\n### 缺失值处理\n\n#### 什么是缺失值？\n\n- 数据收集过程中未记录的值\n- 在 pandas 中显示为 `NaN`（Not a Number）\n- 例子：客户忘记填年龄、传感器故障\n\n\n#### 🔍 缺失值处理的首要原则：理解业务逻辑\n\n**业务理解优先于技术方法**\n\n- **为什么缺失？** 分析缺失的根本原因\n- **隐形缺失**：有些缺失并非数据错误，而是业务逻辑的一部分\n- **填补策略**：优先基于业务逻辑，然后考虑统计方法\n\n\n#### 📊 隐形缺失的经典案例\n\n**R&D支出示例**：\n\n公司R&D支出数据示例：\n\n| 公司名称     | R&D支出  |\n|------------|----------|\n| 科技公司A   | 1000     |\n| 传统公司B   | NaN      |\n| 创业公司C   | 500      |\n\n- **业务逻辑分析：**\n\n  - 传统公司B没有R&D部门，所以R&D支出应为0，不是缺失值。\n  - **错误填补：** 如果用均值 (750) 填补，会高估传统公司实际水平。\n  - **正确做法：** 根据业务逻辑填补为0，更准确地反映现实业务情况。\n\n**其他隐形缺失案例**：\n\n- 学生成绩单中\"实习经历\"为空 → 可能从未实习，应填\"无\"\n- 电商数据中\"退货原因\"为空 → 可能未退货，应填\"无退货\"\n- 医疗数据中\"家族遗传病史\"为空 → 需要区分\"未询问\"vs\"无家族史\"\n\n\n#### 缺失值处理决策流程\n\n\n\n\n```{mermaid}\ngraph TD\n    A[发现缺失值] --> B[理解业务逻辑<br/>为何缺失？]\n    B --> C{是否为<br/>隐形缺失？}\n\n    C -->|是| D[根据业务规则填补<br/>如R&D=0, 退货原因=无]\n    C -->|否| E[检查缺失比例]\n\n    E -->|很小 <5%| F[删除法]\n    E -->|中等 5-20%| G[统计填充法]\n    E -->|较大 >20%| H[高级方法或<br/>放弃特征]\n\n    D --> I[验证业务合理性]\n    F --> I\n    G --> I\n    H --> I\n\n    style D fill:#4caf50,color:#fff\n    style I fill:#2196f3,color:#fff\n```\n\n\n\n\n\n#### 删除法\n\n**原始数据**：`[100, NaN, 120, 110, NaN]`\n\n**删除后**：`[100, 120, 110]`\n\n**优点**：\n- 简单直接\n- 不引入偏差\n\n**缺点**：\n- 丢失信息\n- 样本量减少\n\n**适用场景**：缺失比例很小（<5%）\n\n\n#### 填充法\n\n**常用填充值**：\n\n| 特征类型 | 推荐填充值 | 原因 |\n|---------|-----------|------|\n| 连续型（如年龄） | 中位数 | 不受极端值影响 |\n| 计数型（如卧室数） | 众数 | 符合实际分布 |\n| 二元型（如性别） | 众数 | 最常见类别 |\n\n**示例**：\n\n```\n原始: [10, 20, NaN, 30, 100]\n均值填充: [10, 20, 32, 30, 100]  ← 受极端值影响\n中位数填充: [10, 20, 25, 30, 100]  ← 更稳健 ✓\n```\n\n\n#### 高级方法（简介）\n\n**模型预测填充**：\n- 用其他特征预测缺失值\n- 例子：根据房屋面积、位置预测缺失的房龄\n- 后续课程会学习\n\n**多重插补**：\n- 生成多个填充版本\n- 综合结果\n- 统计学高级方法\n\n\n### 异常值检测与处理\n\n#### 什么是异常值？\n\n**定义**：明显偏离正常范围的数据点\n\n**例子**：\n\n- 房价数据中出现 1 美元（可能是录入错误）\n- 年龄数据中出现 999 岁（占位符未替换）\n- 收入数据中出现负值（除非是亏损）\n\n**关键问题**：**异常值 ≠ 错误值**\n\n- 亿万富翁买豪宅（真实但极端） → 保留\n- 录入错误（如 1 元/平米） → 删除/修正\n\n\n#### 异常值识别：箱线图\n\n::: {#36475906 .cell execution_count=2}\n``` {.python .cell-code}\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\n\nnp.random.seed(42)\n# 正常数据 + 几个异常值\nnormal_data = np.random.normal(100, 15, 100)\noutliers = np.array([50, 55, 180, 190])\nprice_data = np.concatenate([normal_data, outliers])\n\nplt.figure(figsize=(10, 6))\nplt.subplot(1, 2, 1)\nplt.boxplot(price_data, vert=True)\nplt.ylabel('房价 (千美元)')\nplt.title('箱线图：异常值检测')\nplt.grid(True, alpha=0.3)\n\n# 标注关键位置\nQ1 = np.percentile(price_data, 25)\nQ3 = np.percentile(price_data, 75)\nIQR = Q3 - Q1\nlower_bound = Q1 - 1.5 * IQR\nupper_bound = Q3 + 1.5 * IQR\n\nplt.axhline(y=Q1, color='green', linestyle='--', alpha=0.5, label=f'Q1={Q1:.1f}')\nplt.axhline(y=Q3, color='blue', linestyle='--', alpha=0.5, label=f'Q3={Q3:.1f}')\nplt.axhline(y=lower_bound, color='red', linestyle='--', alpha=0.5, label=f'下界={lower_bound:.1f}')\nplt.axhline(y=upper_bound, color='red', linestyle='--', alpha=0.5, label=f'上界={upper_bound:.1f}')\nplt.legend(fontsize=8)\n\nplt.subplot(1, 2, 2)\nplt.hist(price_data, bins=20, edgecolor='black', alpha=0.7)\nplt.xlabel('房价 (千美元)')\nplt.ylabel('频数')\nplt.title('直方图：数据分布')\nplt.axvline(x=lower_bound, color='red', linestyle='--', label='异常值边界')\nplt.axvline(x=upper_bound, color='red', linestyle='--')\nplt.legend()\nplt.grid(True, alpha=0.3)\n\nplt.tight_layout()\nplt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![](w2_data_processing_files/figure-html/cell-3-output-1.png){width=950 height=568}\n:::\n:::\n\n\n**箱线图组成**：\n\n- **箱体**：Q1 到 Q3（中间 50% 数据）\n- **中线**：中位数\n- **须**：正常数据范围\n- **点**：异常值\n\n\n#### 异常值识别：统计方法\n\n**1. IQR 方法（四分位距）**\n\n```\nQ1 = 25% 分位数\nQ3 = 75% 分位数\nIQR = Q3 - Q1\n下界 = Q1 - 1.5 × IQR\n上界 = Q3 + 1.5 × IQR\n\n异常值 = 低于下界 或 高于上界\n```\n\n**2. 3σ 原则**\n\n```\n异常值 = 超出 [均值 - 3×标准差, 均值 + 3×标准差]\n```\n\n\n#### 异常值处理决策\n\n\n\n\n```{mermaid}\ngraph TD\n    A[发现异常值] --> B{分析原因}\n    B --> C{是否错误?}\n    C -->|明确错误<br/>如负数面积| D[删除]\n    C -->|不确定| E{业务判断}\n    C -->|真实极端值<br/>如豪宅| F[保留]\n    \n    E -->|影响大| D\n    E -->|影响小| G[替换为边界值<br/>Winsorization]\n    E -->|需要建模| F\n    \n    style D fill:#f44336,color:#fff\n    style F fill:#4caf50,color:#fff\n    style G fill:#ff9800,color:#fff\n```\n\n\n\n\n**关键原则**：**先分析，再处理！不要盲目删除！**\n\n\n### 归一化（Normalization）\n\n#### 为什么需要归一化？\n\n**问题场景**：\n\n| 特征 | 范围 | 单位 |\n|------|------|------|\n| 面积 | 50-200 | 平米 |\n| 房龄 | 0-50 | 年 |\n| 票价 | 10-5000 | 元 |\n\n**影响**：\n\n- 某些模型（如神经网络、SVM）对特征尺度敏感\n- 大数值特征会主导梯度下降\n- 导致收敛慢或不收敛\n\n**线性回归影响较小，但归一化仍有益**\n\n\n#### 两种常用归一化方法\n\n**1. Min-Max 归一化（缩放到 [0, 1]）**\n\n$$\nx' = \\frac{x - \\min(x)}{\\max(x) - \\min(x)}\n$$\n\n**示例**：`[10, 20, 30]` → `[0, 0.5, 1]`\n\n**优点**：\n- 保留原始分布形状\n- 结果有界\n\n**缺点**：\n- 对异常值敏感\n\n\n**2. Z-score 标准化（均值 0，标准差 1）**\n\n$$\nx' = \\frac{x - \\mu}{\\sigma}\n$$\n\n**示例**：`[10, 20, 30]` → `[-1, 0, 1]`\n\n**优点**：\n- 不受异常值影响（相对）\n- 适合正态分布数据\n\n**缺点**：\n- 结果无界\n\n\n#### 归一化前后对比\n\n::: {#55efc427 .cell execution_count=3}\n``` {.python .cell-code}\nfrom sklearn.preprocessing import MinMaxScaler, StandardScaler\n\n# 模拟三个特征\nnp.random.seed(42)\narea = np.random.uniform(50, 200, 100)    # 面积 50-200\nage = np.random.uniform(0, 50, 100)       # 房龄 0-50\nprice = np.random.uniform(100, 500, 100)  # 价格 100-500\n\n# 创建 DataFrame\ndata_orig = pd.DataFrame({\n    '面积': area,\n    '房龄': age,\n    '价格': price\n})\n\n# Min-Max 归一化\nscaler_minmax = MinMaxScaler()\ndata_minmax = pd.DataFrame(\n    scaler_minmax.fit_transform(data_orig),\n    columns=data_orig.columns\n)\n\n# Z-score 标准化\nscaler_std = StandardScaler()\ndata_std = pd.DataFrame(\n    scaler_std.fit_transform(data_orig),\n    columns=data_orig.columns\n)\n\n# 可视化\nfig, axes = plt.subplots(1, 3, figsize=(15, 5))\n\n# 原始数据\ndata_orig.boxplot(ax=axes[0])\naxes[0].set_title('原始数据')\naxes[0].set_ylabel('数值')\naxes[0].grid(True, alpha=0.3)\n\n# Min-Max\ndata_minmax.boxplot(ax=axes[1])\naxes[1].set_title('Min-Max 归一化 [0,1]')\naxes[1].set_ylabel('归一化值')\naxes[1].grid(True, alpha=0.3)\n\n# Z-score\ndata_std.boxplot(ax=axes[2])\naxes[2].set_title('Z-score 标准化 (μ=0, σ=1)')\naxes[2].set_ylabel('标准化值')\naxes[2].grid(True, alpha=0.3)\n\nplt.tight_layout()\nplt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![](w2_data_processing_files/figure-html/cell-4-output-1.png){width=1431 height=471}\n:::\n:::\n\n\n#### 何时使用哪种归一化？\n\n| 方法 | 适用场景 | 例子 |\n|------|---------|------|\n| **Min-Max** | 数据分布均匀<br/>需要固定范围<br/>图像数据（0-255 → 0-1） | 神经网络输入层 |\n| **Z-score** | 数据有异常值<br/>正态分布<br/>需要保留分布形状 | 逻辑回归<br/>SVM |\n| **不归一化** | 树模型<br/>（决策树、随机森林、GBDT） | 线性回归影响小<br/>但建议归一化 |\n\n\n## 第二部分：回归模型评估\n\n\n### 残差（Residual）\n\n#### 核心概念\n\n**定义**：\n$$\n\\text{残差} = \\text{真实值} - \\text{预测值} = y - \\hat{y}\n$$\n\n**例子**：\n\n| 样本 | 真实价格 | 预测价格 | 残差 |\n|------|---------|---------|------|\n| 1 | 250 | 240 | +10 |\n| 2 | 200 | 210 | -10 |\n| 3 | 300 | 295 | +5 |\n\n\n#### 理想的残差\n\n::: {#f0de3a8a .cell message='false' execution_count=4}\n``` {.python .cell-code}\n# 模拟好的模型和差的模型\nnp.random.seed(42)\nX = np.linspace(0, 10, 100)\ny_true = 2*X + 3 + np.random.randn(100)*0.5\n\n# 好的模型\ny_pred_good = 2*X + 3\nresiduals_good = y_true - y_pred_good\n\n# 差的模型（欠拟合）\ny_pred_bad = 1.5*X + 2\nresiduals_bad = y_true - y_pred_bad\n\nfig, axes = plt.subplots(2, 2, figsize=(14, 10))\n\n# 好的模型：拟合图\naxes[0, 0].scatter(X, y_true, alpha=0.5, label='真实数据')\naxes[0, 0].plot(X, y_pred_good, 'r-', linewidth=2, label='拟合线')\naxes[0, 0].set_xlabel('特征 X')\naxes[0, 0].set_ylabel('目标 y')\naxes[0, 0].set_title('好的模型：拟合图')\naxes[0, 0].legend()\naxes[0, 0].grid(True, alpha=0.3)\n\n# 好的模型：残差图\naxes[0, 1].scatter(y_pred_good, residuals_good, alpha=0.5)\naxes[0, 1].axhline(y=0, color='red', linestyle='--', linewidth=2)\naxes[0, 1].set_xlabel('预测值')\naxes[0, 1].set_ylabel('残差')\naxes[0, 1].set_title('好的模型：残差随机分布 ✓')\naxes[0, 1].grid(True, alpha=0.3)\n\n# 差的模型：拟合图\naxes[1, 0].scatter(X, y_true, alpha=0.5, label='真实数据')\naxes[1, 0].plot(X, y_pred_bad, 'r-', linewidth=2, label='拟合线（欠拟合）')\naxes[1, 0].set_xlabel('特征 X')\naxes[1, 0].set_ylabel('目标 y')\naxes[1, 0].set_title('差的模型：拟合图')\naxes[1, 0].legend()\naxes[1, 0].grid(True, alpha=0.3)\n\n# 差的模型：残差图\naxes[1, 1].scatter(y_pred_bad, residuals_bad, alpha=0.5, color='orange')\naxes[1, 1].axhline(y=0, color='red', linestyle='--', linewidth=2)\naxes[1, 1].set_xlabel('预测值')\naxes[1, 1].set_ylabel('残差')\naxes[1, 1].set_title('差的模型：残差有趋势 ✗')\naxes[1, 1].grid(True, alpha=0.3)\n\nplt.tight_layout()\nplt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![](w2_data_processing_files/figure-html/cell-5-output-1.png){width=1335 height=953}\n:::\n:::\n\n\n**判断标准**：\n\n- ✓ **好的残差图**：点随机分布在 y=0 附近，无明显趋势\n- ✗ **差的残差图**：有漏斗形、U 形、趋势线等规律\n\n\n### MAE（平均绝对误差）\n\n#### 定义\n\n$$\n\\text{MAE} = \\frac{1}{n}\\sum_{i=1}^{n}|y_i - \\hat{y}_i|\n$$\n\n**直观理解**：所有预测误差的绝对值的平均\n\n\n#### MAE 的优缺点\n\n**优点**：\n\n- 🎯 直观：单位与原数据相同\n- 🛡️ 稳健：对异常值不敏感\n- 📊 易解释：适合向业务人员汇报\n\n**缺点**：\n\n- 😐 不区分大小误差：误差 10 和误差 100 被同等对待\n\n**适用场景**：\n\n- 关注平均误差水平\n- 对所有误差一视同仁\n- 例子：房价预测、销量预测\n\n\n### RMSE（均方根误差）\n\n#### 定义\n\n$$\n\\text{RMSE} = \\sqrt{\\frac{1}{n}\\sum_{i=1}^{n}(y_i - \\hat{y}_i)^2}\n$$\n\n**步骤**：\n\n1. 计算残差的平方\n2. 求平均\n3. 开根号\n\n\n#### MAE vs RMSE 对比\n\n::: {#abfb0e87 .cell execution_count=5}\n``` {.python .cell-code}\n# 对比两个场景\n# 场景1：误差均匀分布\nerrors_uniform = np.array([5, 5, 5, 5, 5])\n\n# 场景2：存在一个大误差\nerrors_outlier = np.array([1, 1, 1, 1, 21])\n\nmae_uniform = np.mean(np.abs(errors_uniform))\nrmse_uniform = np.sqrt(np.mean(errors_uniform**2))\n\nmae_outlier = np.mean(np.abs(errors_outlier))\nrmse_outlier = np.sqrt(np.mean(errors_outlier**2))\n\ncomparison_data = pd.DataFrame({\n    '场景': ['均匀误差', '存在大误差'],\n    '误差分布': ['[5,5,5,5,5]', '[1,1,1,1,21]'],\n    'MAE': [mae_uniform, mae_outlier],\n    'RMSE': [rmse_uniform, rmse_outlier],\n    'RMSE/MAE': [rmse_uniform/mae_uniform, rmse_outlier/mae_outlier]\n})\n\nprint(comparison_data.to_string(index=False))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n   场景         误差分布  MAE     RMSE  RMSE/MAE\n 均匀误差  [5,5,5,5,5]  5.0 5.000000  1.000000\n存在大误差 [1,1,1,1,21]  5.0 9.433981  1.886796\n```\n:::\n:::\n\n\n**观察**：\n\n- 场景 1（均匀误差）：RMSE ≈ MAE\n- 场景 2（有大误差）：RMSE >> MAE（RMSE 对大误差更敏感）\n\n\n#### MAE vs RMSE 总结\n\n| 指标 | 计算 | 优点 | 缺点 | 何时使用 |\n|------|------|------|------|---------|\n| **MAE** | 绝对值平均 | 直观<br/>稳健 | 不区分大小误差 | 关注平均误差<br/>垃圾邮件分类 |\n| **RMSE** | 平方平均开根 | 惩罚大误差<br/>常用 | 对异常值敏感 | 大误差代价高<br/>医疗诊断<br/>金融风控 |\n\n**选择建议**：\n\n- 不确定 → **两个都算**\n- 业务对大误差敏感 → RMSE\n- 只关心平均水平 → MAE\n\n\n### R² 决定系数\n\n#### 定义\n\n$$\nR^2 = 1 - \\frac{SS_{res}}{SS_{tot}} = 1 - \\frac{\\sum(y_i - \\hat{y}_i)^2}{\\sum(y_i - \\bar{y})^2}\n$$\n\n**直观理解**：模型解释了多少变异\n\n- $SS_{res}$：残差平方和（模型的误差）\n- $SS_{tot}$：总平方和（数据的总变异）\n\n\n#### R² 的含义\n\n**取值范围**：\n\n- R² = 1：完美预测\n- R² = 0.8：模型解释了 80% 的变异\n- R² = 0：模型等同于预测平均值\n- R² < 0：模型比预测平均值还差（很糟糕）\n\n::: {#ba688fd5 .cell execution_count=6}\n``` {.python .cell-code}\n# 可视化 R² 的含义\nnp.random.seed(42)\nX_demo = np.linspace(0, 10, 50).reshape(-1, 1)\ny_demo = 2*X_demo.flatten() + 3 + np.random.randn(50)*2\n\nfrom sklearn.linear_model import LinearRegression\n\nmodel_demo = LinearRegression()\nmodel_demo.fit(X_demo, y_demo)\ny_pred_demo = model_demo.predict(X_demo)\ny_mean = np.mean(y_demo)\n\n# 计算 R²\nr2 = model_demo.score(X_demo, y_demo)\n\nplt.figure(figsize=(12, 5))\n\nplt.subplot(1, 2, 1)\nplt.scatter(X_demo, y_demo, alpha=0.6, label='真实数据')\nplt.plot(X_demo, y_pred_demo, 'r-', linewidth=2, label='模型预测')\nplt.axhline(y=y_mean, color='green', linestyle='--', linewidth=2, label=f'平均值 = {y_mean:.1f}')\nplt.xlabel('X')\nplt.ylabel('y')\nplt.title(f'模型拟合 (R² = {r2:.3f})')\nplt.legend()\nplt.grid(True, alpha=0.3)\n\n# 残差对比\nplt.subplot(1, 2, 2)\nresiduals_model = y_demo - y_pred_demo\nresiduals_mean = y_demo - y_mean\n\nx_pos = np.arange(len(residuals_model))\nwidth = 0.35\nplt.bar(x_pos - width/2, np.abs(residuals_mean), width, label='预测平均值的误差', alpha=0.6)\nplt.bar(x_pos + width/2, np.abs(residuals_model), width, label='模型的误差', alpha=0.6)\nplt.xlabel('样本序号')\nplt.ylabel('|残差|')\nplt.title('模型 vs 基线（预测平均值）')\nplt.legend()\nplt.grid(True, alpha=0.3)\n\nplt.tight_layout()\nplt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![](w2_data_processing_files/figure-html/cell-7-output-1.png){width=1144 height=472}\n:::\n:::\n\n\n## 第三部分：数据可视化\n\n\n### 为什么需要可视化？\n\n#### Anscombe's Quartet（安斯库姆四重奏）\n\n**四组数据，统计量完全相同**：\n\n- 均值、方差、相关系数、回归线都一样\n- 但数据分布完全不同！\n\n::: {#088b1802 .cell execution_count=7}\n``` {.python .cell-code}\n# Anscombe's Quartet\ndatasets = {\n    'I': {'x': [10, 8, 13, 9, 11, 14, 6, 4, 12, 7, 5],\n          'y': [8.04, 6.95, 7.58, 8.81, 8.33, 9.96, 7.24, 4.26, 10.84, 4.82, 5.68]},\n    'II': {'x': [10, 8, 13, 9, 11, 14, 6, 4, 12, 7, 5],\n           'y': [9.14, 8.14, 8.74, 8.77, 9.26, 8.10, 6.13, 3.10, 9.13, 7.26, 4.74]},\n    'III': {'x': [10, 8, 13, 9, 11, 14, 6, 4, 12, 7, 5],\n            'y': [7.46, 6.77, 12.74, 7.11, 7.81, 8.84, 6.08, 5.39, 8.15, 6.42, 5.73]},\n    'IV': {'x': [8, 8, 8, 8, 8, 8, 8, 19, 8, 8, 8],\n           'y': [6.58, 5.76, 7.71, 8.84, 8.47, 7.04, 5.25, 12.50, 5.56, 7.91, 6.89]}\n}\n\nfig, axes = plt.subplots(2, 2, figsize=(12, 10))\naxes = axes.flatten()\n\nfor idx, (name, data) in enumerate(datasets.items()):\n    x = np.array(data['x'])\n    y = np.array(data['y'])\n    \n    # 回归线\n    from scipy import stats\n    slope, intercept, r_value, p_value, std_err = stats.linregress(x, y)\n    line = slope * x + intercept\n    \n    axes[idx].scatter(x, y, s=100, alpha=0.6)\n    axes[idx].plot(x, line, 'r-', linewidth=2)\n    axes[idx].set_xlabel('X')\n    axes[idx].set_ylabel('Y')\n    axes[idx].set_title(f'数据集 {name}\\n均值X={np.mean(x):.1f}, 均值Y={np.mean(y):.2f}, r={r_value:.3f}')\n    axes[idx].grid(True, alpha=0.3)\n    axes[idx].set_xlim(0, 20)\n    axes[idx].set_ylim(2, 14)\n\nplt.tight_layout()\nplt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![](w2_data_processing_files/figure-html/cell-8-output-1.png){width=1144 height=954}\n:::\n:::\n\n\n**教训**：**永远要可视化数据！数字不会说谎，但会隐藏真相。**\n\n\n### 常用图表类型\n\n#### 散点图（Scatter Plot）\n\n**用途**：观察两个变量的关系\n\n::: {#4820064a .cell execution_count=8}\n``` {.python .cell-code}\n# 生成示例数据\nnp.random.seed(42)\narea_demo = np.random.uniform(50, 200, 100)\nprice_demo = 2*area_demo + np.random.randn(100)*30 + 50\n\nplt.figure(figsize=(10, 6))\nplt.scatter(area_demo, price_demo, alpha=0.6, s=50)\nplt.xlabel('面积 (平米)', fontsize=12)\nplt.ylabel('价格 (千美元)', fontsize=12)\nplt.title('散点图示例：房屋面积 vs 价格', fontsize=14)\nplt.grid(True, alpha=0.3)\n\n# 添加趋势线\nz = np.polyfit(area_demo, price_demo, 1)\np = np.poly1d(z)\nplt.plot(area_demo, p(area_demo), \"r--\", linewidth=2, alpha=0.8, label=f'趋势线: y={z[0]:.2f}x+{z[1]:.2f}')\nplt.legend()\nplt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![](w2_data_processing_files/figure-html/cell-9-output-1.png){width=812 height=527}\n:::\n:::\n\n\n**能看出什么**：\n\n- 正相关/负相关/无关系\n- 线性/非线性\n- 离群点\n\n\n#### 直方图（Histogram）\n\n**用途**：观察单个变量的分布\n\n::: {#51622742 .cell execution_count=9}\n``` {.python .cell-code}\nfig, axes = plt.subplots(1, 3, figsize=(15, 5))\n\n# 正态分布\ndata_normal = np.random.normal(100, 15, 1000)\naxes[0].hist(data_normal, bins=30, edgecolor='black', alpha=0.7)\naxes[0].set_xlabel('数值')\naxes[0].set_ylabel('频数')\naxes[0].set_title('正态分布（对称）')\naxes[0].grid(True, alpha=0.3)\n\n# 右偏分布\ndata_skewed = np.random.exponential(50, 1000)\naxes[1].hist(data_skewed, bins=30, edgecolor='black', alpha=0.7, color='orange')\naxes[1].set_xlabel('数值')\naxes[1].set_ylabel('频数')\naxes[1].set_title('右偏分布（收入、房价常见）')\naxes[1].grid(True, alpha=0.3)\n\n# 双峰分布\ndata_bimodal = np.concatenate([np.random.normal(50, 10, 500), np.random.normal(100, 10, 500)])\naxes[2].hist(data_bimodal, bins=30, edgecolor='black', alpha=0.7, color='green')\naxes[2].set_xlabel('数值')\naxes[2].set_ylabel('频数')\naxes[2].set_title('双峰分布（可能有两个群体）')\naxes[2].grid(True, alpha=0.3)\n\nplt.tight_layout()\nplt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![](w2_data_processing_files/figure-html/cell-10-output-1.png){width=1431 height=473}\n:::\n:::\n\n\n#### 相关系数热力图（Heatmap）\n\n**用途**：一次性看所有特征之间的相关性\n\n::: {#93dfab68 .cell execution_count=10}\n``` {.python .cell-code}\n# 生成相关数据\nnp.random.seed(42)\nn = 100\ndata_corr = pd.DataFrame({\n    '面积': np.random.uniform(50, 200, n),\n})\ndata_corr['卧室数'] = 0.7 * data_corr['面积'] / 30 + np.random.randn(n) * 0.5\ndata_corr['房龄'] = np.random.uniform(0, 50, n)\ndata_corr['价格'] = 2 * data_corr['面积'] + 20 * data_corr['卧室数'] - 1 * data_corr['房龄'] + np.random.randn(n) * 20\n\n# 计算相关系数矩阵\ncorr_matrix = data_corr.corr()\n\nplt.figure(figsize=(8, 6))\nsns.heatmap(corr_matrix, annot=True, cmap='coolwarm', center=0, \n            square=True, linewidths=1, cbar_kws={\"shrink\": 0.8},\n            vmin=-1, vmax=1)\nplt.title('特征相关系数热力图', fontsize=14)\nplt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![](w2_data_processing_files/figure-html/cell-11-output-1.png){width=567 height=507}\n:::\n:::\n\n\n**解读**：\n\n- **红色（接近 +1）**：强正相关（面积↑价格↑）\n- **蓝色（接近 -1）**：强负相关（房龄↑价格↓）\n- **白色（接近 0）**：无线性关系\n\n\n### 可视化陷阱\n\n#### 陷阱 1：截断 Y 轴\n\n::: {#e6176668 .cell execution_count=11}\n``` {.python .cell-code}\n# 示例：夸大差异\ncategories = ['产品A', '产品B']\nvalues = [100, 102]\n\nfig, axes = plt.subplots(1, 2, figsize=(12, 5))\n\n# 诚实的图\naxes[0].bar(categories, values, color=['blue', 'orange'])\naxes[0].set_ylabel('销量')\naxes[0].set_title('诚实的图：差异很小')\naxes[0].set_ylim(0, 120)\naxes[0].grid(True, alpha=0.3, axis='y')\n\n# 误导的图（截断Y轴）\naxes[1].bar(categories, values, color=['blue', 'orange'])\naxes[1].set_ylabel('销量')\naxes[1].set_title('误导的图：看起来差距巨大！')\naxes[1].set_ylim(99, 103)  # 截断 Y 轴\naxes[1].grid(True, alpha=0.3, axis='y')\n\nplt.tight_layout()\nplt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![](w2_data_processing_files/figure-html/cell-12-output-1.png){width=1143 height=471}\n:::\n:::\n\n\n**教训**：始终检查 Y 轴起点是否为 0\n\n\n#### 陷阱 2：忽略样本量\n\n::: {#8b63be5d .cell execution_count=12}\n``` {.python .cell-code}\n# 示例：样本量差异\ndata_large = np.random.normal(100, 15, 1000)\ndata_small = np.random.normal(105, 15, 10)\n\nfig, axes = plt.subplots(1, 2, figsize=(12, 5))\n\naxes[0].hist(data_large, bins=30, alpha=0.7, label=f'样本量=1000\\n均值={np.mean(data_large):.1f}')\naxes[0].set_xlabel('数值')\naxes[0].set_ylabel('频数')\naxes[0].set_title('大样本：分布稳定')\naxes[0].legend()\naxes[0].grid(True, alpha=0.3)\n\naxes[1].hist(data_small, bins=10, alpha=0.7, color='orange', label=f'样本量=10\\n均值={np.mean(data_small):.1f}')\naxes[1].set_xlabel('数值')\naxes[1].set_ylabel('频数')\naxes[1].set_title('小样本：分布不稳定')\naxes[1].legend()\naxes[1].grid(True, alpha=0.3)\n\nplt.tight_layout()\nplt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![](w2_data_processing_files/figure-html/cell-13-output-1.png){width=1143 height=473}\n:::\n:::\n\n\n**教训**：报告统计量时，务必说明样本量\n\n\n## 第四部分：完整实战流程\n\n\n### 完整流程概览\n\n\n\n\n```{mermaid}\ngraph TD\n    A[读取数据] --> B[探索性数据分析<br>EDA]\n    B --> C[数据清洗]\n    C --> D[特征工程<br>可选]\n    D --> E[数据切分]\n    E --> F[训练模型]\n    F --> G[模型评估]\n    G --> H[残差分析]\n    H --> I{满意?}\n    I -->|否| J[调整模型/特征]\n    J --> F\n    I -->|是| K[完成]\n    \n    style A fill:#e3f2fd\n    style C fill:#fff9c4\n    style F fill:#c8e6c9\n    style G fill:#ffccbc\n    style K fill:#4caf50,color:#fff\n```\n\n\n\n\n\n## 总结\n\n\n### 本讲知识回顾\n\n#### 数据预处理\n\n- **缺失值**：删除 vs 填充\n- **异常值**：IQR 方法、3σ 原则、业务判断\n- **归一化**：Min-Max vs Z-score\n\n#### 模型评估\n\n- **残差**：模型诊断的核心\n- **MAE**：平均绝对误差，直观稳健\n- **RMSE**：均方根误差，惩罚大误差\n- **R²**：解释变异的比例\n\n#### 数据可视化\n\n- 散点图、直方图、箱线图、热力图\n- **永远先可视化，再建模！**\n\n\n### 核心要点\n\n1. **数据质量决定模型质量**  \n   \"Garbage In, Garbage Out\" → 数据清洗是基础\n\n2. **评估指标要多角度**  \n   不要只看一个指标，MAE + RMSE + R² + 残差图\n\n3. **可视化是必须的**  \n   Anscombe's Quartet 的教训\n\n4. **模型诊断很重要**  \n   残差图能发现很多问题\n\n\n## Q&A\n\n**Q1：请简述 Min-Max 归一化和 Z-score 标准化各自的计算目标（或特点）。根据讲义，为什么树模型（如决策树、随机森林）通常不需要进行归一化处理？**\n\n**A：**\n\n* Min-Max 归一化：其目标是将数据线性缩放到一个固定的区间，通常是 [0, 1]。\n* Z-score 标准化：其目标是将数据转换为均值为 0、标准差为 1 的分布。\n* 树模型不需要的原因：树模型是基于“分裂点”来做决策的（例如“面积 > 80平米”），它关心的是特征的顺序和阈值，而不关心特征的绝对尺度。归一化不会改变特征值的相对顺序，因此对树模型的决策几乎没有影响。\n\n\n**Q2：在处理缺失值时，为什么讲义强调第一步是“理解业务逻辑”？请结合课程中“R&D支出”的例子说明。**\n\n**A：**\n因为某些缺失值（`NaN`）可能并非真正的“数据丢失”，而是具有特定业务含义的“隐形缺失”。\n\n* 例子：在“R&D支出”的例子中，一家“传统公司”的R&D支出显示为 `NaN`。\n* 错误处理：如果盲目用均值或中位数填充，会错误地高估这家公司的研发投入。\n* 正确处理：通过业务逻辑理解，这家公司很可能没有R&D部门，因此 `NaN` 的真实含义是 0。此时应将其填充为 0 才能准确反映业务现实。\n\n\n**Q3：MAE (平均绝对误差) 和 RMSE (均方根误差) 都是评估回归模型的指标。请问 RMSE 的计算方式（平方-求均-开方）有何特点，这导致它对哪种类型的误差（大误差还是小误差）更敏感？**\n\n**A：**\n* 特点：RMSE 的计算涉及“平方”步骤（ $(y_i - \\hat{y}_i)^2$ ）。\n* 敏感性：这个“平方”操作会显著放大那些数值较大的误差。\n* 结论：因此，RMSE 相比 MAE 对“大误差”（即预测错得离谱的异常点）更为敏感。如果业务上无法容忍大的预测失误（例如金融风控），RMSE 是一个很重要的参考指标。\n\n\n**Q4：课程中的“安斯库姆四重奏”(Anscombe's Quartet) 案例告诉了我们一个关于数据分析的什么重要教训？**\n\n**A：**\n它告诉我们的教训是：“永远要可视化你的数据！”\n\n这四组数据的均值、方差、相关系数、甚至回归线都完全相同，但它们的数据分布形态却截然不同。如果只看统计数字，我们会误以为它们是一样的数据；只有通过可视化（如散点图），才能发现真相和数据中隐藏的模式。\n\n\n**Q5：某回归模型的 R² (决定系数) 值为 0.8 [cite: 83]。这句话的直观解释是什么？R² 是否有可能为负数？**\n\n**A：**\n\n* 解释：R² = 0.8 意味着，这个模型解释了数据中 80% 的变异性（或方差）。换句话说，相比于“盲猜”所有样本的平均值，这个模型能将预测的误差（用平方和衡量）减少 80%。\n* 是否为负：有可能。R² 为负数意味着模型的预测表现比“直接预测平均值”这个最简单的基线还要差。这通常说明模型非常糟糕，或者数据完全不适合该模型。\n\n\n**Q6：你在使用箱线图（Boxplot）进行异常值检测时，发现了一个明显偏离上界（Q3 + 1.5*IQR）的“异常值”。你的下一步处理流程是什么？**\n\n**A：**\n\n* 不应该立即删除。发现异常值只是第一步，关键是分析其产生的原因：\n\n1.  分析原因：这个异常值是录入错误、测量错误，还是一个真实但极端的数据点？\n2.  业务判断：\n    * 如果是明确的错误：例如“面积-50”或“房龄999年”，这种数据应予以删除或修正（如果可能）。\n    * 如果是真实极端值：例如“亿万富翁买豪宅”导致的极高房价，这个数据是真实有效的，应该保留。盲目删除会扭曲数据分布，使模型失去对高端市场的预测能力。\n    * 如果不确定：可以尝试替换（例如用边界值替换），或者分别训练“包含”和“不包含”该异常值的模型，对比其对模型稳定性和评估指标的影响，再做决策。\n\n\n**Q7：在对线性回归模型进行“残差分析”时，如果你发现残差图（横轴为预测值，纵轴为残差）中的点呈现出明显的“喇叭口”形状（即预测值越大，残差的波动范围越大），这揭示了模型可能存在什么问题？**\n\n**A：**\n这揭示了模型可能存在“异方差性”（Heteroscedasticity）。\n\n* 含义：“异方差性”意味着模型的误差（残差）不是恒定的，而是随着预测值的变化而变化。\n* 具体表现：在“喇叭口”形态中，当预测值（例如房价）较低时，模型预测得较准（误差小）；但当预测值较高时，模型的预测误差变得非常不稳定（时而偏高，时而偏低，波动范围大）。\n* 影响：这违反了线性回归的基本假设之一（误差方差恒定），可能导致模型的参数估计和置信区间不准确。\n\n\n**Q8：假设你在构建两个金融模型：**\n1.  **模型A：预测银行网点的平均每日取款量，用于常规运营规划**。\n2.  **模型B：预测高频交易中的极端风险敞口，用于触发熔断机制**。\n\n**在评估时，模型A 和 模型B 应该分别更侧重 MAE 还是 RMSE？为什么？**\n\n**A：**\n\n* 模型A (平均取款量)：应该更侧重 MAE (平均绝对误差)。\n    * 原因：运营规划关心的是“平均”误差水平。MAE 能够直观地反映模型平均预测偏差了多少金额，且它对少数几天的极端值（例如节假日）不那么敏感（即更稳健），适合评估模型的整体稳健性。\n* 模型B (极端风险)：应该更侧重 RMSE (均方根误差)。\n    * 原因：风险控制和熔断机制的核心就是识别和惩罚“大误差”。RMSE 因为计算时有平方项，会极大地惩罚那些预测偏差大的点，侧重 RMSE 能确保模型在“错得最离谱”的极端情况下表现得更好，这对于风控至关重要。\n\n\n**Q9：在第一讲我们学到要先切分训练集/测试集。在第二讲我们学习了归一化。为什么“归一化”这个操作（例如 Z-score）必须在“切分数据”之后进行？如果顺序反了，会导致什么严重后果？**\n\n**A：**\n这是为了防止“数据泄露”（Data Leakage）。\n\n* 后果：Z-score 归一化需要计算数据的均值($\\mu$)和标准差($\\sigma$)。如果先对所有数据（1000条）进行归一化，再切分为训练集（800条）和测试集（200条），那么在计算均值和标准差时，测试集的 200 条数据信息已经被用到了。\n* 影响：这导致模型在训练阶段就已经“偷看”到了测试集的分布信息。这违反了“测试集必须是模型在训练过程中从未见过的数据”这一核心原则。这会导致模型在测试集上的评估结果过于乐观（分数虚高），而无法代表模型在未来真实新数据上的泛化能力。\n* 正确做法：1. 先切分。 2. 只在训练集上计算 $\\mu$ 和 $\\sigma$。 3. 用这个（来自训练集的）$\\mu$ 和 $\\sigma$ 去归一化训练集，并用同一个 $\\mu$ 和 $\\sigma$ 去归一化测试集。\n\n",
    "supporting": [
      "w2_data_processing_files/figure-html"
    ],
    "filters": [],
    "includes": {}
  }
}