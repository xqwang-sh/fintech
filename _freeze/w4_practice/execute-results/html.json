{
  "hash": "508e97bbd39ccccd3ce2fbaff75145e8",
  "result": {
    "engine": "jupyter",
    "markdown": "---\ntitle: 第四讲上机实践\n---\n\n\n\n本上机讲义覆盖以下内容：\n\n- Titanic 数据集介绍\n- 探索性数据分析 (EDA)\n- 数据预处理与特征工程\n- 决策树超参数调优与模型训练\n- 模型评估（混淆矩阵/准确率/精确率/召回率/F1/ROC/AUC）\n- 总结与实战经验\n\n**学习目标**：\n\n- 理解分类问题的基本概念\n- 掌握决策树的工作原理\n- 学会评估分类模型的性能\n- 掌握超参数调优的方法\n\n## Titanic 数据集介绍\n\n**背景**：1912 年泰坦尼克号沉船事故，2224 名乘客中 1502 人遇难，成为历史上最著名的沉船灾难之一。\n\n**任务**：预测乘客是否能在灾难中存活\n\n**数据集特征**：\n\n| 特征 | 含义 | 类型 |\n|------|------|------|\n| Pclass | 舱位等级（1/2/3） | 数值 |\n| Sex | 性别 | 类别 |\n| Age | 年龄 | 数值 |\n| SibSp | 兄弟姐妹/配偶数 | 数值 |\n| Parch | 父母/子女数 | 数值 |\n| Fare | 票价 | 数值 |\n| Embarked | 登船港口（C/Q/S） | 类别 |\n\n**标签**：Survived（0=死亡，1=存活）\n\n**为什么选择这个数据集？**\n\n- 数据完整，包含丰富的信息\n- 是一个经典的二分类问题\n- 结果易于理解和解释\n- 可以很好地展示分类算法的效果\n\n::: {#fb9836f8 .cell message='false' execution_count=2}\n``` {.python .cell-code}\n# 导入所需库\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom sklearn.model_selection import train_test_split, cross_val_score\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.metrics import (confusion_matrix, ConfusionMatrixDisplay,\n                             accuracy_score, precision_score, recall_score, f1_score,\n                             roc_curve, auc, classification_report)\n\n# 设置中文显示\nplt.rcParams[\"font.sans-serif\"] = [\"SimHei\"]\nplt.rcParams[\"axes.unicode_minus\"] = False\n%matplotlib inline\n```\n:::\n\n\n::: {#fe715241 .cell message='false' execution_count=3}\n``` {.python .cell-code}\n# 加载 Titanic 数据\ndf = pd.read_csv(\"titanic_data/train.csv\")\nprint(f\"数据集形状: {df.shape}\")\nprint(\"前5行数据:\")\nprint(df.head())\nprint(\"生存情况统计:\")\nprint(df[\"Survived\"].value_counts())\nprint(f\"生存率: {df['Survived'].mean():.3f}\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n数据集形状: (891, 12)\n前5行数据:\n   PassengerId  Survived  Pclass  \\\n0            1         0       3   \n1            2         1       1   \n2            3         1       3   \n3            4         1       1   \n4            5         0       3   \n\n                                                Name     Sex   Age  SibSp  \\\n0                            Braund, Mr. Owen Harris    male  22.0      1   \n1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n2                             Heikkinen, Miss. Laina  female  26.0      0   \n3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n4                           Allen, Mr. William Henry    male  35.0      0   \n\n   Parch            Ticket     Fare Cabin Embarked  \n0      0         A/5 21171   7.2500   NaN        S  \n1      0          PC 17599  71.2833   C85        C  \n2      0  STON/O2. 3101282   7.9250   NaN        S  \n3      0            113803  53.1000  C123        S  \n4      0            373450   8.0500   NaN        S  \n生存情况统计:\nSurvived\n0    549\n1    342\nName: count, dtype: int64\n生存率: 0.384\n```\n:::\n:::\n\n\n## 探索性数据分析 (EDA)\n\n**为什么需要数据探索？**\n\n在训练模型之前，我们需要：\n\n- 了解数据的分布特征\n- 发现变量之间的关系\n- 识别潜在的问题（如异常值、缺失值）\n- 为特征工程和模型选择提供依据\n\n**让我们通过可视化来探索 Titanic 数据：**\n\n::: {#c6a2d993 .cell message='false' execution_count=4}\n``` {.python .cell-code}\n# 数据探索：可视化分析\nfig, axes = plt.subplots(2, 2, figsize=(14, 10))\n\n# 1. 性别 vs 存活率\npd.crosstab(df[\"Sex\"], df[\"Survived\"], normalize=\"index\").plot(\n    kind=\"bar\", ax=axes[0, 0], color=[\"#f44336\", \"#4caf50\"]\n)\naxes[0, 0].set_title(\"性别 vs 存活率\", fontsize=12)\naxes[0, 0].set_xlabel(\"性别\")\naxes[0, 0].set_ylabel(\"比例\")\naxes[0, 0].set_xticklabels([\"女性\", \"男性\"], rotation=0)\naxes[0, 0].legend([\"死亡\", \"存活\"])\naxes[0, 0].grid(True, alpha=0.3, axis=\"y\")\n\n# 2. 舱位等级 vs 存活率\npd.crosstab(df[\"Pclass\"], df[\"Survived\"], normalize=\"index\").plot(\n    kind=\"bar\", ax=axes[0, 1], color=[\"#f44336\", \"#4caf50\"]\n)\naxes[0, 1].set_title(\"舱位等级 vs 存活率\", fontsize=12)\naxes[0, 1].set_xlabel(\"舱位等级\")\naxes[0, 1].set_ylabel(\"比例\")\naxes[0, 1].set_xticklabels([\"一等舱\", \"二等舱\", \"三等舱\"], rotation=0)\naxes[0, 1].legend([\"死亡\", \"存活\"])\naxes[0, 1].grid(True, alpha=0.3, axis=\"y\")\n\n# 3. 年龄分布（存活 vs 死亡）\ndf[df[\"Survived\"]==0][\"Age\"].dropna().hist(\n    bins=30, alpha=0.5, label=\"死亡\", ax=axes[1, 0], color=\"#f44336\"\n)\ndf[df[\"Survived\"]==1][\"Age\"].dropna().hist(\n    bins=30, alpha=0.5, label=\"存活\", ax=axes[1, 0], color=\"#4caf50\"\n)\naxes[1, 0].set_xlabel(\"年龄\")\naxes[1, 0].set_ylabel(\"频数\")\naxes[1, 0].set_title(\"年龄分布 (存活 vs 死亡)\", fontsize=12)\naxes[1, 0].legend()\naxes[1, 0].grid(True, alpha=0.3)\n\n# 4. 票价分布（存活 vs 死亡）\ndf[df[\"Survived\"]==0][\"Fare\"].dropna().hist(\n    bins=30, alpha=0.5, label=\"死亡\", ax=axes[1, 1], color=\"#f44336\"\n)\ndf[df[\"Survived\"]==1][\"Fare\"].dropna().hist(\n    bins=30, alpha=0.5, label=\"存活\", ax=axes[1, 1], color=\"#4caf50\"\n)\naxes[1, 1].set_xlabel(\"票价\")\naxes[1, 1].set_ylabel(\"频数\")\naxes[1, 1].set_title(\"票价分布 (存活 vs 死亡)\", fontsize=12)\naxes[1, 1].legend()\naxes[1, 1].grid(True, alpha=0.3)\n\nplt.tight_layout()\nplt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![](w4_practice_files/figure-html/cell-5-output-1.png){width=1334 height=950}\n:::\n:::\n\n\n**从可视化中我们可以观察到：**\n\n1. **性别差异显著**：女性存活率明显高于男性（体现\"女士优先\"的救援原则）\n\n2. **舱位等级重要**：一等舱存活率 > 二等舱 > 三等舱（舱位等级反映了社会经济地位）\n\n3. **年龄分布**：儿童存活率相对较高，青壮年死亡较多\n\n4. **票价影响**：高票价乘客存活率更高（与舱位等级相关）\n\n**这些洞察告诉我们哪些特征对预测存活重要！**\n\n## 数据预处理与特征工程\n\n**为什么需要数据预处理？**\n\n现实世界的数据往往是\"脏\"的：\n\n- **缺失值**：有些信息没有收集到\n- **类别变量**：机器学习算法通常需要数值输入\n- **异常值**：可能影响模型性能\n- **特征尺度不同**：决策树不需要归一化\n\n**我们的预处理策略：**\n\n1. **缺失值处理**\n   - Age：用中位数填充（比均值更稳健）\n   - Cabin：缺失太多，直接删除\n   - Embarked：删除缺失行（很少）\n\n2. **特征编码**\n   - Sex：标签编码（female=0, male=1）\n   - Embarked：独热编码（避免有序假设）\n\n3. **特征选择**\n   - 选择对预测存活有用的特征\n   - 排除像 Name、Ticket ID 这样的无关特征\n\n::: {#da5ea18f .cell message='false' execution_count=5}\n``` {.python .cell-code}\n# 数据预处理\nprint(\"缺失值统计:\")\nprint(df.isnull().sum())\n\n# Age: 中位数填充，Cabin: 删除，Embarked: 删除缺失行\ndf[\"Age\"].fillna(df[\"Age\"].median(), inplace=True)\ndf.drop(\"Cabin\", axis=1, inplace=True)\ndf.dropna(subset=[\"Embarked\"], inplace=True)\n\n# 编码：Sex 标签编码、Embarked 独热编码\ndf[\"Sex\"] = LabelEncoder().fit_transform(df[\"Sex\"])\ndf = pd.get_dummies(df, columns=[\"Embarked\"], drop_first=True)\n\n# 选择特征\nfeatures = [\"Pclass\", \"Sex\", \"Age\", \"SibSp\", \"Parch\", \"Fare\", \"Embarked_Q\", \"Embarked_S\"]\nX = df[features]\ny = df[\"Survived\"]\n\nprint(f\"特征矩阵形状: {X.shape}\")\nprint(f\"标签向量形状: {y.shape}\")\nprint(f\"选择的特征: {features}\")\n\n# 保存预处理后的特征和标签到本地（方便后续模型使用）\nX.to_csv(\"titanic_data/features_processed.csv\", index=False)\ny.to_csv(\"titanic_data/labels_processed.csv\", index=False)\nprint(\"已保存处理后的特征 (titanic_data/features_processed.csv) 和标签 (titanic_data/labels_processed.csv)\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n缺失值统计:\nPassengerId      0\nSurvived         0\nPclass           0\nName             0\nSex              0\nAge            177\nSibSp            0\nParch            0\nTicket           0\nFare             0\nCabin          687\nEmbarked         2\ndtype: int64\n特征矩阵形状: (889, 8)\n标签向量形状: (889,)\n选择的特征: ['Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare', 'Embarked_Q', 'Embarked_S']\n已保存处理后的特征 (titanic_data/features_processed.csv) 和标签 (titanic_data/labels_processed.csv)\n```\n:::\n:::\n\n\n## 决策树超参数调优与模型训练\n\n**标准机器学习流程：**\n\n1. **数据分割**：训练集 vs 测试集（必须在预处理之后）\n2. **超参数调优**：通过交叉验证找到最佳参数（在训练集上）\n3. **模型训练**：使用最佳参数在训练集上训练最终模型\n4. **模型评估**：在测试集上评估模型性能\n\n**为什么需要调参？**\n\n决策树有很多超参数可以调节，不同的参数组合会影响模型性能：\n\n- **max_depth**：树的最大深度（控制模型复杂度）\n- **min_samples_split**：分裂所需的最小样本数\n- **min_samples_leaf**：叶节点的最小样本数\n\n**调参策略：**\n\n通过绘制学习曲线（训练集 vs 验证集）来找到最佳参数：\n\n- 如果训练集得分远高于验证集 → 过拟合，需要降低复杂度\n- 如果两者都低 → 欠拟合，需要增加复杂度\n- 最佳点：验证集得分最高且与训练集差距不大\n\n::: {#b6b17b17 .cell message='false' execution_count=6}\n``` {.python .cell-code}\n# 数据分割：将数据分为训练集和测试集\nX_train, X_test, y_train, y_test = train_test_split(\n    X, y, test_size=0.2, random_state=42, stratify=y\n)\n\nprint(f\"训练集大小: {X_train.shape[0]}\")\nprint(f\"测试集大小: {X_test.shape[0]}\")\nprint(f\"训练集存活率: {y_train.mean():.3f}\")\nprint(f\"测试集存活率: {y_test.mean():.3f}\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n训练集大小: 711\n测试集大小: 178\n训练集存活率: 0.383\n测试集存活率: 0.382\n```\n:::\n:::\n\n\n::: {#dba7ccd3 .cell message='false' execution_count=7}\n``` {.python .cell-code}\n# 超参数调优：1. 调优 max_depth 参数\nprint(\"=\" * 50)\nprint(\"1. 调优 max_depth 参数\")\nprint(\"=\" * 50)\n\nmax_depths = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 15, 20]\ntrain_scores = []\ncv_scores = []\n\nfor depth in max_depths:\n    dt = DecisionTreeClassifier(max_depth=depth, random_state=42)\n    # 交叉验证得分\n    cv_score = cross_val_score(dt, X_train, y_train, cv=5, scoring=\"accuracy\").mean()\n    cv_scores.append(cv_score)\n    # 训练集得分\n    dt.fit(X_train, y_train)\n    train_scores.append(dt.score(X_train, y_train))\n\n# 绘制学习曲线\nplt.figure(figsize=(10, 6))\nplt.plot(max_depths, train_scores, \"o-\", label=\"训练集得分\", linewidth=2, markersize=8)\nplt.plot(max_depths, cv_scores, \"o-\", label=\"交叉验证得分\", linewidth=2, markersize=8)\nplt.xlabel(\"决策树最大深度 (max_depth)\", fontsize=12)\nplt.ylabel(\"准确率\", fontsize=12)\nplt.title(\"决策树不同 max_depth 的学习曲线\", fontsize=14)\nplt.legend(fontsize=11)\nplt.grid(True, alpha=0.3)\nplt.tight_layout()\nplt.show()\n\n# 选择最佳 max_depth\nbest_max_depth = max_depths[cv_scores.index(max(cv_scores))]\nprint(f\"最佳 max_depth: {best_max_depth}\")\nprint(f\"交叉验证准确率: {max(cv_scores):.4f}\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n==================================================\n1. 调优 max_depth 参数\n==================================================\n```\n:::\n\n::: {.cell-output .cell-output-display}\n![](w4_practice_files/figure-html/cell-8-output-2.png){width=951 height=566}\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n最佳 max_depth: 4\n交叉验证准确率: 0.8129\n```\n:::\n:::\n\n\n::: {#1882d479 .cell message='false' execution_count=8}\n``` {.python .cell-code}\n# 超参数调优：2. 调优 min_samples_split 参数\nprint(\"=\" * 50)\nprint(\"2. 调优 min_samples_split 参数\")\nprint(\"=\" * 50)\n\nmin_samples_splits = [2, 5, 10, 15, 20, 25, 30, 40, 50, 60, 80, 100]\ntrain_scores = []\ncv_scores = []\n\nfor min_samples in min_samples_splits:\n    dt = DecisionTreeClassifier(\n        max_depth=best_max_depth,\n        min_samples_split=min_samples,\n        random_state=42\n    )\n    # 交叉验证得分\n    cv_score = cross_val_score(dt, X_train, y_train, cv=5, scoring=\"accuracy\").mean()\n    cv_scores.append(cv_score)\n    # 训练集得分\n    dt.fit(X_train, y_train)\n    train_scores.append(dt.score(X_train, y_train))\n\n# 绘制学习曲线\nplt.figure(figsize=(10, 6))\nplt.plot(min_samples_splits, train_scores, \"o-\", label=\"训练集得分\", linewidth=2, markersize=8)\nplt.plot(min_samples_splits, cv_scores, \"o-\", label=\"交叉验证得分\", linewidth=2, markersize=8)\nplt.xlabel(\"最小分裂样本数 (min_samples_split)\", fontsize=12)\nplt.ylabel(\"准确率\", fontsize=12)\nplt.title(\"决策树不同 min_samples_split 的学习曲线\", fontsize=14)\nplt.legend(fontsize=11)\nplt.grid(True, alpha=0.3)\nplt.tight_layout()\nplt.show()\n\n# 选择最佳 min_samples_split\nbest_min_samples_split = min_samples_splits[cv_scores.index(max(cv_scores))]\nprint(f\"最佳 min_samples_split: {best_min_samples_split}\")\nprint(f\"交叉验证准确率: {max(cv_scores):.4f}\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n==================================================\n2. 调优 min_samples_split 参数\n==================================================\n```\n:::\n\n::: {.cell-output .cell-output-display}\n![](w4_practice_files/figure-html/cell-9-output-2.png){width=951 height=566}\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n最佳 min_samples_split: 2\n交叉验证准确率: 0.8129\n```\n:::\n:::\n\n\n::: {#308b5155 .cell message='false' execution_count=9}\n``` {.python .cell-code}\n# 超参数调优：3. 调优 min_samples_leaf 参数\nprint(\"=\" * 50)\nprint(\"3. 调优 min_samples_leaf 参数\")\nprint(\"=\" * 50)\n\nmin_samples_leafs = [1, 2, 3, 4, 5, 8, 10, 15, 20, 25, 30]\ntrain_scores = []\ncv_scores = []\n\nfor min_samples in min_samples_leafs:\n    dt = DecisionTreeClassifier(\n        max_depth=best_max_depth,\n        min_samples_split=best_min_samples_split,\n        min_samples_leaf=min_samples,\n        random_state=42\n    )\n    # 交叉验证得分\n    cv_score = cross_val_score(dt, X_train, y_train, cv=5, scoring=\"accuracy\").mean()\n    cv_scores.append(cv_score)\n    # 训练集得分\n    dt.fit(X_train, y_train)\n    train_scores.append(dt.score(X_train, y_train))\n\n# 绘制学习曲线\nplt.figure(figsize=(10, 6))\nplt.plot(min_samples_leafs, train_scores, \"o-\", label=\"训练集得分\", linewidth=2, markersize=8)\nplt.plot(min_samples_leafs, cv_scores, \"o-\", label=\"交叉验证得分\", linewidth=2, markersize=8)\nplt.xlabel(\"最小叶节点样本数 (min_samples_leaf)\", fontsize=12)\nplt.ylabel(\"准确率\", fontsize=12)\nplt.title(\"决策树不同 min_samples_leaf 的学习曲线\", fontsize=14)\nplt.legend(fontsize=11)\nplt.grid(True, alpha=0.3)\nplt.tight_layout()\nplt.show()\n\n# 选择最佳 min_samples_leaf\nbest_min_samples_leaf = min_samples_leafs[cv_scores.index(max(cv_scores))]\nprint(f\"最佳 min_samples_leaf: {best_min_samples_leaf}\")\nprint(f\"交叉验证准确率: {max(cv_scores):.4f}\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n==================================================\n3. 调优 min_samples_leaf 参数\n==================================================\n```\n:::\n\n::: {.cell-output .cell-output-display}\n![](w4_practice_files/figure-html/cell-10-output-2.png){width=951 height=566}\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n最佳 min_samples_leaf: 1\n交叉验证准确率: 0.8129\n```\n:::\n:::\n\n\n::: {#2f047090 .cell message='false' execution_count=10}\n``` {.python .cell-code}\n# 训练最终模型\nprint(\"=\" * 50)\nprint(\"使用最佳参数训练最终模型\")\nprint(\"=\" * 50)\n\nbest_dt = DecisionTreeClassifier(\n    max_depth=best_max_depth,\n    min_samples_split=best_min_samples_split,\n    min_samples_leaf=best_min_samples_leaf,\n    random_state=42\n)\n\nbest_dt.fit(X_train, y_train)\n\n# 在训练集和测试集上评估\ntrain_accuracy = best_dt.score(X_train, y_train)\ntest_accuracy = best_dt.score(X_test, y_test)\n\nprint(f\"最终模型参数:\")\nprint(f\"  max_depth: {best_max_depth}\")\nprint(f\"  min_samples_split: {best_min_samples_split}\")\nprint(f\"  min_samples_leaf: {best_min_samples_leaf}\")\nprint(f\"\\n训练集准确率: {train_accuracy:.4f}\")\nprint(f\"测试集准确率: {test_accuracy:.4f}\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n==================================================\n使用最佳参数训练最终模型\n==================================================\n最终模型参数:\n  max_depth: 4\n  min_samples_split: 2\n  min_samples_leaf: 1\n\n训练集准确率: 0.8298\n测试集准确率: 0.8090\n```\n:::\n:::\n\n\n## 模型评估（混淆矩阵/准确率/精确率/召回率/F1/ROC/AUC）\n\n**为什么需要多种评估指标？**\n\n准确率虽然直观，但有时会产生误导：\n- **不平衡数据集**：如果 95% 的样本是类别 A，那么一个\"傻瓜模型\"（总是预测 A）也能达到 95% 准确率\n- **不同错误成本**：在医疗诊断中，漏诊和误诊的代价不同；在垃圾邮件分类中，错过垃圾邮件 vs 误删正常邮件的代价不同\n\n**分类问题的四个基本概念：**\n\n- **真正例 (TP)**：正确预测为正例\n- **真反例 (TN)**：正确预测为反例\n- **假正例 (FP)**：错误预测为正例（第一类错误）\n- **假反例 (FN)**：错误预测为反例（第二类错误）\n\n**常用评估指标：**\n\n- **准确率 (Accuracy)** = (TP + TN) / (TP + TN + FP + FN)\n- **精确率 (Precision)** = TP / (TP + FP) —— 在预测为正例的样本中，真正正例的比例\n- **召回率 (Recall)** = TP / (TP + FN) —— 在所有真正正例中，被正确预测的比例\n- **F1 分数** = 2 × Precision × Recall / (Precision + Recall) —— 精确率和召回率的调和平均\n\n**ROC 曲线和 AUC：**\n\n- **ROC 曲线**：以假正例率(FPR)为横轴，真正例率(TPR)为纵轴绘制的曲线\n- **AUC**：ROC 曲线下的面积，AUC 越大，模型性能越好\n\n::: {#233a1ff3 .cell message='false' execution_count=11}\n``` {.python .cell-code}\n# 预测测试集\ny_pred = best_dt.predict(X_test)\ny_pred_proba = best_dt.predict_proba(X_test)[:, 1]  # 预测为正例的概率\n\n# 1. 混淆矩阵\ncm = confusion_matrix(y_test, y_pred)\nprint(\"=\" * 50)\nprint(\"1. 混淆矩阵\")\nprint(\"=\" * 50)\nprint(\"混淆矩阵:\")\nprint(cm)\nprint(f\"\\n真正例 (TP): {cm[1,1]} - 正确预测存活\")\nprint(f\"真反例 (TN): {cm[0,0]} - 正确预测死亡\")\nprint(f\"假正例 (FP): {cm[0,1]} - 错误预测存活（实际死亡）\")\nprint(f\"假反例 (FN): {cm[1,0]} - 错误预测死亡（实际存活）\")\n\n# 可视化混淆矩阵\nplt.figure(figsize=(6, 5))\ndisp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=['死亡', '存活'])\ndisp.plot(cmap='Blues', ax=plt.gca())\nplt.title('决策树模型混淆矩阵', fontsize=14)\nplt.grid(False)\nplt.show()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n==================================================\n1. 混淆矩阵\n==================================================\n混淆矩阵:\n[[100  10]\n [ 24  44]]\n\n真正例 (TP): 44 - 正确预测存活\n真反例 (TN): 100 - 正确预测死亡\n假正例 (FP): 10 - 错误预测存活（实际死亡）\n假反例 (FN): 24 - 错误预测死亡（实际存活）\n```\n:::\n\n::: {.cell-output .cell-output-display}\n![](w4_practice_files/figure-html/cell-12-output-2.png){width=495 height=439}\n:::\n:::\n\n\n::: {#4c51527d .cell message='false' execution_count=12}\n``` {.python .cell-code}\n# 2. 分类报告：包含多种评估指标\nprint(\"=\" * 50)\nprint(\"2. 详细评估指标\")\nprint(\"=\" * 50)\nprint(\"分类报告:\")\nprint(classification_report(y_test, y_pred, target_names=['死亡', '存活']))\n\n# 手动计算各项指标\naccuracy = accuracy_score(y_test, y_pred)\nprecision = precision_score(y_test, y_pred)\nrecall = recall_score(y_test, y_pred)\nf1 = f1_score(y_test, y_pred)\n\nprint(\"=\" * 50)\nprint(\"关键指标总结:\")\nprint(\"=\" * 50)\nprint(f\"准确率 (Accuracy): {accuracy:.4f} - 整体预测正确的比例\")\nprint(f\"精确率 (Precision): {precision:.4f} - 预测存活者中真正存活的比例\")\nprint(f\"召回率 (Recall): {recall:.4f} - 实际存活者中被正确预测的比例\")\nprint(f\"F1 分数: {f1:.4f} - 精确率和召回率的调和平均\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n==================================================\n2. 详细评估指标\n==================================================\n分类报告:\n              precision    recall  f1-score   support\n\n          死亡       0.81      0.91      0.85       110\n          存活       0.81      0.65      0.72        68\n\n    accuracy                           0.81       178\n   macro avg       0.81      0.78      0.79       178\nweighted avg       0.81      0.81      0.80       178\n\n==================================================\n关键指标总结:\n==================================================\n准确率 (Accuracy): 0.8090 - 整体预测正确的比例\n精确率 (Precision): 0.8148 - 预测存活者中真正存活的比例\n召回率 (Recall): 0.6471 - 实际存活者中被正确预测的比例\nF1 分数: 0.7213 - 精确率和召回率的调和平均\n```\n:::\n:::\n\n\n::: {#513ba177 .cell message='false' execution_count=13}\n``` {.python .cell-code}\n# 3. ROC 曲线和 AUC\nfpr, tpr, thresholds = roc_curve(y_test, y_pred_proba)\nroc_auc = auc(fpr, tpr)\n\nplt.figure(figsize=(8, 6))\nplt.plot(fpr, tpr, color='darkorange', linewidth=2, label=f'ROC 曲线 (AUC = {roc_auc:.4f})')\nplt.plot([0, 1], [0, 1], color='navy', linewidth=2, linestyle='--', label='随机猜测')\nplt.xlim([0.0, 1.0])\nplt.ylim([0.0, 1.05])\nplt.xlabel('假正例率 (FPR)', fontsize=12)\nplt.ylabel('真正例率 (TPR)', fontsize=12)\nplt.title('ROC 曲线 - 决策树模型', fontsize=14)\nplt.legend(loc=\"lower right\", fontsize=11)\nplt.grid(True, alpha=0.3)\nplt.show()\n\nprint(\"=\" * 50)\nprint(\"ROC 曲线分析\")\nprint(\"=\" * 50)\nprint(f\"AUC 值: {roc_auc:.4f}\")\nprint(\"\\nAUC 解读:\")\nprint(\"- AUC = 1.0: 完美模型\")\nprint(\"- AUC = 0.5: 随机猜测\")\nprint(\"- AUC < 0.5: 比随机猜测还差\")\nprint(f\"- 我们的模型 AUC = {roc_auc:.4f}，说明模型性能 {(roc_auc-0.5)/0.5*100:.1f}% 优于随机猜测\")\n```\n\n::: {.cell-output .cell-output-display}\n![](w4_practice_files/figure-html/cell-14-output-1.png){width=676 height=528}\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n==================================================\nROC 曲线分析\n==================================================\nAUC 值: 0.8560\n\nAUC 解读:\n- AUC = 1.0: 完美模型\n- AUC = 0.5: 随机猜测\n- AUC < 0.5: 比随机猜测还差\n- 我们的模型 AUC = 0.8560，说明模型性能 71.2% 优于随机猜测\n```\n:::\n:::\n\n\n::: {#b95da318 .cell message='false' execution_count=14}\n``` {.python .cell-code}\n# 4. 特征重要性分析\nfeature_importance = pd.DataFrame({\n    'feature': features,\n    'importance': best_dt.feature_importances_\n}).sort_values('importance', ascending=False)\n\nprint(\"=\" * 50)\nprint(\"4. 特征重要性分析\")\nprint(\"=\" * 50)\nprint(\"各特征对预测存活的重要性:\")\nfor idx, row in feature_importance.iterrows():\n    print(f\"{row['feature']:12s}: {row['importance']:.4f}\")\n\n# 可视化特征重要性\nplt.figure(figsize=(10, 6))\ncolors = plt.cm.viridis(np.linspace(0, 1, len(feature_importance)))\nbars = plt.barh(feature_importance['feature'], feature_importance['importance'], color=colors)\nplt.xlabel('重要性分数', fontsize=12)\nplt.ylabel('特征', fontsize=12)\nplt.title('决策树特征重要性', fontsize=14)\nplt.grid(True, alpha=0.3, axis='x')\n\n# 添加数值标签\nfor bar, importance in zip(bars, feature_importance['importance']):\n    plt.text(bar.get_width() + 0.001, bar.get_y() + bar.get_height()/2,\n             f'{importance:.3f}', ha='left', va='center', fontsize=10)\n\nplt.tight_layout()\nplt.show()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n==================================================\n4. 特征重要性分析\n==================================================\n各特征对预测存活的重要性:\nSex         : 0.6121\nPclass      : 0.1842\nAge         : 0.0881\nFare        : 0.0711\nEmbarked_Q  : 0.0222\nSibSp       : 0.0123\nParch       : 0.0100\nEmbarked_S  : 0.0000\n```\n:::\n\n::: {.cell-output .cell-output-display}\n![](w4_practice_files/figure-html/cell-15-output-2.png){width=947 height=566}\n:::\n:::\n\n\n::: {#bbabf9c0 .cell message='false' execution_count=15}\n``` {.python .cell-code}\n# 保存模型和结果（供 W5 使用）\nimport pickle\n\n# 保存决策树模型\nwith open('titanic_results/dt_model_w4.pkl', 'wb') as f:\n    pickle.dump(best_dt, f)\n\n# 保存评估结果\ndt_results = {\n    'accuracy': accuracy,\n    'precision': precision,\n    'recall': recall,\n    'f1': f1,\n    'roc_auc': roc_auc\n}\n\nwith open('titanic_results/dt_results_w4.pkl', 'wb') as f:\n    pickle.dump(dt_results, f)\n\nprint(\"\\n✅ 已保存决策树模型和结果到本地文件：\")\nprint(\"   dt_model_w4.pkl - 决策树模型\")\nprint(\"   dt_results_w4.pkl - 评估结果\")\nprint(f\"\\n模型性能摘要:\")\nprint(f\"   准确率: {accuracy:.4f}\")\nprint(f\"   AUC: {roc_auc:.4f}\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\n✅ 已保存决策树模型和结果到本地文件：\n   dt_model_w4.pkl - 决策树模型\n   dt_results_w4.pkl - 评估结果\n\n模型性能摘要:\n   准确率: 0.8090\n   AUC: 0.8560\n```\n:::\n:::\n\n\n## 总结与实战经验\n\n**本次课程的核心内容：**\n\n1. **分类问题基础**\n   - 理解二分类问题的基本概念\n   - 掌握 Titanic 数据集的特点和预处理方法\n\n2. **探索性数据分析**\n   - 通过可视化理解数据分布和特征关系\n   - 发现性别、舱位等级等关键特征的影响\n\n3. **决策树算法**\n   - 理解决策树的工作原理和优势\n   - 掌握超参数调优的方法（max_depth, min_samples_split, min_samples_leaf）\n\n4. **模型评估体系**\n   - 混淆矩阵：理解预测结果的四种情况\n   - 准确率/精确率/召回率/F1：从不同角度评估模型\n   - ROC/AUC：评估模型的整体性能\n\n5. **特征重要性**\n   - 理解哪些特征对预测最重要\n   - 为特征选择和工程提供指导\n\n**实战经验总结：**\n\n- ✅ **EDA 很重要**：可视化分析能帮我们发现数据中的关键模式\n- ✅ **数据预处理**：缺失值处理和特征编码是机器学习的基础\n- ✅ **超参数调优**：通过交叉验证找到最佳参数，避免过拟合\n- ✅ **评估指标多样化**：不要只看准确率，要根据业务场景选择合适的指标\n- ✅ **特征重要性分析**：理解模型的决策逻辑，提高可解释性\n- ✅ **调参是必要的**：通过交叉验证找到最佳参数组合\n- ✅ **可解释性很重要**：决策树的优势在于易于理解和解释\n\n",
    "supporting": [
      "w4_practice_files/figure-html"
    ],
    "filters": [],
    "includes": {}
  }
}