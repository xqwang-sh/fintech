---
title: ç¬¬äº”è®²ä¸Šæœºå®è·µ
---

æœ¬ä¸Šæœºè®²ä¹‰è¦†ç›–ä»¥ä¸‹å†…å®¹ï¼š

- è¯»å– Titanic é¢„å¤„ç†åçš„æ•°æ®
- éšæœºæ£®æ—æ¨¡å‹è®­ç»ƒä¸è¶…å‚æ•°è°ƒä¼˜
- GBDTï¼ˆLightGBMï¼‰æ¨¡å‹è®­ç»ƒä¸è¶…å‚æ•°è°ƒä¼˜
- ä¸‰æ¨¡å‹å¯¹æ¯”ï¼šå†³ç­–æ ‘ vs éšæœºæ£®æ— vs GBDT

**å­¦ä¹ ç›®æ ‡**ï¼š

- ç†è§£éšæœºæ£®æ—çš„å·¥ä½œåŸç†å’Œä¼˜åŠ¿
- æŒæ¡ GBDTï¼ˆæ¢¯åº¦æå‡æ ‘ï¼‰çš„åŸºæœ¬æ¦‚å¿µ
- å­¦ä¼šä½¿ç”¨ GridSearchCV è¿›è¡Œè¶…å‚æ•°è°ƒä¼˜
- æ¯”è¾ƒä¸åŒé›†æˆå­¦ä¹ æ–¹æ³•çš„æ€§èƒ½

**æ•°æ®æ¥æº**ï¼š`titanic_data/features_processed.csv` å’Œ `titanic_data/labels_processed.csv`ï¼ˆæ¥è‡ª W4 çš„é¢„å¤„ç†ç»“æœï¼‰

```{python}
# å¯¼å…¥æ‰€éœ€åº“
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import pickle

from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import (accuracy_score, precision_score, recall_score, f1_score,
                             roc_auc_score, roc_curve, auc, classification_report)

import lightgbm as lgb

# è®¾ç½®ä¸­æ–‡æ˜¾ç¤º
plt.rcParams['font.sans-serif'] = ['SimHei']
plt.rcParams['axes.unicode_minus'] = False
%matplotlib inline
```

## æ•°æ®å‡†å¤‡

**è¯´æ˜**ï¼šæˆ‘ä»¬ä½¿ç”¨ W3 é¢„å¤„ç†åçš„æ•°æ®ï¼Œç›´æ¥åŠ è½½å³å¯ã€‚æ•°æ®å·²ç»å®Œæˆï¼š

- ç¼ºå¤±å€¼å¤„ç†
- ç‰¹å¾ç¼–ç ï¼ˆSex æ ‡ç­¾ç¼–ç ï¼ŒEmbarked ç‹¬çƒ­ç¼–ç ï¼‰
- ç‰¹å¾é€‰æ‹©

**æ³¨æ„**ï¼šæ•°æ®åˆ†å‰²çš„ random_state éœ€è¦ä¸ W3 ä¿æŒä¸€è‡´ï¼ˆrandom_state=42ï¼‰ï¼Œè¿™æ ·æ‰èƒ½ä½¿ç”¨ç›¸åŒçš„æµ‹è¯•é›†è¿›è¡Œå…¬å¹³å¯¹æ¯”ã€‚

```{python}
# è¯»å– W4 é¢„å¤„ç†åçš„æ•°æ®
X = pd.read_csv('titanic_data/features_processed.csv')
y = pd.read_csv('titanic_data/labels_processed.csv')

# æ•°æ®åˆ†å‰²ï¼ˆä¸ W4 ä¿æŒä¸€è‡´ï¼‰
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42, stratify=y
)

print(f"è®­ç»ƒé›†å½¢çŠ¶: {X_train.shape}")
print(f"æµ‹è¯•é›†å½¢çŠ¶: {X_test.shape}")
print(f"ç‰¹å¾åˆ—è¡¨: {list(X.columns)}")
print(f"è®­ç»ƒé›†å­˜æ´»ç‡: {y_train.mean().values[0]:.3f}")
print(f"æµ‹è¯•é›†å­˜æ´»ç‡: {y_test.mean().values[0]:.3f}")

# åŠ è½½ W4 çš„å†³ç­–æ ‘æ¨¡å‹å’Œç»“æœ
try:
    with open('titanic_results/dt_model_w4.pkl', 'rb') as f:
        dt_model_w4 = pickle.load(f)
    with open('titanic_results/dt_results_w4.pkl', 'rb') as f:
        dt_results_w4 = pickle.load(f)
    print("\nâœ… æˆåŠŸåŠ è½½ W4 çš„å†³ç­–æ ‘æ¨¡å‹å’Œç»“æœ")
except FileNotFoundError:
    print("\nâš ï¸  æœªæ‰¾åˆ° W4 çš„æ¨¡å‹æ–‡ä»¶ï¼Œå°†åœ¨åç»­é‡æ–°è®­ç»ƒå†³ç­–æ ‘")
    dt_model_w4 = None
    dt_results_w4 = None
```

## éšæœºæ£®æ—æ¨¡å‹è®­ç»ƒä¸è¶…å‚æ•°è°ƒä¼˜

**éšæœºæ£®æ—ç®€ä»‹**ï¼š

éšæœºæ£®æ—æ˜¯ä¸€ç§é›†æˆå­¦ä¹ æ–¹æ³•ï¼Œé€šè¿‡ç»„åˆå¤šä¸ªå†³ç­–æ ‘æ¥æå‡é¢„æµ‹æ€§èƒ½ï¼š

- **Baggingï¼ˆè‡ªåŠ©é‡‡æ ·ï¼‰**ï¼šæ¯ä¸ªæ ‘ä½¿ç”¨ä¸åŒçš„è®­ç»ƒå­é›†
- **ç‰¹å¾éšæœºæ€§**ï¼šæ¯ä¸ªåˆ†è£‚æ—¶éšæœºé€‰æ‹©éƒ¨åˆ†ç‰¹å¾
- **ä¼˜åŠ¿**ï¼šå‡å°‘è¿‡æ‹Ÿåˆï¼Œæé«˜æ³›åŒ–èƒ½åŠ›

**ä¸»è¦è¶…å‚æ•°**ï¼š

- **n_estimators**ï¼šæ£®æ—ä¸­æ ‘çš„æ•°é‡ï¼ˆè¶Šå¤šè¶Šå¥½ï¼Œä½†è®¡ç®—æˆæœ¬å¢åŠ ï¼‰
- **max_depth**ï¼šæ¯æ£µæ ‘çš„æœ€å¤§æ·±åº¦
- **min_samples_split**ï¼šåˆ†è£‚å†…éƒ¨èŠ‚ç‚¹æ‰€éœ€çš„æœ€å°æ ·æœ¬æ•°
- **min_samples_leaf**ï¼šå¶èŠ‚ç‚¹æ‰€éœ€çš„æœ€å°æ ·æœ¬æ•°
- **max_features**ï¼šå¯»æ‰¾æœ€ä½³åˆ†è£‚æ—¶è€ƒè™‘çš„ç‰¹å¾æ•°é‡

```{python}
# éšæœºæ£®æ—ï¼šè¶…å‚æ•°è°ƒä¼˜ï¼ˆä½¿ç”¨ GridSearchCVï¼‰
print("\n" + "=" * 60)
print("éšæœºæ£®æ—è¶…å‚æ•°è°ƒä¼˜")
print("=" * 60)

# å®šä¹‰å‚æ•°ç½‘æ ¼
param_grid_rf = {
    'n_estimators': [50, 100, 200],
    'max_depth': [5, 10, None],
    'min_samples_split': [2, 5, 10],
    'min_samples_leaf': [1, 2, 4],
    'max_features': ['sqrt', 'log2']
}

# ä½¿ç”¨ GridSearchCV è¿›è¡Œç½‘æ ¼æœç´¢
rf_model = RandomForestClassifier(random_state=42)
rf_grid = GridSearchCV(
    rf_model,
    param_grid_rf,
    cv=5,
    scoring='roc_auc',
    n_jobs=-1,
    verbose=1
)

print("\nå¼€å§‹ç½‘æ ¼æœç´¢...")
rf_grid.fit(X_train, y_train)

print(f"\nâœ… éšæœºæ£®æ—æœ€ä½³å‚æ•°: {rf_grid.best_params_}")
print(f"âœ… æœ€ä½³äº¤å‰éªŒè¯ AUC: {rf_grid.best_score_:.4f}")

# ä½¿ç”¨æœ€ä½³å‚æ•°è®­ç»ƒæœ€ç»ˆæ¨¡å‹
rf_best = rf_grid.best_estimator_

# åœ¨æµ‹è¯•é›†ä¸Šè¯„ä¼°
y_pred_rf = rf_best.predict(X_test)
y_prob_rf = rf_best.predict_proba(X_test)[:, 1]

rf_accuracy = accuracy_score(y_test, y_pred_rf)
rf_precision = precision_score(y_test, y_pred_rf)
rf_recall = recall_score(y_test, y_pred_rf)
rf_f1 = f1_score(y_test, y_pred_rf)
rf_auc = roc_auc_score(y_test, y_prob_rf)

print(f"\nğŸ“Š éšæœºæ£®æ—æµ‹è¯•é›†æ€§èƒ½:")
print(f"  å‡†ç¡®ç‡: {rf_accuracy:.4f}")
print(f"  ç²¾ç¡®ç‡: {rf_precision:.4f}")
print(f"  å¬å›ç‡: {rf_recall:.4f}")
print(f"  F1åˆ†æ•°: {rf_f1:.4f}")
print(f"  AUC: {rf_auc:.4f}")
```

```{python}
# éšæœºæ£®æ—ï¼šç‰¹å¾é‡è¦æ€§å¯è§†åŒ–
importances_rf = rf_best.feature_importances_
indices_rf = np.argsort(importances_rf)[::-1]

plt.figure(figsize=(10, 6))
plt.barh(range(len(importances_rf)), importances_rf[indices_rf], color='skyblue')
plt.yticks(range(len(importances_rf)), [X.columns[i] for i in indices_rf])
plt.xlabel('ç‰¹å¾é‡è¦æ€§', fontsize=12)
plt.title('éšæœºæ£®æ—ç‰¹å¾é‡è¦æ€§æ’åº', fontsize=14)
plt.gca().invert_yaxis()  # æœ€é‡è¦çš„åœ¨é¡¶éƒ¨
plt.grid(axis='x', alpha=0.3)
plt.tight_layout()
plt.show()

# æ‰“å°ç‰¹å¾é‡è¦æ€§
print("\néšæœºæ£®æ—ç‰¹å¾é‡è¦æ€§ï¼ˆä»é«˜åˆ°ä½ï¼‰:")
for i in indices_rf:
    print(f"  {X.columns[i]}: {importances_rf[i]:.4f}")
```

## GBDTï¼ˆLightGBMï¼‰æ¨¡å‹è®­ç»ƒä¸è¶…å‚æ•°è°ƒä¼˜

**GBDTï¼ˆæ¢¯åº¦æå‡å†³ç­–æ ‘ï¼‰ç®€ä»‹**ï¼š

GBDT æ˜¯ä¸€ç§å¼ºå¤§çš„é›†æˆå­¦ä¹ æ–¹æ³•ï¼Œé€šè¿‡é€æ­¥ä¿®æ­£å‰ä¸€è½®çš„é”™è¯¯æ¥æå‡æ€§èƒ½ï¼š

- **Boostingï¼ˆæå‡ï¼‰**ï¼šå¼±å­¦ä¹ å™¨é€æ­¥æ”¹è¿›
- **æ¢¯åº¦ä¸‹é™**ï¼šä½¿ç”¨æ¢¯åº¦ä¿¡æ¯ä¼˜åŒ–æŸå¤±å‡½æ•°
- **LightGBM ä¼˜åŠ¿**ï¼šé€Ÿåº¦å¿«ã€å†…å­˜æ•ˆç‡é«˜ï¼Œæ”¯æŒå¤§è§„æ¨¡æ•°æ®

**ä¸»è¦è¶…å‚æ•°**ï¼š

- **n_estimators**ï¼šæå‡è½®æ•°
- **learning_rate**ï¼šå­¦ä¹ ç‡ï¼ˆæ§åˆ¶æ¯è½®çš„å½±å“ï¼‰
- **max_depth**ï¼šæ ‘çš„æœ€å¤§æ·±åº¦
- **num_leaves**ï¼šå¶å­èŠ‚ç‚¹æ•°é‡ï¼ˆLightGBM ç‰¹æœ‰ï¼‰
- **min_child_samples**ï¼šå¶èŠ‚ç‚¹çš„æœ€å°æ ·æœ¬æ•°

**è¶…å‚æ•°è°ƒä¼˜ç­–ç•¥**ï¼š

å‚è€ƒ `lab03_titanic.py`ï¼Œæˆ‘ä»¬ä½¿ç”¨ GridSearchCV è¿›è¡Œç½‘æ ¼æœç´¢ï¼š

- **n_estimators**ï¼šæ ‘çš„æ•°é‡
- **learning_rate**ï¼šå­¦ä¹ ç‡ï¼ˆæ§åˆ¶æ¯æ£µæ ‘çš„å½±å“ï¼‰
- **max_depth**ï¼šæ ‘çš„æœ€å¤§æ·±åº¦
- **num_leaves**ï¼šå¶å­èŠ‚ç‚¹æ•°é‡ï¼ˆLightGBM ç‰¹æœ‰ï¼‰
- **min_child_samples**ï¼šå¶èŠ‚ç‚¹çš„æœ€å°æ ·æœ¬æ•°

```{python}
# GBDTï¼ˆLightGBMï¼‰ï¼šè¶…å‚æ•°è°ƒä¼˜ï¼ˆä½¿ç”¨ GridSearchCVï¼‰
print("\n" + "=" * 60)
print("GBDT (LightGBM) è¶…å‚æ•°è°ƒä¼˜")
print("=" * 60)

# å®šä¹‰å‚æ•°ç½‘æ ¼ï¼ˆå‚è€ƒ lab03_titanic.py ä¸­çš„ XGBoost è°ƒå‚ï¼‰
param_grid_gbm = {
    'n_estimators': [50, 100, 200],
    'learning_rate': [0.01, 0.05, 0.1, 0.2],
    'max_depth': [3, 5, 7],
    'num_leaves': [15, 31, 63],  # LightGBM ç‰¹æœ‰å‚æ•°
    'min_child_samples': [10, 20, 30]
}

# ä½¿ç”¨ GridSearchCV è¿›è¡Œç½‘æ ¼æœç´¢
gbm_model = lgb.LGBMClassifier(random_state=42, verbosity=-1)
gbm_grid = GridSearchCV(
    gbm_model,
    param_grid_gbm,
    cv=5,
    scoring='roc_auc',
    n_jobs=-1,
    verbose=1
)

print("\nå¼€å§‹ç½‘æ ¼æœç´¢...")
gbm_grid.fit(X_train, y_train)

print(f"\nâœ… GBDT æœ€ä½³å‚æ•°: {gbm_grid.best_params_}")
print(f"âœ… æœ€ä½³äº¤å‰éªŒè¯ AUC: {gbm_grid.best_score_:.4f}")

# ä½¿ç”¨æœ€ä½³å‚æ•°è®­ç»ƒæœ€ç»ˆæ¨¡å‹
gbm_best = gbm_grid.best_estimator_

# åœ¨æµ‹è¯•é›†ä¸Šè¯„ä¼°
y_pred_gbm = gbm_best.predict(X_test)
y_prob_gbm = gbm_best.predict_proba(X_test)[:, 1]

gbm_accuracy = accuracy_score(y_test, y_pred_gbm)
gbm_precision = precision_score(y_test, y_pred_gbm)
gbm_recall = recall_score(y_test, y_pred_gbm)
gbm_f1 = f1_score(y_test, y_pred_gbm)
gbm_auc = roc_auc_score(y_test, y_prob_gbm)

print(f"\nğŸ“Š GBDT æµ‹è¯•é›†æ€§èƒ½:")
print(f"  å‡†ç¡®ç‡: {gbm_accuracy:.4f}")
print(f"  ç²¾ç¡®ç‡: {gbm_precision:.4f}")
print(f"  å¬å›ç‡: {gbm_recall:.4f}")
print(f"  F1åˆ†æ•°: {gbm_f1:.4f}")
print(f"  AUC: {gbm_auc:.4f}")
```

```{python}
# GBDTï¼šç‰¹å¾é‡è¦æ€§å¯è§†åŒ–
importances_gbm = gbm_best.feature_importances_
indices_gbm = np.argsort(importances_gbm)[::-1]

plt.figure(figsize=(10, 6))
plt.barh(range(len(importances_gbm)), importances_gbm[indices_gbm], color='lightgreen')
plt.yticks(range(len(importances_gbm)), [X.columns[i] for i in indices_gbm])
plt.xlabel('ç‰¹å¾é‡è¦æ€§', fontsize=12)
plt.title('GBDT (LightGBM) ç‰¹å¾é‡è¦æ€§æ’åº', fontsize=14)
plt.gca().invert_yaxis()  # æœ€é‡è¦çš„åœ¨é¡¶éƒ¨
plt.grid(axis='x', alpha=0.3)
plt.tight_layout()
plt.show()

# æ‰“å°ç‰¹å¾é‡è¦æ€§
print("\nGBDT ç‰¹å¾é‡è¦æ€§ï¼ˆä»é«˜åˆ°ä½ï¼‰:")
for i in indices_gbm:
    print(f"  {X.columns[i]}: {importances_gbm[i]:.4f}")
```

## ä¸‰æ¨¡å‹å¯¹æ¯”ï¼šå†³ç­–æ ‘ vs éšæœºæ£®æ— vs GBDT

**å¯¹æ¯”è¯´æ˜**ï¼š

æˆ‘ä»¬å°†æ¯”è¾ƒä¸‰ä¸ªæ¨¡å‹çš„æ€§èƒ½ï¼š

1. **å†³ç­–æ ‘**ï¼šæ¥è‡ª W3 çš„è®­ç»ƒç»“æœï¼ˆæˆ–é‡æ–°è¯„ä¼°ï¼‰
2. **éšæœºæ£®æ—**ï¼šä½¿ç”¨ GridSearchCV æ‰¾åˆ°çš„æœ€ä½³å‚æ•°
3. **GBDT (LightGBM)**ï¼šä½¿ç”¨ GridSearchCV æ‰¾åˆ°çš„æœ€ä½³å‚æ•°

**å¯¹æ¯”æŒ‡æ ‡**ï¼š

- å‡†ç¡®ç‡ (Accuracy)
- ç²¾ç¡®ç‡ (Precision)
- å¬å›ç‡ (Recall)
- F1 åˆ†æ•°
- AUCï¼ˆROC æ›²çº¿ä¸‹é¢ç§¯ï¼‰

```{python}
# ä¸‰æ¨¡å‹å¯¹æ¯”ï¼šå†³ç­–æ ‘ vs éšæœºæ£®æ— vs GBDT
print("\n" + "=" * 60)
print("ä¸‰æ¨¡å‹æ€§èƒ½å¯¹æ¯”")
print("=" * 60)

# å¦‚æœ W4 çš„æ¨¡å‹å·²åŠ è½½ï¼Œä½¿ç”¨å…¶ç»“æœï¼›å¦åˆ™é‡æ–°è¯„ä¼°
if dt_model_w4 is not None and dt_results_w4 is not None:
    dt_accuracy = dt_results_w4['accuracy']
    dt_precision = dt_results_w4['precision']
    dt_recall = dt_results_w4['recall']
    dt_f1 = dt_results_w4['f1']
    dt_auc = dt_results_w4['roc_auc']
    print("âœ… ä½¿ç”¨ W4 ä¿å­˜çš„å†³ç­–æ ‘ç»“æœ")
else:
    # é‡æ–°è¯„ä¼°å†³ç­–æ ‘ï¼ˆä½¿ç”¨ W4 çš„æœ€ä½³å‚æ•°æˆ–é»˜è®¤å‚æ•°ï¼‰
    print("âš ï¸  é‡æ–°è®­ç»ƒå†³ç­–æ ‘...")
    dt_temp = DecisionTreeClassifier(max_depth=5, random_state=42)
    dt_temp.fit(X_train, y_train)
    y_pred_dt = dt_temp.predict(X_test)
    y_prob_dt = dt_temp.predict_proba(X_test)[:, 1]
    dt_accuracy = accuracy_score(y_test, y_pred_dt)
    dt_precision = precision_score(y_test, y_pred_dt)
    dt_recall = recall_score(y_test, y_pred_dt)
    dt_f1 = f1_score(y_test, y_pred_dt)
    dt_auc = roc_auc_score(y_test, y_prob_dt)

# åˆ›å»ºå¯¹æ¯”è¡¨æ ¼
comparison_data = {
    'æ¨¡å‹': ['å†³ç­–æ ‘', 'éšæœºæ£®æ—', 'GBDT (LightGBM)'],
    'å‡†ç¡®ç‡': [dt_accuracy, rf_accuracy, gbm_accuracy],
    'ç²¾ç¡®ç‡': [dt_precision, rf_precision, gbm_precision],
    'å¬å›ç‡': [dt_recall, rf_recall, gbm_recall],
    'F1åˆ†æ•°': [dt_f1, rf_f1, gbm_f1],
    'AUC': [dt_auc, rf_auc, gbm_auc]
}

comparison_df = pd.DataFrame(comparison_data)
print("\nğŸ“Š æ¨¡å‹æ€§èƒ½å¯¹æ¯”è¡¨:")
print(comparison_df.round(4))

# å¯è§†åŒ–å¯¹æ¯”
fig, axes = plt.subplots(2, 3, figsize=(18, 10))

metrics = ['å‡†ç¡®ç‡', 'ç²¾ç¡®ç‡', 'å¬å›ç‡', 'F1åˆ†æ•°', 'AUC']
colors = ['#3498db', '#2ecc71', '#e74c3c']

for i, metric in enumerate(metrics):
    row = i // 3
    col = i % 3
    axes[row, col].bar(comparison_df['æ¨¡å‹'], comparison_df[metric], color=colors)
    axes[row, col].set_title(f'{metric} å¯¹æ¯”', fontsize=12, fontweight='bold')
    axes[row, col].set_ylabel(metric, fontsize=11)
    axes[row, col].set_ylim([0, 1])
    axes[row, col].grid(axis='y', alpha=0.3)
    # æ·»åŠ æ•°å€¼æ ‡ç­¾
    for j, v in enumerate(comparison_df[metric]):
        axes[row, col].text(j, v + 0.01, f'{v:.3f}', ha='center', fontsize=10)

# æœ€åä¸€ä¸ªå­å›¾ï¼šAUC å¯¹æ¯”ï¼ˆçªå‡ºæ˜¾ç¤ºï¼‰
axes[1, 2].bar(comparison_df['æ¨¡å‹'], comparison_df['AUC'], color=colors)
axes[1, 2].set_title('AUC å¯¹æ¯”ï¼ˆæ ¸å¿ƒæŒ‡æ ‡ï¼‰', fontsize=12, fontweight='bold')
axes[1, 2].set_ylabel('AUC', fontsize=11)
axes[1, 2].set_ylim([0.7, 1.0])
axes[1, 2].grid(axis='y', alpha=0.3)
for j, v in enumerate(comparison_df['AUC']):
    axes[1, 2].text(j, v + 0.01, f'{v:.4f}', ha='center', fontsize=10, fontweight='bold')

plt.tight_layout()
plt.show()

# æ‰¾å‡ºæœ€ä½³æ¨¡å‹
best_auc_idx = comparison_df['AUC'].idxmax()
best_model = comparison_df.loc[best_auc_idx, 'æ¨¡å‹']
print(f"\nğŸ† æœ€ä½³æ¨¡å‹ï¼ˆæŒ‰ AUCï¼‰: {best_model}")
print(f"   AUC: {comparison_df.loc[best_auc_idx, 'AUC']:.4f}")
```

```{python}
# ROC æ›²çº¿å¯¹æ¯”
# è·å–å„æ¨¡å‹çš„é¢„æµ‹æ¦‚ç‡
if dt_model_w4 is not None:
    y_prob_dt = dt_model_w4.predict_proba(X_test)[:, 1]
else:
    dt_temp = DecisionTreeClassifier(max_depth=5, random_state=42)
    dt_temp.fit(X_train, y_train)
    y_prob_dt = dt_temp.predict_proba(X_test)[:, 1]

y_prob_rf = rf_best.predict_proba(X_test)[:, 1]
y_prob_gbm = gbm_best.predict_proba(X_test)[:, 1]

# è®¡ç®— ROC æ›²çº¿
fpr_dt, tpr_dt, _ = roc_curve(y_test, y_prob_dt)
fpr_rf, tpr_rf, _ = roc_curve(y_test, y_prob_rf)
fpr_gbm, tpr_gbm, _ = roc_curve(y_test, y_prob_gbm)

auc_dt = auc(fpr_dt, tpr_dt)
auc_rf = auc(fpr_rf, tpr_rf)
auc_gbm = auc(fpr_gbm, tpr_gbm)

# ç»˜åˆ¶ ROC æ›²çº¿
plt.figure(figsize=(10, 8))
plt.plot(fpr_dt, tpr_dt, color='#3498db', linewidth=2, label=f'å†³ç­–æ ‘ (AUC = {auc_dt:.4f})')
plt.plot(fpr_rf, tpr_rf, color='#2ecc71', linewidth=2, label=f'éšæœºæ£®æ— (AUC = {auc_rf:.4f})')
plt.plot(fpr_gbm, tpr_gbm, color='#e74c3c', linewidth=2, label=f'GBDT (AUC = {auc_gbm:.4f})')
plt.plot([0, 1], [0, 1], color='navy', linewidth=2, linestyle='--', label='éšæœºçŒœæµ‹')

plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel('å‡æ­£ä¾‹ç‡ (FPR)', fontsize=12)
plt.ylabel('çœŸæ­£ä¾‹ç‡ (TPR)', fontsize=12)
plt.title('ä¸‰æ¨¡å‹ ROC æ›²çº¿å¯¹æ¯”', fontsize=14, fontweight='bold')
plt.legend(loc="lower right", fontsize=11)
plt.grid(True, alpha=0.3)
plt.tight_layout()
plt.show()

print("\nROC æ›²çº¿å¯¹æ¯”åˆ†æ:")
print("- AUC è¶Šæ¥è¿‘ 1.0ï¼Œæ¨¡å‹æ€§èƒ½è¶Šå¥½")
print("- æ›²çº¿è¶Šé è¿‘å·¦ä¸Šè§’ï¼Œæ¨¡å‹æ€§èƒ½è¶Šå¥½")
print(f"- æœ€ä½³æ¨¡å‹: {best_model} (AUC = {comparison_df.loc[best_auc_idx, 'AUC']:.4f})")
```

## æ€»ç»“ä¸å®æˆ˜ç»éªŒ

**æœ¬æ¬¡è¯¾ç¨‹çš„æ ¸å¿ƒå†…å®¹ï¼š**

1. **é›†æˆå­¦ä¹ æ–¹æ³•**
   - **Baggingï¼ˆè£…è¢‹ï¼‰**ï¼šéšæœºæ£®æ—é€šè¿‡è‡ªåŠ©é‡‡æ ·å‡å°‘æ–¹å·®
   - **Boostingï¼ˆæå‡ï¼‰**ï¼šGBDT é€šè¿‡é€æ­¥ä¿®æ­£é”™è¯¯æå‡æ€§èƒ½
   - **ç‰¹å¾éšæœºæ€§**ï¼šéšæœºæ£®æ—åœ¨ç‰¹å¾é€‰æ‹©ä¸Šå¼•å…¥éšæœºæ€§

2. **LightGBM ç‰¹æ€§**
   - åŸºäºç›´æ–¹å›¾çš„ç®—æ³•ï¼Œè®­ç»ƒé€Ÿåº¦å¿«
   - æ”¯æŒå¤§è§„æ¨¡æ•°æ®ï¼Œå†…å­˜æ•ˆç‡é«˜
   - å†…ç½®ç‰¹å¾é‡è¦æ€§åˆ†æ

3. **è¶…å‚æ•°è°ƒä¼˜**
   - **GridSearchCV**ï¼šç³»ç»Ÿåœ°æœç´¢æœ€ä¼˜å‚æ•°ç»„åˆ
   - **äº¤å‰éªŒè¯**ï¼šç¡®ä¿å‚æ•°é€‰æ‹©çš„å¯é æ€§
   - **å¤šæŒ‡æ ‡è¯„ä¼°**ï¼šç»¼åˆè€ƒè™‘å‡†ç¡®ç‡ã€AUC ç­‰æŒ‡æ ‡

4. **æ¨¡å‹å¯¹æ¯”åˆ†æ**
   - é›†æˆæ–¹æ³•é€šå¸¸ä¼˜äºå•ä¸€å†³ç­–æ ‘
   - ä¸åŒç®—æ³•å„æœ‰ä¼˜åŠ¿ï¼Œéœ€è¦æ ¹æ®æ•°æ®ç‰¹ç‚¹é€‰æ‹©
   - å¯è§£é‡Šæ€§ vs é¢„æµ‹æ€§èƒ½çš„æƒè¡¡

**é›†æˆå­¦ä¹ çš„å…³é”®ä¼˜åŠ¿ï¼š**

- **å‡å°‘è¿‡æ‹Ÿåˆ**ï¼šé€šè¿‡ç»„åˆå¤šä¸ªæ¨¡å‹æé«˜æ³›åŒ–èƒ½åŠ›
- **æå‡æ€§èƒ½**ï¼šé›†æˆæ–¹æ³•é€šå¸¸æ¯”å•ä¸€æ¨¡å‹è¡¨ç°æ›´å¥½
- **é²æ£’æ€§å¼º**ï¼šå¯¹å¼‚å¸¸å€¼å’Œå™ªå£°æœ‰æ›´å¥½çš„æŠµæŠ—åŠ›

**å®æˆ˜ç»éªŒæ€»ç»“ï¼š**

- âœ… **é›†æˆæ–¹æ³•é€šå¸¸æ›´å¼ºå¤§**ï¼šéšæœºæ£®æ—å’Œ GBDT å¾€å¾€ä¼˜äºå•ä¸€å†³ç­–æ ‘
- âœ… **GridSearchCV å¾ˆå®ç”¨**ï¼šç³»ç»Ÿåœ°æœç´¢æœ€ä¼˜å‚æ•°ï¼Œé¿å…æ‰‹åŠ¨è°ƒå‚çš„ç›²ç›®æ€§
- âœ… **AUC ä½œä¸ºæ ¸å¿ƒæŒ‡æ ‡**ï¼šåœ¨åˆ†ç±»é—®é¢˜ä¸­ï¼ŒAUC æ¯”å‡†ç¡®ç‡æ›´å¯é 
- âœ… **ç‰¹å¾é‡è¦æ€§æœ‰ä»·å€¼**ï¼šå¸®åŠ©ç†è§£æ¨¡å‹å†³ç­–é€»è¾‘ï¼Œæ”¯æŒç‰¹å¾å·¥ç¨‹
- âœ… **è®¡ç®—æ•ˆç‡å¾ˆé‡è¦**ï¼šLightGBM åœ¨å¤§è§„æ¨¡æ•°æ®ä¸Šè¡¨ç°ä¼˜ç§€
- âœ… **æ¨¡å‹é€‰æ‹©è¦å› åœ°åˆ¶å®œ**ï¼šæ ¹æ®æ•°æ®è§„æ¨¡å’Œä¸šåŠ¡éœ€æ±‚é€‰æ‹©åˆé€‚çš„ç®—æ³•
