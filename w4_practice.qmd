---
title: 第四讲上机实践
---

```{python}
#| echo: false
import matplotlib.pyplot as plt
# 根据操作系统设置不同的字体
import platform

# 获取操作系统类型
system = platform.system()

# 设置 matplotlib 字体
if system == 'Windows':
    plt.rcParams['font.sans-serif'] = ['SimHei']  # Windows 使用黑体
elif system == 'Darwin':
    plt.rcParams['font.sans-serif'] = ['Songti SC']  # Mac 使用宋体
else:
    plt.rcParams['font.sans-serif'] = ['WenQuanYi Zen Hei']  # Linux 使用文泉驿正黑

# 解决负号显示问题
plt.rcParams['axes.unicode_minus'] = False

```

本上机讲义覆盖以下内容：

- Titanic 数据集介绍
- 探索性数据分析 (EDA)
- 数据预处理与特征工程
- 决策树超参数调优与模型训练
- 模型评估（混淆矩阵/准确率/精确率/召回率/F1/ROC/AUC）
- 总结与实战经验

**学习目标**：

- 理解分类问题的基本概念
- 掌握决策树的工作原理
- 学会评估分类模型的性能
- 掌握超参数调优的方法

## Titanic 数据集介绍

**背景**：1912 年泰坦尼克号沉船事故，2224 名乘客中 1502 人遇难，成为历史上最著名的沉船灾难之一。

**任务**：预测乘客是否能在灾难中存活

**数据集特征**：

| 特征 | 含义 | 类型 |
|------|------|------|
| Pclass | 舱位等级（1/2/3） | 数值 |
| Sex | 性别 | 类别 |
| Age | 年龄 | 数值 |
| SibSp | 兄弟姐妹/配偶数 | 数值 |
| Parch | 父母/子女数 | 数值 |
| Fare | 票价 | 数值 |
| Embarked | 登船港口（C/Q/S） | 类别 |

**标签**：Survived（0=死亡，1=存活）

**为什么选择这个数据集？**

- 数据完整，包含丰富的信息
- 是一个经典的二分类问题
- 结果易于理解和解释
- 可以很好地展示分类算法的效果

```{python}
#| message: false
#| warning: false
# 导入所需库
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

from sklearn.model_selection import train_test_split, cross_val_score
from sklearn.preprocessing import LabelEncoder
from sklearn.tree import DecisionTreeClassifier
from sklearn.metrics import (confusion_matrix, ConfusionMatrixDisplay,
                             accuracy_score, precision_score, recall_score, f1_score,
                             roc_curve, auc, classification_report)

```

```{python}
#| message: false
#| warning: false
# 加载 Titanic 数据
df = pd.read_csv("titanic_data/train.csv")
print(f"数据集形状: {df.shape}")
print("前5行数据:")
print(df.head())
print("生存情况统计:")
print(df["Survived"].value_counts())
print(f"生存率: {df['Survived'].mean():.3f}")
```

## 探索性数据分析 (EDA)

**为什么需要数据探索？**

在训练模型之前，我们需要：

- 了解数据的分布特征
- 发现变量之间的关系
- 识别潜在的问题（如异常值、缺失值）
- 为特征工程和模型选择提供依据

**让我们通过可视化来探索 Titanic 数据：**

```{python}
#| message: false
#| warning: false
# 数据探索：可视化分析
fig, axes = plt.subplots(2, 2, figsize=(14, 10))

# 1. 性别 vs 存活率
pd.crosstab(df["Sex"], df["Survived"], normalize="index").plot(
    kind="bar", ax=axes[0, 0], color=["#f44336", "#4caf50"]
)
axes[0, 0].set_title("性别 vs 存活率", fontsize=12)
axes[0, 0].set_xlabel("性别")
axes[0, 0].set_ylabel("比例")
axes[0, 0].set_xticklabels(["女性", "男性"], rotation=0)
axes[0, 0].legend(["死亡", "存活"])
axes[0, 0].grid(True, alpha=0.3, axis="y")

# 2. 舱位等级 vs 存活率
pd.crosstab(df["Pclass"], df["Survived"], normalize="index").plot(
    kind="bar", ax=axes[0, 1], color=["#f44336", "#4caf50"]
)
axes[0, 1].set_title("舱位等级 vs 存活率", fontsize=12)
axes[0, 1].set_xlabel("舱位等级")
axes[0, 1].set_ylabel("比例")
axes[0, 1].set_xticklabels(["一等舱", "二等舱", "三等舱"], rotation=0)
axes[0, 1].legend(["死亡", "存活"])
axes[0, 1].grid(True, alpha=0.3, axis="y")

# 3. 年龄分布（存活 vs 死亡）
df[df["Survived"]==0]["Age"].dropna().hist(
    bins=30, alpha=0.5, label="死亡", ax=axes[1, 0], color="#f44336"
)
df[df["Survived"]==1]["Age"].dropna().hist(
    bins=30, alpha=0.5, label="存活", ax=axes[1, 0], color="#4caf50"
)
axes[1, 0].set_xlabel("年龄")
axes[1, 0].set_ylabel("频数")
axes[1, 0].set_title("年龄分布 (存活 vs 死亡)", fontsize=12)
axes[1, 0].legend()
axes[1, 0].grid(True, alpha=0.3)

# 4. 票价分布（存活 vs 死亡）
df[df["Survived"]==0]["Fare"].dropna().hist(
    bins=30, alpha=0.5, label="死亡", ax=axes[1, 1], color="#f44336"
)
df[df["Survived"]==1]["Fare"].dropna().hist(
    bins=30, alpha=0.5, label="存活", ax=axes[1, 1], color="#4caf50"
)
axes[1, 1].set_xlabel("票价")
axes[1, 1].set_ylabel("频数")
axes[1, 1].set_title("票价分布 (存活 vs 死亡)", fontsize=12)
axes[1, 1].legend()
axes[1, 1].grid(True, alpha=0.3)

plt.tight_layout()
plt.show()
```

**从可视化中我们可以观察到：**

1. **性别差异显著**：女性存活率明显高于男性（体现"女士优先"的救援原则）

2. **舱位等级重要**：一等舱存活率 > 二等舱 > 三等舱（舱位等级反映了社会经济地位）

3. **年龄分布**：儿童存活率相对较高，青壮年死亡较多

4. **票价影响**：高票价乘客存活率更高（与舱位等级相关）

**这些洞察告诉我们哪些特征对预测存活重要！**

## 数据预处理与特征工程

**为什么需要数据预处理？**

现实世界的数据往往是"脏"的：

- **缺失值**：有些信息没有收集到
- **类别变量**：机器学习算法通常需要数值输入
- **异常值**：可能影响模型性能
- **特征尺度不同**：决策树不需要归一化

**我们的预处理策略：**

1. **缺失值处理**
   - Age：用中位数填充（比均值更稳健）
   - Cabin：缺失太多，直接删除
   - Embarked：删除缺失行（很少）

2. **特征编码**
   - Sex：标签编码（female=0, male=1）
   - Embarked：独热编码（避免有序假设）

3. **特征选择**
   - 选择对预测存活有用的特征
   - 排除像 Name、Ticket ID 这样的无关特征

```{python}
#| message: false
#| warning: false
# 数据预处理
print("缺失值统计:")
print(df.isnull().sum())

# Age: 中位数填充，Cabin: 删除，Embarked: 删除缺失行
df["Age"].fillna(df["Age"].median(), inplace=True)
df.drop("Cabin", axis=1, inplace=True)
df.dropna(subset=["Embarked"], inplace=True)

# 编码：Sex 标签编码、Embarked 独热编码
df["Sex"] = LabelEncoder().fit_transform(df["Sex"])
df = pd.get_dummies(df, columns=["Embarked"], drop_first=True)

# 选择特征
features = ["Pclass", "Sex", "Age", "SibSp", "Parch", "Fare", "Embarked_Q", "Embarked_S"]
X = df[features]
y = df["Survived"]

print(f"特征矩阵形状: {X.shape}")
print(f"标签向量形状: {y.shape}")
print(f"选择的特征: {features}")

# 保存预处理后的特征和标签到本地（方便后续模型使用）
X.to_csv("titanic_data/features_processed.csv", index=False)
y.to_csv("titanic_data/labels_processed.csv", index=False)
print("已保存处理后的特征 (titanic_data/features_processed.csv) 和标签 (titanic_data/labels_processed.csv)")

```

## 决策树超参数调优与模型训练

**标准机器学习流程：**

1. **数据分割**：训练集 vs 测试集（必须在预处理之后）
2. **超参数调优**：通过交叉验证找到最佳参数（在训练集上）
3. **模型训练**：使用最佳参数在训练集上训练最终模型
4. **模型评估**：在测试集上评估模型性能

**为什么需要调参？**

决策树有很多超参数可以调节，不同的参数组合会影响模型性能：

- **max_depth**：树的最大深度（控制模型复杂度）
- **min_samples_split**：分裂所需的最小样本数
- **min_samples_leaf**：叶节点的最小样本数

**调参策略：**

通过绘制学习曲线（训练集 vs 验证集）来找到最佳参数：

- 如果训练集得分远高于验证集 → 过拟合，需要降低复杂度
- 如果两者都低 → 欠拟合，需要增加复杂度
- 最佳点：验证集得分最高且与训练集差距不大

```{python}
#| message: false
#| warning: false
# 数据分割：将数据分为训练集和测试集
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42, stratify=y
)

print(f"训练集大小: {X_train.shape[0]}")
print(f"测试集大小: {X_test.shape[0]}")
print(f"训练集存活率: {y_train.mean():.3f}")
print(f"测试集存活率: {y_test.mean():.3f}")
```

```{python}
#| message: false
#| warning: false
# 超参数调优：1. 调优 max_depth 参数
print("=" * 50)
print("1. 调优 max_depth 参数")
print("=" * 50)

max_depths = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 15, 20]
train_scores = []
cv_scores = []

for depth in max_depths:
    dt = DecisionTreeClassifier(max_depth=depth, random_state=42)
    # 交叉验证得分
    cv_score = cross_val_score(dt, X_train, y_train, cv=5, scoring="accuracy").mean()
    cv_scores.append(cv_score)
    # 训练集得分
    dt.fit(X_train, y_train)
    train_scores.append(dt.score(X_train, y_train))

# 绘制学习曲线
plt.figure(figsize=(10, 6))
plt.plot(max_depths, train_scores, "o-", label="训练集得分", linewidth=2, markersize=8)
plt.plot(max_depths, cv_scores, "o-", label="交叉验证得分", linewidth=2, markersize=8)
plt.xlabel("决策树最大深度 (max_depth)", fontsize=12)
plt.ylabel("准确率", fontsize=12)
plt.title("决策树不同 max_depth 的学习曲线", fontsize=14)
plt.legend(fontsize=11)
plt.grid(True, alpha=0.3)
plt.tight_layout()
plt.show()

# 选择最佳 max_depth
best_max_depth = max_depths[cv_scores.index(max(cv_scores))]
print(f"最佳 max_depth: {best_max_depth}")
print(f"交叉验证准确率: {max(cv_scores):.4f}")
```

```{python}
#| message: false
#| warning: false
# 超参数调优：2. 调优 min_samples_split 参数
print("=" * 50)
print("2. 调优 min_samples_split 参数")
print("=" * 50)

min_samples_splits = [2, 5, 10, 15, 20, 25, 30, 40, 50, 60, 80, 100]
train_scores = []
cv_scores = []

for min_samples in min_samples_splits:
    dt = DecisionTreeClassifier(
        max_depth=best_max_depth,
        min_samples_split=min_samples,
        random_state=42
    )
    # 交叉验证得分
    cv_score = cross_val_score(dt, X_train, y_train, cv=5, scoring="accuracy").mean()
    cv_scores.append(cv_score)
    # 训练集得分
    dt.fit(X_train, y_train)
    train_scores.append(dt.score(X_train, y_train))

# 绘制学习曲线
plt.figure(figsize=(10, 6))
plt.plot(min_samples_splits, train_scores, "o-", label="训练集得分", linewidth=2, markersize=8)
plt.plot(min_samples_splits, cv_scores, "o-", label="交叉验证得分", linewidth=2, markersize=8)
plt.xlabel("最小分裂样本数 (min_samples_split)", fontsize=12)
plt.ylabel("准确率", fontsize=12)
plt.title("决策树不同 min_samples_split 的学习曲线", fontsize=14)
plt.legend(fontsize=11)
plt.grid(True, alpha=0.3)
plt.tight_layout()
plt.show()

# 选择最佳 min_samples_split
best_min_samples_split = min_samples_splits[cv_scores.index(max(cv_scores))]
print(f"最佳 min_samples_split: {best_min_samples_split}")
print(f"交叉验证准确率: {max(cv_scores):.4f}")
```

```{python}
#| message: false
#| warning: false
# 超参数调优：3. 调优 min_samples_leaf 参数
print("=" * 50)
print("3. 调优 min_samples_leaf 参数")
print("=" * 50)

min_samples_leafs = [1, 2, 3, 4, 5, 8, 10, 15, 20, 25, 30]
train_scores = []
cv_scores = []

for min_samples in min_samples_leafs:
    dt = DecisionTreeClassifier(
        max_depth=best_max_depth,
        min_samples_split=best_min_samples_split,
        min_samples_leaf=min_samples,
        random_state=42
    )
    # 交叉验证得分
    cv_score = cross_val_score(dt, X_train, y_train, cv=5, scoring="accuracy").mean()
    cv_scores.append(cv_score)
    # 训练集得分
    dt.fit(X_train, y_train)
    train_scores.append(dt.score(X_train, y_train))

# 绘制学习曲线
plt.figure(figsize=(10, 6))
plt.plot(min_samples_leafs, train_scores, "o-", label="训练集得分", linewidth=2, markersize=8)
plt.plot(min_samples_leafs, cv_scores, "o-", label="交叉验证得分", linewidth=2, markersize=8)
plt.xlabel("最小叶节点样本数 (min_samples_leaf)", fontsize=12)
plt.ylabel("准确率", fontsize=12)
plt.title("决策树不同 min_samples_leaf 的学习曲线", fontsize=14)
plt.legend(fontsize=11)
plt.grid(True, alpha=0.3)
plt.tight_layout()
plt.show()

# 选择最佳 min_samples_leaf
best_min_samples_leaf = min_samples_leafs[cv_scores.index(max(cv_scores))]
print(f"最佳 min_samples_leaf: {best_min_samples_leaf}")
print(f"交叉验证准确率: {max(cv_scores):.4f}")
```

```{python}
#| message: false
#| warning: false
# 训练最终模型
print("=" * 50)
print("使用最佳参数训练最终模型")
print("=" * 50)

best_dt = DecisionTreeClassifier(
    max_depth=best_max_depth,
    min_samples_split=best_min_samples_split,
    min_samples_leaf=best_min_samples_leaf,
    random_state=42
)

best_dt.fit(X_train, y_train)

# 在训练集和测试集上评估
train_accuracy = best_dt.score(X_train, y_train)
test_accuracy = best_dt.score(X_test, y_test)

print(f"最终模型参数:")
print(f"  max_depth: {best_max_depth}")
print(f"  min_samples_split: {best_min_samples_split}")
print(f"  min_samples_leaf: {best_min_samples_leaf}")
print(f"\n训练集准确率: {train_accuracy:.4f}")
print(f"测试集准确率: {test_accuracy:.4f}")
```

## 模型评估（混淆矩阵/准确率/精确率/召回率/F1/ROC/AUC）

**为什么需要多种评估指标？**

准确率虽然直观，但有时会产生误导：
- **不平衡数据集**：如果 95% 的样本是类别 A，那么一个"傻瓜模型"（总是预测 A）也能达到 95% 准确率
- **不同错误成本**：在医疗诊断中，漏诊和误诊的代价不同；在垃圾邮件分类中，错过垃圾邮件 vs 误删正常邮件的代价不同

**分类问题的四个基本概念：**

- **真正例 (TP)**：正确预测为正例
- **真反例 (TN)**：正确预测为反例
- **假正例 (FP)**：错误预测为正例（第一类错误）
- **假反例 (FN)**：错误预测为反例（第二类错误）

**常用评估指标：**

- **准确率 (Accuracy)** = (TP + TN) / (TP + TN + FP + FN)
- **精确率 (Precision)** = TP / (TP + FP) —— 在预测为正例的样本中，真正正例的比例
- **召回率 (Recall)** = TP / (TP + FN) —— 在所有真正正例中，被正确预测的比例
- **F1 分数** = 2 × Precision × Recall / (Precision + Recall) —— 精确率和召回率的调和平均

**ROC 曲线和 AUC：**

- **ROC 曲线**：以假正例率(FPR)为横轴，真正例率(TPR)为纵轴绘制的曲线
- **AUC**：ROC 曲线下的面积，AUC 越大，模型性能越好

```{python}
#| message: false
#| warning: false
# 预测测试集
y_pred = best_dt.predict(X_test)
y_pred_proba = best_dt.predict_proba(X_test)[:, 1]  # 预测为正例的概率

# 1. 混淆矩阵
cm = confusion_matrix(y_test, y_pred)
print("=" * 50)
print("1. 混淆矩阵")
print("=" * 50)
print("混淆矩阵:")
print(cm)
print(f"\n真正例 (TP): {cm[1,1]} - 正确预测存活")
print(f"真反例 (TN): {cm[0,0]} - 正确预测死亡")
print(f"假正例 (FP): {cm[0,1]} - 错误预测存活（实际死亡）")
print(f"假反例 (FN): {cm[1,0]} - 错误预测死亡（实际存活）")

# 可视化混淆矩阵
plt.figure(figsize=(6, 5))
disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=['死亡', '存活'])
disp.plot(cmap='Blues', ax=plt.gca())
plt.title('决策树模型混淆矩阵', fontsize=14)
plt.grid(False)
plt.show()
```

```{python}
#| message: false
#| warning: false
# 2. 分类报告：包含多种评估指标
print("=" * 50)
print("2. 详细评估指标")
print("=" * 50)
print("分类报告:")
print(classification_report(y_test, y_pred, target_names=['死亡', '存活']))

# 手动计算各项指标
accuracy = accuracy_score(y_test, y_pred)
precision = precision_score(y_test, y_pred)
recall = recall_score(y_test, y_pred)
f1 = f1_score(y_test, y_pred)

print("=" * 50)
print("关键指标总结:")
print("=" * 50)
print(f"准确率 (Accuracy): {accuracy:.4f} - 整体预测正确的比例")
print(f"精确率 (Precision): {precision:.4f} - 预测存活者中真正存活的比例")
print(f"召回率 (Recall): {recall:.4f} - 实际存活者中被正确预测的比例")
print(f"F1 分数: {f1:.4f} - 精确率和召回率的调和平均")
```

```{python}
#| message: false
#| warning: false
# 3. ROC 曲线和 AUC
fpr, tpr, thresholds = roc_curve(y_test, y_pred_proba)
roc_auc = auc(fpr, tpr)

plt.figure(figsize=(8, 6))
plt.plot(fpr, tpr, color='darkorange', linewidth=2, label=f'ROC 曲线 (AUC = {roc_auc:.4f})')
plt.plot([0, 1], [0, 1], color='navy', linewidth=2, linestyle='--', label='随机猜测')
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel('假正例率 (FPR)', fontsize=12)
plt.ylabel('真正例率 (TPR)', fontsize=12)
plt.title('ROC 曲线 - 决策树模型', fontsize=14)
plt.legend(loc="lower right", fontsize=11)
plt.grid(True, alpha=0.3)
plt.show()

print("=" * 50)
print("ROC 曲线分析")
print("=" * 50)
print(f"AUC 值: {roc_auc:.4f}")
print("\nAUC 解读:")
print("- AUC = 1.0: 完美模型")
print("- AUC = 0.5: 随机猜测")
print("- AUC < 0.5: 比随机猜测还差")
print(f"- 我们的模型 AUC = {roc_auc:.4f}，说明模型性能 {(roc_auc-0.5)/0.5*100:.1f}% 优于随机猜测")
```


```{python}
#| message: false
#| warning: false
# 4. 特征重要性分析
feature_importance = pd.DataFrame({
    'feature': features,
    'importance': best_dt.feature_importances_
}).sort_values('importance', ascending=False)

print("=" * 50)
print("4. 特征重要性分析")
print("=" * 50)
print("各特征对预测存活的重要性:")
for idx, row in feature_importance.iterrows():
    print(f"{row['feature']:12s}: {row['importance']:.4f}")

# 可视化特征重要性
plt.figure(figsize=(10, 6))
colors = plt.cm.viridis(np.linspace(0, 1, len(feature_importance)))
bars = plt.barh(feature_importance['feature'], feature_importance['importance'], color=colors)
plt.xlabel('重要性分数', fontsize=12)
plt.ylabel('特征', fontsize=12)
plt.title('决策树特征重要性', fontsize=14)
plt.grid(True, alpha=0.3, axis='x')

# 添加数值标签
for bar, importance in zip(bars, feature_importance['importance']):
    plt.text(bar.get_width() + 0.001, bar.get_y() + bar.get_height()/2,
             f'{importance:.3f}', ha='left', va='center', fontsize=10)

plt.tight_layout()
plt.show()
```

```{python}
#| message: false
#| warning: false
# 保存模型和结果（供 W5 使用）
import pickle

# 保存决策树模型
with open('titanic_results/dt_model_w4.pkl', 'wb') as f:
    pickle.dump(best_dt, f)

# 保存评估结果
dt_results = {
    'accuracy': accuracy,
    'precision': precision,
    'recall': recall,
    'f1': f1,
    'roc_auc': roc_auc
}

with open('titanic_results/dt_results_w4.pkl', 'wb') as f:
    pickle.dump(dt_results, f)

print("\n✅ 已保存决策树模型和结果到本地文件：")
print("   dt_model_w4.pkl - 决策树模型")
print("   dt_results_w4.pkl - 评估结果")
print(f"\n模型性能摘要:")
print(f"   准确率: {accuracy:.4f}")
print(f"   AUC: {roc_auc:.4f}")
```

## 总结与实战经验

**本次课程的核心内容：**

1. **分类问题基础**
   - 理解二分类问题的基本概念
   - 掌握 Titanic 数据集的特点和预处理方法

2. **探索性数据分析**
   - 通过可视化理解数据分布和特征关系
   - 发现性别、舱位等级等关键特征的影响

3. **决策树算法**
   - 理解决策树的工作原理和优势
   - 掌握超参数调优的方法（max_depth, min_samples_split, min_samples_leaf）

4. **模型评估体系**
   - 混淆矩阵：理解预测结果的四种情况
   - 准确率/精确率/召回率/F1：从不同角度评估模型
   - ROC/AUC：评估模型的整体性能

5. **特征重要性**
   - 理解哪些特征对预测最重要
   - 为特征选择和工程提供指导

**实战经验总结：**

- ✅ **EDA 很重要**：可视化分析能帮我们发现数据中的关键模式
- ✅ **数据预处理**：缺失值处理和特征编码是机器学习的基础
- ✅ **超参数调优**：通过交叉验证找到最佳参数，避免过拟合
- ✅ **评估指标多样化**：不要只看准确率，要根据业务场景选择合适的指标
- ✅ **特征重要性分析**：理解模型的决策逻辑，提高可解释性
- ✅ **调参是必要的**：通过交叉验证找到最佳参数组合
- ✅ **可解释性很重要**：决策树的优势在于易于理解和解释


