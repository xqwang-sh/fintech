---
title: 项目5：IEEE‑CIS Fraud Detection 学生项目要求
---

## 项目背景

* **项目名称**：线上交易实时反欺诈（IEEE‑CIS / Vesta）
* **应用场景 / 价值**：在**交易授权前**识别高风险交易，降低欺诈损失与误拒率（减少“好人被拒”）。你们将基于历史交易数据构建一个**可在线部署**的欺诈概率模型，并解释关键风险特征与业务取舍（查得率 vs. 误杀率）。
* **数据来源**：课程提供自 Kaggle *IEEE‑CIS Fraud Detection* 的**子集**。核心数据表：

  * `train_transaction.csv`（主表，含标签 `isFraud`）
  * `train_identity.csv`（设备/浏览器/网络指纹，按 `TransactionID` 可左连接）
  * 测试集在 Kaggle 为无标签格式，本课程不提交 Kaggle 榜，仅做课程内评估。
* **任务类型**：二分类（`isFraud` = 1 表示欺诈）。

---

## 项目任务（必须完成）

1. **目标变量口径**：以主表 `isFraud` 为标签，`1=欺诈/0=正常`；报告中打印**类比例**（说明极度不平衡）。
2. **样本选择**：统一使用课程提供的 `ieee_train_sample.csv`（主表子集）作为训练/测试样本（**最低要求只用主表**）。
3. **仅用授权前可得信息**：禁止任何基于**未来时点或标签**构造的泄漏特征（如在全体数据上先用 `isFraud` 计算用户的“历史欺诈率”，再用于同一切分的训练/测试）。
4. **数据读取与检查**：打印行列数、前 3 行、关键列存在性；在 `README.md` 记录数据摘要。
5. **数据清洗**：缺失处理、类别统一（大小写/空格）、明显异常值处置（如不合理金额/时间戳）。
6. **特征工程（主表）**：至少 **2 个**新增特征（示例：`TransactionAmt` 对数、金额分箱、`addr1/dist1` 组合、邮箱域名 Top‑K One‑Hot、`card*` 频次或长度特征等）；必要的 One‑Hot/分箱。
7. **训练/测试切分**：固定随机种子；说明比例与分层策略（建议 `stratify=isFraud`）。
8. **基线模型**：逻辑回归（必做基线）；至少 **1 个**评估指标（推荐 **ROC AUC + PR AUC**，并给出阈值下的查得率/准确率）。
9. **模型解释**：打印或可视化关键特征影响（系数/重要性），并给出 2–3 条业务洞见（如金额、设备一致性、邮箱域名等）。
10. **结果导出**：在 `outputs/` 输出预测概率列，并在报告中说明阈值选择与业务含义（拦截阈值 vs. 人工复核阈值）。

> 允许在基线之上追加 1–2 个简单模型作对比（如 决策树/随机森林/轻量级梯度提升），见“额外加分”。

---

## 团队与分工（6-10 人）

* **推荐规模**：6-10 人；可根据团队实际人数灵活调整。
* **核心角色（必须）**：
  A. 数据读取与清洗（`clean_data`）
  B. 数据探索（`explore_data`）
  C. 特征工程（`feature_engineering`）
  D. 数据切分（`split_data`）
  E. 训练模型（`train_model`）
  F. 评估与导出（`evaluate_model` / `save_predictions`）
* **可选角色（7-8 人时添加）**：
  G. 可视化与报告排版（负责图表制作、报告编写）
  H. presenter（做PPT、项目答辩汇报）
* **协作角色（9-10 人时添加）**：
  I. 数据探索辅助（协助 A 完成数据理解、可视化探索）
  J. 特征工程辅助（协助 C 完成特征构造、验证）
  K. 模型调参辅助（协助 E 完成超参数调优、模型对比）
* **署名规范**：每位成员在自己负责的函数顶部写 `(owner 学号)+姓名`；**不得修改他人代码**；合并由队长负责。
* **分工建议**：
  - 6 人：每人 1 个核心角色
  - 7 人：6 个核心角色 + 1 个可选角色（G 或 H）
  - 8 人：6 个核心角色 + 2 个可选角色（G + H）
  - 9 人：6 个核心角色 + 2 个可选角色 + 1 个协作角色
  - 10 人：6 个核心角色 + 2 个可选角色 + 2 个协作角色

---

## 数据与合规

* **数据说明**：在 `README.md` 或报告中写明来源、时间范围、关键字段、目标变量口径、过滤规则。
* **隐私与伦理**：数据已匿名化；如追加外部数据，确保合法来源并说明许可与处理。
* **数据字典**：提供关键字段释义（表格或清单）。

---

## 交付与时间线（统一里程碑）

* **W3：立项检查**

  1. `README.md`（项目背景、分工、数据来源与口径摘要）；
  2. 可运行的最小脚本（跑通样例数据并生成至少一张图片）；
  3. 明确任务清单与负责人。

* **W7：结项答辩**

  提交完整复现包（见下 §5）+ 报告（6–8 页）+ 幻灯（6–8 页）+ AI 使用记录。

---

## 交付清单（统一目录）

```
project_root/
  README.md                # 项目背景、分工、数据来源与口径摘要、运行命令
  main.py                  # 单文件分工脚本
  requirements.txt         # 依赖（pandas/numpy/scikit-learn 等）
  data/
    sample.csv             # 样本（数据不上传）
    README.md              # 数据文件夹结构
  outputs/
    predictions.csv        # 模型输出样例（运行脚本可覆盖生成）
  report.pdf  (或 .md)     # 6–8 页项目报告（请在结题时添加）
  slides.pdf               # 6–8 页答辩幻灯（请在结题时添加）
  ai_usage_log.md          # AI 使用记录（日期/工具/用途/采纳与否）
  .gitignore               # 忽略大文件（保留示例数据与示例输出）
```

---

## 技术要求

**最低要求（必须达成）**

* 按照README可以复刻结果。
* 最小流程：读取 → 清洗 → 特征 → 切分 → 训练（基线）→ 评估 → 导出。
* 基线模型：分类=逻辑回归 / 回归=线性回归；至少 1 个评估指标；固定随机种子；输出预测到 `outputs/`。
* 可复现性：写清版本号与数据来源；提交样例数据与样例输出。
* 代码协作：每人仅编辑自己的函数；完成 `TODO` 后改为 `DONE`；合并由队长统一执行。

**额外加分点（任选 1–4 项）**

* **时间感知切分**：用 `TransactionDT` 做**时间顺序切分**（前 80% 时间训练，后 20% 测试），并对比随机切分差异。
* **类别不平衡处理**：类权重/下采样/上采样/SMOTE；并报告对 **PR AUC / 查得率@固定误杀率** 的影响。
* **单张辅助表汇总**（≤1 张，**identity 表优先**）：以 `TransactionID` 左连接到主表，抽取**设备/浏览器/网络**的聚合特征（如出现频次、稳定度、近期多端登录计数）。
* **可视化 ≥2 张**：金额分布、邮箱域名 Top‑K、设备/浏览器稳定性、ROC/PR 曲线等。
* **工程性**：友好报错与自动日志（数据形状、特征清单、耗时、随机种子）。

---

## 评分与 Rubric（统一口径，可微调）

> 总评 = **团队分 90% + 互评 10%**；如公布**难度系数**（0.9 / 1.0 / 1.1），按乘数计算。

### 团队分（90%）

> 其中"报告与可读性"仅针对**报告文本与图表**评分。

| 维度         | A（优秀）          | B（良好）       | C（合格）      | D（需改进） |
| ---------- | -------------- | ----------- | ---------- | ------ |
| 可运行性(10)   | 一键跑通；无报错；跨平台稳定 | 一键跑通，小问题可自解 | 基本跑通，需老师介入 | 无法跑通   |
| 正确性(20)    | 任务实现到位，评估合理    | 基本实现，评估略单薄  | 只完成部分流程    | 偏离题意   |
| 稳健性(10)   | 缺失/异常/边界处理到位 | 处理常见问题 | 处理有限  | 几乎未处理  |
| 代码质量(10)   | 变量/注释清晰，结构整洁 | 基本清晰   | 可读性一般 | 可读性差   |
| 报告与可读性(30) | 结构清晰、图表规范、叙述有因有据 | 大体清晰        | 说明不全/结构混乱  | 缺失关键说明 |
| 演示表达(20)    | 逻辑清楚，答辩到位      | 讲清主要结论      | 表达一般       | 不能自洽   |

### 互评（10%）

* 每位成员对**其他人**打分；与教师评分结合。
* 若互评明显失真，教师可依据提交记录与痕迹进行调整。

---

## 报告与答辩内容（统一骨架）

**报告（6–8 页）**

1. 背景与任务（场景、目标、评估指标）
2. 数据与变量（来源、时间、清洗摘要、口径与过滤、数据字典片段；如有 identity 汇总请画**数据关系图**）
3. 方法（流程图、基线模型、评估方案；强调如何防止信息泄漏）
4. 结果（表/图 + 解读 + 业务含义；阈值选择与查得/误杀权衡；PR 曲线解读）
5. 误差来源与改进（类别不平衡、时间漂移、特征选择、编码方式等）
6. 结论与建议（面向风控的可执行建议：拦截阈值、人工复核策略等）

**答辩幻灯（6–8 页）**：与报告同结构，突出关键结论与可视化（ROC/PR、Top 特征等）。

---

## 提交与命名规范

* **打包**：提交 `.zip`，保留目录结构；不要包含超大无关文件。
* **命名**：`【IEEE】_【班级】_【队名】.zip`；报告/幻灯使用相同前缀。
* **提交方式**：按课程平台要求（学习通 / LMS / GitHub Release）。

---

## 学术诚信与 AI 使用政策

* 允许用 AI 工具进行**资料查询、代码解释、调试建议**；
* **禁止**：粘贴未理解的大段生成代码、虚构数据/结果、抄袭他组；
* 必交 `ai_usage_log.md`（日期、工具、用途、是否采纳与原因 2–3 句）；
* 发现学术不端将按校规处理。

